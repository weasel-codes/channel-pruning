{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "L2_PECSS_VGG16.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weasel-codes/channel-pruning/blob/main/L2_PECSS_VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwNip6GBaY4w"
      },
      "source": [
        "# Using Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4pWmScUlDA4",
        "outputId": "4979c322-f267-4df1-dd39-1f4ecfbe5bcf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbys7ZOE6y6D"
      },
      "source": [
        "one time start"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhg-5uCWjqhR"
      },
      "source": [
        "! pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-srEUzmjtt_"
      },
      "source": [
        " from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t45jiJoylkcd",
        "outputId": "4f39d47c-012b-4805-a03d-a6e6a208cee8"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset   old_vgg      vgg16_m_19  vgg16_m_35  vgg16_m_45  vgg16_m_60\n",
            "drive\t  sample_data  vgg16_m_25  vgg16_m_4   vgg16_m_50  vgg16_m_9\n",
            "new_vgg4  vgg16_m_14   vgg16_m_30  vgg16_m_40  vgg16_m_55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq-yppaAmGqc"
      },
      "source": [
        "!mkdir /root/.kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lleOS_wGjEmN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61ca2d3d-f4e7-45ca-96a5-aeee41eb20d4"
      },
      "source": [
        "!mv kaggle.json /root/.kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat 'kaggle.json': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sj6kgTtOmXfm",
        "outputId": "76726ded-4b60-4f0e-f8c5-531091c5b124"
      },
      "source": [
        "!kaggle datasets download -d ifigotin/imagenetmini-1000"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 146, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "IOError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCPHhkIgmpUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e53f2e75-e92d-441f-efeb-4c3113cb637e"
      },
      "source": [
        "!mv kaggle.json /root/.kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat 'kaggle.json': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5XsJmGamuSD",
        "outputId": "63e1df6b-4b9d-42cf-dd35-79957505d7c7"
      },
      "source": [
        "!kaggle datasets download -d ifigotin/imagenetmini-1000"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 146, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "IOError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r496t4wAnAGw",
        "outputId": "58cc5f31-d44a-4da1-d06c-f9f1fda624f3"
      },
      "source": [
        "!unzip /content/imagenetmini-1000.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open /content/imagenetmini-1000.zip, /content/imagenetmini-1000.zip.zip or /content/imagenetmini-1000.zip.ZIP.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1n-KO0I644C"
      },
      "source": [
        "one time end"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_Mm_T2e-t72",
        "outputId": "e4ef64df-d756-4239-b08c-362ab414d1f2"
      },
      "source": [
        "!pip install kerop"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kerop\n",
            "  Downloading https://files.pythonhosted.org/packages/15/0e/e8c06d41f2a584890b6631d3cf32a20cbfc1833c4d66424525bccd52bffc/kerop-0.1.4-2010260808.tar.gz\n",
            "Building wheels for collected packages: kerop\n",
            "  Building wheel for kerop (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kerop: filename=kerop-0.1.4.post2105221903-cp37-none-any.whl size=5824 sha256=c873450fd85c0c038e0dd67cc509a35beb44ec2f2c5e68dc54dcbae2f24ef02c\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/14/1c/ac2ee932faa6bc904b26430a266195a515ccaa79f73a258b88\n",
            "Successfully built kerop\n",
            "Installing collected packages: kerop\n",
            "Successfully installed kerop-0.1.4.post2105221903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36hYOfrtaVwh",
        "outputId": "f7ae08c0-2522-4fa1-afe1-f02082c5c3ea"
      },
      "source": [
        "pip install tf-explain"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf-explain\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/f0/4faa7a1749e39d0d623f801ccf185230d22b885fa212d8ee08aa47cebaa4/tf_explain-0.3.0-py3-none-any.whl (43kB)\n",
            "\r\u001b[K     |███████▌                        | 10kB 23.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 29.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 30kB 20.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 40kB 16.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 4.4MB/s \n",
            "\u001b[?25hInstalling collected packages: tf-explain\n",
            "Successfully installed tf-explain-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9QE3mnWdbASH",
        "outputId": "c578508b-284f-45d0-808b-63421f029ca6"
      },
      "source": [
        "pip install kerassurgeon"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kerassurgeon\n",
            "  Downloading https://files.pythonhosted.org/packages/0c/7d/77839f5b038971d0d8f0ce195a6edff6b0d25f0fa088d6a5ecbc4acceda1/kerassurgeon-0.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from kerassurgeon) (2.4.1)\n",
            "Collecting importlib-metadata<2.0.0,>=1.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8e/58/cdea07eb51fc2b906db0968a94700866fc46249bdc75cac23f9d13168929/importlib_metadata-1.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pandas[examples]<2.0.0,>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from kerassurgeon) (1.1.5)\n",
            "\u001b[33m  WARNING: pandas 1.1.5 does not provide the extra 'examples'\u001b[0m\n",
            "Requirement already satisfied: keras[standalone-keras]<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from kerassurgeon) (2.4.3)\n",
            "\u001b[33m  WARNING: Keras 2.4.3 does not provide the extra 'standalone-keras'\u001b[0m\n",
            "Collecting pytest[test]<7.0.0,>=6.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/59/6821e900592fbe261f19d67e4def0cb27e52ef8ed16d9922c144961cc1ee/pytest-6.2.4-py3-none-any.whl (280kB)\n",
            "\u001b[K     |████████████████████████████████| 286kB 13.1MB/s \n",
            "\u001b[33m  WARNING: pytest 6.2.4 does not provide the extra 'test'\u001b[0m\n",
            "\u001b[?25hCollecting pillow[examples]<8.0.0,>=7.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/f2/6722dd0c22e3a143ac792ccb2424924ac72af4adea756b1165b4cad50da7/Pillow-7.2.0-cp37-cp37m-manylinux1_x86_64.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 38.1MB/s \n",
            "\u001b[33m  WARNING: Pillow 7.2.0 does not provide the extra 'examples'\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerassurgeon) (1.19.5)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerassurgeon) (1.12)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerassurgeon) (3.3.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerassurgeon) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerassurgeon) (1.1.2)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerassurgeon) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerassurgeon) (2.4.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerassurgeon) (1.32.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerassurgeon) (1.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerassurgeon) (2.4.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerassurgeon) (0.3.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerassurgeon) (0.2.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerassurgeon) (2.10.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerassurgeon) (3.7.4.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerassurgeon) (0.12.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerassurgeon) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerassurgeon) (3.12.4)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerassurgeon) (1.6.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<2.0.0,>=1.7.0->kerassurgeon) (3.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas[examples]<2.0.0,>=1.1.2->kerassurgeon) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas[examples]<2.0.0,>=1.1.2->kerassurgeon) (2018.9)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras[standalone-keras]<3.0.0,>=2.4.3->kerassurgeon) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras[standalone-keras]<3.0.0,>=2.4.3->kerassurgeon) (3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytest[test]<7.0.0,>=6.0.2->kerassurgeon) (20.9)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from pytest[test]<7.0.0,>=6.0.2->kerassurgeon) (21.2.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.7/dist-packages (from pytest[test]<7.0.0,>=6.0.2->kerassurgeon) (1.1.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pytest[test]<7.0.0,>=6.0.2->kerassurgeon) (0.10.2)\n",
            "Collecting pluggy<1.0.0a1,>=0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/28/85c7aa31b80d150b772fbe4a229487bc6644da9ccb7e427dd8cc60cb8a62/pluggy-0.13.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from pytest[test]<7.0.0,>=6.0.2->kerassurgeon) (1.10.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3.0,>=2.0->kerassurgeon) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3.0,>=2.0->kerassurgeon) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3.0,>=2.0->kerassurgeon) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3.0,>=2.0->kerassurgeon) (56.1.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3.0,>=2.0->kerassurgeon) (1.30.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3.0,>=2.0->kerassurgeon) (2.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3.0,>=2.0->kerassurgeon) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytest[test]<7.0.0,>=6.0.2->kerassurgeon) (2.4.7)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<3.0,>=2.0->kerassurgeon) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3.0,>=2.0->kerassurgeon) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3.0,>=2.0->kerassurgeon) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3.0,>=2.0->kerassurgeon) (4.7.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3.0,>=2.0->kerassurgeon) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3.0,>=2.0->kerassurgeon) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3.0,>=2.0->kerassurgeon) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3.0,>=2.0->kerassurgeon) (2020.12.5)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<3.0,>=2.0->kerassurgeon) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3.0,>=2.0->kerassurgeon) (0.4.8)\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: importlib-metadata, pluggy, pytest, pillow, kerassurgeon\n",
            "  Found existing installation: importlib-metadata 4.0.1\n",
            "    Uninstalling importlib-metadata-4.0.1:\n",
            "      Successfully uninstalled importlib-metadata-4.0.1\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "Successfully installed importlib-metadata-1.7.0 kerassurgeon-0.2.0 pillow-7.2.0 pluggy-0.13.1 pytest-6.2.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsqCJ2HRZkuX"
      },
      "source": [
        "Importing needed library and degrading the version of tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiKarWUTahLp",
        "outputId": "682d31e9-5c3b-44f7-e353-bf96cf06c9a8"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from kerassurgeon import identify\n",
        "from kerassurgeon.operations import delete_channels, delete_layer\n",
        "from kerassurgeon import Surgeon\n",
        "\n",
        "from tensorflow.keras.applications.xception import decode_predictions\n",
        "from tf_explain.core.activations import ExtractActivations\n",
        "import kerop\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFou4Tkvaiyh",
        "outputId": "76e4b18c-a776-448e-e00d-b93c0e8e2dcc"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJWp_865ZxzC"
      },
      "source": [
        "Loading the pretatined model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZeEUsyda4e9",
        "outputId": "ec9a07e3-2df7-4b3a-9c3f-8a44a2c44786"
      },
      "source": [
        "model=tf.keras.applications.vgg16.VGG16(weights='imagenet',include_top=True)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 7s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y8Ly09LaL2y"
      },
      "source": [
        "Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgPIobZGxIOl",
        "outputId": "ab3bc826-9709-4771-d9c5-0838b08fa85f"
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTf6dBSlovYb",
        "outputId": "4e7be669-24a0-49ef-d44b-cdafbcbcacc5"
      },
      "source": [
        "from keras.applications.vgg16 import preprocess_input,decode_predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tiv6hYJAAzh1"
      },
      "source": [
        "Unzip dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGbAOdahaQNK"
      },
      "source": [
        "Unzipping the test dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GClDap9YA2un",
        "outputId": "66ed376e-3435-45ea-b143-f8951dea86c2"
      },
      "source": [
        "!unzip /content/drive/MyDrive/dataset-20210506T124641Z-001.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/dataset-20210506T124641Z-001.zip\n",
            "  inflating: dataset/n03447721_ILSVRC2012_val_00041280.JPEG  \n",
            "  inflating: dataset/n03788365_ILSVRC2012_val_00006572.JPEG  \n",
            "  inflating: dataset/n03095699_ILSVRC2012_val_00019229.JPEG  \n",
            "  inflating: dataset/n02127052_ILSVRC2012_val_00012958.JPEG  \n",
            "  inflating: dataset/n02129165_ILSVRC2012_val_00016765.JPEG  \n",
            "  inflating: dataset/n03314780_ILSVRC2012_val_00000624.JPEG  \n",
            "  inflating: dataset/n03837869_ILSVRC2012_val_00016087.JPEG  \n",
            "  inflating: dataset/n01843383_ILSVRC2012_val_00014068.JPEG  \n",
            "  inflating: dataset/n03584829_ILSVRC2012_val_00012032.JPEG  \n",
            "  inflating: dataset/n02134084_ILSVRC2012_val_00021889.JPEG  \n",
            "  inflating: dataset/n03447721_ILSVRC2012_val_00026287.JPEG  \n",
            "  inflating: dataset/n03584829_ILSVRC2012_val_00025030.JPEG  \n",
            "  inflating: dataset/n02134084_ILSVRC2012_val_00002578.JPEG  \n",
            "  inflating: dataset/n02129165_ILSVRC2012_val_00030575.JPEG  \n",
            "  inflating: dataset/n03788365_ILSVRC2012_val_00046284.JPEG  \n",
            "  inflating: dataset/n03788365_ILSVRC2012_val_00034671.JPEG  \n",
            "  inflating: dataset/n03888257_ILSVRC2012_val_00015689.JPEG  \n",
            "  inflating: dataset/n11939491_ILSVRC2012_val_00048975.JPEG  \n",
            "  inflating: dataset/n03467068_ILSVRC2012_val_00007208.JPEG  \n",
            "  inflating: dataset/n03447447_ILSVRC2012_val_00036574.JPEG  \n",
            "  inflating: dataset/n15075141_ILSVRC2012_val_00013028.JPEG  \n",
            "  inflating: dataset/n02509815_ILSVRC2012_val_00026182.JPEG  \n",
            "  inflating: dataset/n03467068_ILSVRC2012_val_00042452.JPEG  \n",
            "  inflating: dataset/n02509815_ILSVRC2012_val_00020033.JPEG  \n",
            "  inflating: dataset/n04372370_ILSVRC2012_val_00017546.JPEG  \n",
            "  inflating: dataset/n03447721_ILSVRC2012_val_00023153.JPEG  \n",
            "  inflating: dataset/n02088238_ILSVRC2012_val_00024881.JPEG  \n",
            "  inflating: dataset/n02002724_ILSVRC2012_val_00048008.JPEG  \n",
            "  inflating: dataset/n04380533_ILSVRC2012_val_00008897.JPEG  \n",
            "  inflating: dataset/n02948072_ILSVRC2012_val_00019827.JPEG  \n",
            "  inflating: dataset/n03131574_ILSVRC2012_val_00044316.JPEG  \n",
            "  inflating: dataset/n03825788_ILSVRC2012_val_00042674.JPEG  \n",
            "  inflating: dataset/n03777754_ILSVRC2012_val_00020155.JPEG  \n",
            "  inflating: dataset/n07753113_ILSVRC2012_val_00016680.JPEG  \n",
            "  inflating: dataset/n03887697_ILSVRC2012_val_00034741.JPEG  \n",
            "  inflating: dataset/n03887697_ILSVRC2012_val_00035980.JPEG  \n",
            "  inflating: dataset/n03935335_ILSVRC2012_val_00035991.JPEG  \n",
            "  inflating: dataset/n03595614_ILSVRC2012_val_00008022.JPEG  \n",
            "  inflating: dataset/n02056570_ILSVRC2012_val_00039797.JPEG  \n",
            "  inflating: dataset/n01824575_ILSVRC2012_val_00009419.JPEG  \n",
            "  inflating: dataset/n04562935_ILSVRC2012_val_00046961.JPEG  \n",
            "  inflating: dataset/n07742313_ILSVRC2012_val_00022487.JPEG  \n",
            "  inflating: dataset/n01494475_ILSVRC2012_val_00027160.JPEG  \n",
            "  inflating: dataset/n02120079_ILSVRC2012_val_00037343.JPEG  \n",
            "  inflating: dataset/n02454379_ILSVRC2012_val_00017710.JPEG  \n",
            "  inflating: dataset/n02277742_ILSVRC2012_val_00035673.JPEG  \n",
            "  inflating: dataset/n03825788_ILSVRC2012_val_00031996.JPEG  \n",
            "  inflating: dataset/n02123394_ILSVRC2012_val_00021703.JPEG  \n",
            "  inflating: dataset/n03485794_ILSVRC2012_val_00036754.JPEG  \n",
            "  inflating: dataset/n02123394_ILSVRC2012_val_00008986.JPEG  \n",
            "  inflating: dataset/n02112137_ILSVRC2012_val_00034735.JPEG  \n",
            "  inflating: dataset/n03026506_ILSVRC2012_val_00034047.JPEG  \n",
            "  inflating: dataset/n02114712_ILSVRC2012_val_00013985.JPEG  \n",
            "  inflating: dataset/n03498962_ILSVRC2012_val_00034911.JPEG  \n",
            "  inflating: dataset/n04264628_ILSVRC2012_val_00043547.JPEG  \n",
            "  inflating: dataset/n02056570_ILSVRC2012_val_00008279.JPEG  \n",
            "  inflating: dataset/n07742313_ILSVRC2012_val_00012232.JPEG  \n",
            "  inflating: dataset/n03773504_ILSVRC2012_val_00031707.JPEG  \n",
            "  inflating: dataset/n04120489_ILSVRC2012_val_00038922.JPEG  \n",
            "  inflating: dataset/n01494475_ILSVRC2012_val_00039588.JPEG  \n",
            "  inflating: dataset/n02782093_ILSVRC2012_val_00018230.JPEG  \n",
            "  inflating: dataset/n02074367_ILSVRC2012_val_00043097.JPEG  \n",
            "  inflating: dataset/n02447366_ILSVRC2012_val_00035718.JPEG  \n",
            "  inflating: dataset/n04456115_ILSVRC2012_val_00012862.JPEG  \n",
            "  inflating: dataset/n04456115_ILSVRC2012_val_00045788.JPEG  \n",
            "  inflating: dataset/n02112018_ILSVRC2012_val_00045514.JPEG  \n",
            "  inflating: dataset/n07742313_ILSVRC2012_val_00009579.JPEG  \n",
            "  inflating: dataset/n02504458_ILSVRC2012_val_00034562.JPEG  \n",
            "  inflating: dataset/n02441942_ILSVRC2012_val_00042483.JPEG  \n",
            "  inflating: dataset/n03938244_ILSVRC2012_val_00001501.JPEG  \n",
            "  inflating: dataset/n04346328_ILSVRC2012_val_00016767.JPEG  \n",
            "  inflating: dataset/n03770679_ILSVRC2012_val_00046793.JPEG  \n",
            "  inflating: dataset/n03887697_ILSVRC2012_val_00047599.JPEG  \n",
            "  inflating: dataset/n02782093_ILSVRC2012_val_00038086.JPEG  \n",
            "  inflating: dataset/n02138441_ILSVRC2012_val_00001742.JPEG  \n",
            "  inflating: dataset/n04592741_ILSVRC2012_val_00007397.JPEG  \n",
            "  inflating: dataset/n03924679_ILSVRC2012_val_00005015.JPEG  \n",
            "  inflating: dataset/n02342885_ILSVRC2012_val_00029758.JPEG  \n",
            "  inflating: dataset/n07760859_ILSVRC2012_val_00025217.JPEG  \n",
            "  inflating: dataset/n02342885_ILSVRC2012_val_00047769.JPEG  \n",
            "  inflating: dataset/n03991062_ILSVRC2012_val_00046305.JPEG  \n",
            "  inflating: dataset/n03924679_ILSVRC2012_val_00038222.JPEG  \n",
            "  inflating: dataset/n01753488_ILSVRC2012_val_00017531.JPEG  \n",
            "  inflating: dataset/n02992529_ILSVRC2012_val_00032046.JPEG  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgiM86a4plKG"
      },
      "source": [
        "checking computation time before pruning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3apRCixcpgsI"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utQiTFs_xwD7"
      },
      "source": [
        "# model.evaluate(test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msyjixltaWE_"
      },
      "source": [
        "path for dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKOYzfNumPmy"
      },
      "source": [
        "path=\"/content/dataset\"\n",
        "total_time=0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Tex65HeAnhU"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.layers import *\n",
        "from keras.models import * \n",
        "from keras.preprocessing import image\n",
        "import time\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHQbGOy4AQxB"
      },
      "source": [
        "def modelFlops(test_model) :\n",
        "  # analyze FLOPS\n",
        "  layer_name, layer_flops, inshape, weights = kerop.profile(test_model)\n",
        "\n",
        "  flops = 0\n",
        "  # visualize results\n",
        "  for name, flop, shape, weight in zip(layer_name, layer_flops, inshape, weights):\n",
        "      flops = flops + flop\n",
        "\n",
        "  return flops"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mw0j-oVOmFqz",
        "outputId": "2b8931fc-bf56-4196-9b4c-4ea95c8d58fa"
      },
      "source": [
        "pred_b = []\n",
        "for filename in os.listdir(path) :\n",
        "      label = filename.split('_')[0]\n",
        "      file_path = path + \"/\" + filename\n",
        "      image=tf.keras.preprocessing.image.load_img(file_path, target_size=(224, 224))  # reading image (Folder path and image name )\n",
        "      \n",
        "      image=np.array(image)\n",
        "      image=image.reshape((1,image.shape[0],image.shape[1],image.shape[2]))\n",
        "      image=preprocess_input(image)\n",
        "\n",
        "      x=time.time()\n",
        "      op1=model.predict(image)\n",
        "      y=time.time()\n",
        "      total_time = total_time + (y-x)\n",
        "      label1=decode_predictions(op1,top=1)\n",
        "      pred_b.append([label, label1[0][0][0]])\n",
        "\n",
        "count = 0\n",
        "for i in range(len(pred_b)) :\n",
        "    if pred_b[i][0] == pred_b[i][1] :\n",
        "      count = count + 1\n",
        "print('Model Flops : ', modelFlops(model))\n",
        "print('Total : ', len(pred_b), ', Correct : ', count, ', Accuracy : ', (100*count/len(pred_b)))\n",
        "print('Time Taken for prediction : ', (total_time/len(pred_b)) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "40960/35363 [==================================] - 0s 0us/step\n",
            "Model Flops :  30932349056\n",
            "Total :  84 , Correct :  83 , Accuracy :  98.80952380952381\n",
            "Time Taken for prediction :  0.09785511096318562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhzfM8u7Zzas",
        "outputId": "58c4a0b0-4761-4d0e-e780-5499449789cb"
      },
      "source": [
        "print(\"Total parameters before pruning\",model.count_params())#toatal parameters before pruning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total parameters before pruning 138357544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmkQBMLNpifA"
      },
      "source": [
        "# test_dataset = image.ImageDataGenerator(\n",
        "#  rescale=1./255,\n",
        "#  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNBzzSmKp3Yv"
      },
      "source": [
        "# test_generator = test_dataset.flow_from_directory(\n",
        "#     \"/content/imagenet-mini/val\",\n",
        "#     target_size = (224, 224))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcYtYcDxzwiW"
      },
      "source": [
        "Saving the model before pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8CzWFvNwqsN"
      },
      "source": [
        "model.save(\"old_vgg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrBHfo9ez03P"
      },
      "source": [
        "Checking the model size before pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZOS63NTyXFw",
        "outputId": "dda3ea10-5aa4-4ae7-876f-92748132aa05"
      },
      "source": [
        "import os\n",
        "import math\n",
        "# Get file size in bytes for a given model\n",
        "print(\"Model size after pruning=>\",(os.stat('/content/old_vgg').st_size)/math.pow(2,20),\" Mega Bytes\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model size after pruning=> 527.8715286254883  Mega Bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVcFbtqsOo5h"
      },
      "source": [
        "# Single Layer Pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DO-ZbIXAfvUL",
        "outputId": "d56e6f6c-2941-4ad6-aaf9-352d77270644"
      },
      "source": [
        "surgeon = Surgeon(model)#initialising surgeon for the model\n",
        "layer1 = model.layers[2]#selectig a particular layer\n",
        "layer1_weights = layer1.get_weights()\n",
        "weights = layer1_weights[0]\n",
        "print(\"Number of channels : \", len(weights[0][2]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of channels :  64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QkinFd9AiaX"
      },
      "source": [
        "# import numpy as np\n",
        "# max=0\n",
        "# max_i=0\n",
        "# for i in range(len(layer1_weights)):\n",
        "#   temp=np.sum(layer1_weights[i])\n",
        "#   if temp>max:\n",
        "#     max=temp\n",
        "#     max_i=i\n",
        "# channel_to_delete=i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGY6eWqqEkTr"
      },
      "source": [
        "# surgeon = Surgeon(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAaOU3XHixEh",
        "outputId": "558ff7c5-55bb-42c6-df67-55ad886da8fd"
      },
      "source": [
        "surgeon = Surgeon(model)\n",
        "surgeon.add_job('delete_channels', layer1, channels=[2, 6, 8,32,38])#deleting selected channels at layer 1\n",
        "new_model = surgeon.operate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deleting 5/64 channels from layer: block1_conv2\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxNuZAUcNuFI"
      },
      "source": [
        "# Multi layer Pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2j5lknKLxv9"
      },
      "source": [
        "surgeon = Surgeon(model)\n",
        "#getting all the convolution layer and storing the weight tensors\n",
        "layer1 = model.layers[1]\n",
        "layer2 = model.layers[2]\n",
        "layer4 = model.layers[4]\n",
        "layer5 = model.layers[5]\n",
        "layer7 = model.layers[7]\n",
        "layer8 = model.layers[8]\n",
        "layer9 = model.layers[9]\n",
        "layer11= model.layers[11]\n",
        "layer12= model.layers[12]\n",
        "layer13 = model.layers[13]\n",
        "layer15 =model.layers[15]\n",
        "layer16 =model.layers[16]\n",
        "layer17 =model.layers[17]\n",
        "\n",
        "layer1_weights = layer1.get_weights()\n",
        "layer2_weights = layer2.get_weights()\n",
        "layer4_weights = layer4.get_weights()\n",
        "layer5_weights = layer5.get_weights()\n",
        "layer7_weights = layer7.get_weights()\n",
        "layer8_weights = layer8.get_weights()\n",
        "layer9_weights = layer9.get_weights()\n",
        "layer11_weights = layer11.get_weights()\n",
        "layer12_weights = layer12.get_weights()\n",
        "layer13_weights = layer13.get_weights()\n",
        "layer15_weights = layer15.get_weights()\n",
        "layer16_weights = layer16.get_weights()\n",
        "layer17_weights = layer17.get_weights()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBVjFqSgS9GP"
      },
      "source": [
        "conv_layer_weights=[layer1_weights,layer2_weights,layer4_weights,layer5_weights,layer7_weights,layer8_weights,layer9_weights,layer11_weights,layer12_weights,layer13_weights,layer15_weights,layer16_weights,layer17_weights]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBRyx7WznhFs",
        "outputId": "0e5e765e-d17f-4802-fbf4-117f79400b93"
      },
      "source": [
        "#rate of deletion\n",
        "r=0.13\n",
        "num_del_layer_wise=[0]*13#initialisation of list which will keep how many channels has to be delete at each layer\n",
        "num_del_layer_wise"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iH3ZxSXTdPS",
        "outputId": "cd15c6f3-bda8-4c4a-b882-af0145ddd6b0"
      },
      "source": [
        "weights_dic_sort=[[],[],[],[],[],[],[],[],[],[],[],[],[]]\n",
        "import numpy as np\n",
        "for i in range(len(conv_layer_weights)):#iterating over each conv layer\n",
        "  weight=conv_layer_weights[i]\n",
        "  weights_dic={}\n",
        "  num_filters=len(weight[0][0][0])#getting number of channels\n",
        "  if i!=0:\n",
        "     num_del_layer_wise[i]=round(num_filters*r)#getting number of channels deleted at each layer\n",
        "  print(num_filters)\n",
        "\n",
        "  for j in range(num_filters):#iterating over each channels and finding the L2-Norm\n",
        "    arr=np.square(weight[0][0][0][j])\n",
        "    w_s=np.sum(arr)\n",
        "    w_s=w_s/9\n",
        "    filt=j #'filt_{}'.format(j)\n",
        "    weights_dic[filt]=w_s#storing L2-Norm of each channel\n",
        "\n",
        "  weights_dic_sort[i]=sorted(weights_dic.items(),key=lambda kv: kv[1])\n",
        "  print(\"L2 norm of conv_layer{}\\n\".format(i+1),weights_dic_sort[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "L2 norm of conv_layer1\n",
            " [(0, 0.24198773172166613), (2, 0.30829652150472003), (1, 0.35901959737141925)]\n",
            "64\n",
            "L2 norm of conv_layer2\n",
            " [(24, 0.0013315817341208458), (32, 0.003077487357788616), (40, 0.0034466187159220376), (29, 0.0036323455472787223), (55, 0.0036865133378240797), (2, 0.003937005168861813), (17, 0.003938651747173733), (38, 0.004155619276894463), (50, 0.004385071496168773), (6, 0.004532900121476915), (52, 0.004538122150633071), (44, 0.004670798364612792), (13, 0.004926790793736775), (9, 0.0050536783205138314), (11, 0.005262661311361525), (56, 0.005291312105125851), (36, 0.005295662416352166), (1, 0.005736995488405228), (22, 0.005856642292605506), (30, 0.006014215035570992), (27, 0.0060821543965074755), (39, 0.00614686475859748), (7, 0.006147119320101208), (42, 0.006453887455993229), (33, 0.006731046984593074), (46, 0.006868792904747857), (16, 0.007097007499800788), (19, 0.007155751188596089), (25, 0.007429348925749461), (15, 0.007786340183681912), (20, 0.008381515741348267), (53, 0.008598913749059042), (4, 0.008905539082156287), (54, 0.009454314079549577), (48, 0.009695995185110304), (18, 0.009717544747723473), (59, 0.010541866223017374), (61, 0.011421297987302145), (57, 0.01145376099480523), (5, 0.011697758403089311), (21, 0.01187549697028266), (49, 0.012053107221921286), (43, 0.01244408306148317), (60, 0.01352522936132219), (23, 0.01352626747555203), (8, 0.013715049458874596), (35, 0.013898094495137533), (41, 0.015151000685162015), (12, 0.0175114158127043), (63, 0.017569306823942397), (47, 0.018062303463617962), (3, 0.01828311218155755), (14, 0.01836154858271281), (28, 0.01865945922003852), (34, 0.01902946001953549), (58, 0.019334910644425288), (31, 0.019385006692674425), (26, 0.01996537380748325), (37, 0.020764384004804824), (0, 0.021099739604526095), (62, 0.022179240981737774), (51, 0.02442577812406752), (45, 0.02750461631351047), (10, 0.029434031910366483)]\n",
            "64\n",
            "L2 norm of conv_layer3\n",
            " [(14, 0.002062475722697046), (22, 0.0029284575333197913), (9, 0.003174619128306707), (36, 0.0033445627325110966), (21, 0.0037939676807986367), (38, 0.003848741865820355), (23, 0.004763361480500963), (8, 0.005021059678660499), (48, 0.005050931953721576), (39, 0.005370148354106479), (43, 0.005662387443913354), (11, 0.006224813560644786), (54, 0.006369056387080086), (42, 0.006433750192324321), (12, 0.006498762302928501), (51, 0.0074185894595252145), (25, 0.007877735628022088), (6, 0.007902277840508355), (57, 0.008171361353662279), (44, 0.008545421891742282), (34, 0.00858636200428009), (16, 0.008620496425363753), (56, 0.00867002291811837), (4, 0.008824509878953299), (59, 0.009999324050214555), (62, 0.010113029016388787), (1, 0.010832134220335219), (5, 0.010948200192716386), (28, 0.01119675487279892), (50, 0.011246654722425673), (46, 0.011636864807870653), (32, 0.011848927372031741), (31, 0.011853420899973975), (30, 0.012207922008302476), (7, 0.012457973427242704), (58, 0.012476694252755906), (17, 0.012993009554015266), (53, 0.013046943479114108), (40, 0.013063858780595992), (0, 0.01336267093817393), (26, 0.013502134217156304), (35, 0.01356470998790529), (55, 0.013728110326661004), (47, 0.013833172619342804), (61, 0.013944440417819552), (63, 0.013946364323298136), (41, 0.014084421926074557), (20, 0.014513581991195679), (15, 0.01625029080443912), (37, 0.01643733845816718), (3, 0.01657997237311469), (13, 0.017332737644513447), (29, 0.017704615990320843), (33, 0.018206394380993314), (10, 0.01870156659020318), (19, 0.02038125197092692), (24, 0.02040625446372562), (49, 0.022829044196340773), (2, 0.024491548538208008), (60, 0.030624621444278292), (27, 0.03253674507141113), (52, 0.03523754080136617), (45, 0.045508639680014715), (18, 0.048350632190704346)]\n",
            "128\n",
            "L2 norm of conv_layer4\n",
            " [(43, 6.286170618194673e-05), (69, 0.00035632564686238766), (123, 0.00039671956458025507), (0, 0.0010868039809995228), (49, 0.0012226545562346776), (27, 0.0015026376479201848), (89, 0.0017015053373244074), (77, 0.0017421299384699927), (1, 0.0018933763106664021), (92, 0.0019025757080978816), (121, 0.0019509740587737826), (115, 0.0019715995424323613), (124, 0.0020089964899751875), (53, 0.0021160872032245), (100, 0.002143578396903144), (74, 0.0022504275871647727), (39, 0.0023574369649092355), (67, 0.0024186575578318704), (118, 0.0025026069747077096), (108, 0.0027194716450240877), (105, 0.002722690709763103), (2, 0.0027547598712974125), (31, 0.0027751103043556213), (50, 0.0027783337152666515), (35, 0.0028570894565847185), (28, 0.002893896773457527), (91, 0.002924431943231159), (68, 0.002963336391581429), (57, 0.0030718553397390577), (13, 0.0031310729682445526), (94, 0.003291110404663616), (62, 0.003441674013932546), (40, 0.003471442394786411), (84, 0.0035119429230690002), (95, 0.003516371879312727), (60, 0.003545422520902422), (51, 0.0035694175296359593), (90, 0.003591783344745636), (10, 0.003731243312358856), (106, 0.0037384749286704594), (52, 0.003805966013007694), (87, 0.0038974032633834416), (119, 0.003950178209278319), (63, 0.00399373471736908), (120, 0.004055451187822554), (112, 0.004207006345192592), (38, 0.004391779916154014), (22, 0.004414374629656474), (98, 0.004818047914240096), (11, 0.004967331058449215), (81, 0.004992264840337966), (93, 0.005001530879073673), (34, 0.005574347658289803), (126, 0.005577056772179074), (101, 0.005652652432521184), (113, 0.005714198781384362), (6, 0.005832726342810525), (19, 0.006058190431859758), (85, 0.006101581785413954), (9, 0.006105199456214905), (79, 0.006112703846560584), (117, 0.0061256082521544564), (58, 0.006182389126883613), (75, 0.0062491268747382695), (29, 0.006304972701602512), (127, 0.0063180699944496155), (99, 0.00661030908425649), (37, 0.006739937596850925), (111, 0.006958699888653225), (5, 0.007046818733215332), (61, 0.007056141065226661), (25, 0.007119218508402507), (8, 0.007120600177182091), (36, 0.0074931300348705715), (110, 0.007641038960880703), (47, 0.007663579450713264), (59, 0.007844979564348856), (45, 0.007972841461499533), (23, 0.008077365656693777), (14, 0.008318407668007744), (48, 0.008366867899894714), (64, 0.008500069379806519), (96, 0.00850254711177614), (18, 0.008787468075752258), (21, 0.009103828834162818), (44, 0.009112573332256742), (83, 0.00912979907459683), (7, 0.009163471559683481), (55, 0.009238007167975107), (71, 0.009300971196757423), (4, 0.0093285557296541), (15, 0.009601771831512451), (86, 0.009832039475440979), (122, 0.00985495580567254), (104, 0.009914813770188225), (76, 0.010028812620374892), (88, 0.01006168954902225), (33, 0.01008696522977617), (17, 0.010365646746423509), (80, 0.010369166731834412), (16, 0.010558126701249016), (30, 0.010645938416322073), (46, 0.010753335224257575), (66, 0.01081130239698622), (42, 0.010853552983866798), (72, 0.011268417040506998), (78, 0.011388894584443834), (41, 0.011510581605964236), (107, 0.011745189627011618), (103, 0.011905408567852445), (20, 0.01190595163239373), (65, 0.011977075702614255), (116, 0.01205602122677697), (109, 0.01246559288766649), (82, 0.01285759276813931), (102, 0.013274316986401876), (97, 0.01341126196914249), (54, 0.014021413193808662), (24, 0.014680269691679213), (3, 0.014838218688964844), (73, 0.015138962202601962), (26, 0.015568430225054422), (125, 0.01619404885503981), (114, 0.016684903038872614), (32, 0.016904479927486844), (56, 0.017411586311128404), (12, 0.017608559793896146), (70, 0.01772716310289171)]\n",
            "128\n",
            "L2 norm of conv_layer5\n",
            " [(95, 0.0023215264081954956), (64, 0.0024797488003969193), (78, 0.002677514942155944), (60, 0.002867279367314445), (75, 0.003324723078144921), (17, 0.0033768187794420454), (112, 0.0034320385505755744), (50, 0.0034390433381001153), (30, 0.0034409972528616586), (72, 0.003523206545246972), (21, 0.0035866561035315194), (49, 0.0036363336775037977), (73, 0.0037084552976820204), (65, 0.00377378405796157), (107, 0.0038619115948677063), (36, 0.003895588219165802), (71, 0.003914903435442183), (2, 0.003969822906785541), (34, 0.004053108394145966), (98, 0.004072237345907424), (46, 0.004248280078172684), (124, 0.004284231199158562), (79, 0.00429753131336636), (93, 0.004361085179779265), (57, 0.004370540380477905), (43, 0.004391750113831626), (119, 0.004397136469682057), (9, 0.004432763904333115), (106, 0.0044417646196153425), (120, 0.0044469452566570705), (15, 0.004455399596028858), (74, 0.004498692022429572), (89, 0.004503947165277269), (22, 0.0045060333278444074), (32, 0.0045079295006063246), (111, 0.004509455627865261), (70, 0.004605261815918816), (4, 0.004724647435877059), (28, 0.004822793106238048), (62, 0.004890090061558617), (94, 0.004952731231848399), (37, 0.005037219574054082), (84, 0.005095194611284468), (80, 0.005153469741344452), (29, 0.00520399378405677), (69, 0.005258566803402371), (27, 0.005272045731544495), (12, 0.005348155068026649), (47, 0.005436537166436513), (114, 0.005446561922629674), (41, 0.005472573969099257), (20, 0.005482681923442417), (53, 0.005548548367288377), (118, 0.005615047282642788), (44, 0.00563104616271125), (90, 0.0056493692100048065), (88, 0.0056547121041350895), (122, 0.0056709494027826525), (26, 0.005735753724972407), (110, 0.005739205827315648), (121, 0.005886887510617574), (83, 0.005989522569709354), (97, 0.005997213224569957), (91, 0.006005088488260905), (40, 0.006052039149734709), (58, 0.006067380309104919), (35, 0.006085754682620366), (0, 0.006096219023068746), (1, 0.006260597871409522), (109, 0.0064357250101036495), (123, 0.0064438217216067845), (113, 0.006443955418136384), (16, 0.006517479403151406), (59, 0.006558573080433739), (92, 0.006561637338664796), (126, 0.0066645774576399065), (108, 0.006757910880777571), (52, 0.0068075814180903966), (24, 0.006865339974562327), (11, 0.006896678772237565), (33, 0.006906283398469289), (45, 0.007004180716143714), (115, 0.007032722234725952), (77, 0.007051561441686418), (3, 0.007063986526595222), (117, 0.007117094265090095), (76, 0.007170317901505364), (25, 0.007263953487078349), (56, 0.007266708546214634), (55, 0.007286327580610911), (82, 0.007397403319676717), (99, 0.007506704164875878), (87, 0.007634274661540985), (38, 0.007690717776616414), (10, 0.007769126858976152), (85, 0.007806373967064751), (23, 0.007833332651191287), (39, 0.007992547419336107), (51, 0.008015890088346269), (18, 0.008091524243354797), (96, 0.008116898437341055), (67, 0.0081559419631958), (63, 0.008179011444250742), (8, 0.008208375838067796), (48, 0.008222118847899966), (104, 0.008430075314309862), (68, 0.008475882311662039), (61, 0.008535608649253845), (31, 0.008537081380685171), (66, 0.008752154807249704), (7, 0.008867451714144813), (6, 0.008869250615437826), (54, 0.008887178368038602), (86, 0.009082076450188955), (5, 0.009096621639198728), (102, 0.009135004546907213), (103, 0.009757238957617018), (127, 0.00982966853512658), (19, 0.010092837942971123), (81, 0.01024526274866528), (13, 0.010341592133045197), (101, 0.010495810045136346), (14, 0.010661270883348253), (42, 0.01107809692621231), (105, 0.011777992049853006), (116, 0.01212380826473236), (125, 0.01385388606124454), (100, 0.014953462613953484)]\n",
            "256\n",
            "L2 norm of conv_layer6\n",
            " [(149, 0.0010584016434020465), (255, 0.0012041685274905628), (37, 0.0013269330892297956), (44, 0.001364568869272868), (174, 0.0014009279095464284), (171, 0.0014320312895708615), (232, 0.0015380571906765301), (54, 0.0015563347066442172), (243, 0.001574746540023221), (233, 0.0016129448389013608), (82, 0.001632794737815857), (123, 0.0016612890693876478), (110, 0.0016919286507699224), (181, 0.0017443678031365077), (58, 0.0017674167950948079), (64, 0.0017708726227283478), (47, 0.0017728327463070552), (202, 0.0017736943231688605), (61, 0.0017958119925525454), (186, 0.0018041210456026925), (28, 0.0018067384759585063), (102, 0.0018289267188972896), (165, 0.0018477559917502934), (131, 0.0018559988174173567), (57, 0.0019033261471324498), (68, 0.0019459322922759587), (152, 0.001984912488195631), (48, 0.0019914362993505266), (74, 0.002020677551627159), (121, 0.002025346996055709), (96, 0.0020403851651483113), (67, 0.002053012036614948), (137, 0.0020634300178951686), (8, 0.002085437791215049), (13, 0.0020933347857660716), (235, 0.002126876471771134), (139, 0.002138286828994751), (158, 0.0021395335594813028), (136, 0.0021471031424072054), (128, 0.002147700016697248), (134, 0.0021742015249199336), (180, 0.002179047299755944), (125, 0.002197892508573002), (135, 0.002232565234104792), (190, 0.0022700909111234876), (52, 0.0022713562680615317), (120, 0.002274107187986374), (49, 0.0022785055140654245), (167, 0.0022896192967891693), (122, 0.0023158354063828788), (175, 0.0023309505648083156), (92, 0.0023533637738890117), (117, 0.002375996775097317), (108, 0.002383655144108666), (42, 0.002384385714928309), (188, 0.0023987723721398246), (38, 0.0024050559020704692), (71, 0.002406444400548935), (39, 0.0024297309832440484), (147, 0.0024314808348814645), (173, 0.002441536635160446), (185, 0.0024539190861913892), (209, 0.002467576207386123), (237, 0.0024742173651854196), (24, 0.002497987614737617), (16, 0.0025240530570348105), (242, 0.0025321547355916765), (100, 0.002544156379169888), (225, 0.0025599396063221824), (9, 0.0025732871145009995), (81, 0.0025914147910144594), (150, 0.0025929568542374503), (18, 0.0025992641846338906), (198, 0.0026751564194758735), (199, 0.0026784584754043156), (78, 0.002682615899377399), (90, 0.002703875924150149), (6, 0.002723232325580385), (140, 0.0027345193343030084), (234, 0.0027433637943532732), (195, 0.0027477755728695127), (10, 0.002754703164100647), (179, 0.002762275437513987), (177, 0.0027982687784565818), (226, 0.0028039581245846218), (182, 0.002809781167242262), (53, 0.002819347091846996), (192, 0.002838074126177364), (76, 0.0028697355753845638), (21, 0.002875676585568322), (204, 0.0028766306738058725), (93, 0.002899339215623008), (3, 0.002902772691514757), (253, 0.002914323781927427), (249, 0.002932763761944241), (238, 0.0029357564118173388), (218, 0.002940600944889916), (144, 0.0029415651741955015), (63, 0.0030095246103074816), (4, 0.003017623805337482), (1, 0.003023748596509298), (36, 0.003032358984152476), (250, 0.003040790350900756), (201, 0.0030479286279943255), (22, 0.0030601068089405694), (30, 0.0030996248953872258), (51, 0.0031059098740418753), (241, 0.0031110385639799964), (114, 0.0031133186486032275), (29, 0.003186723424328698), (104, 0.00319854107995828), (66, 0.003248991237746345), (161, 0.003249751196967231), (142, 0.003260345094733768), (62, 0.0032621692452165815), (112, 0.0032715811911556455), (196, 0.0033035650849342346), (154, 0.0033111735764476988), (148, 0.0033239656024509007), (229, 0.003368818097644382), (240, 0.0033834634555710685), (83, 0.00339114334848192), (163, 0.00339683269460996), (20, 0.00340744915107886), (178, 0.00340754311117861), (215, 0.003413760413726171), (141, 0.0034200683650043276), (85, 0.0034357313480642107), (159, 0.0034415374199549356), (248, 0.00345028109020657), (217, 0.003450653205315272), (106, 0.0034689054720931584), (164, 0.003472527282105552), (105, 0.003476808468500773), (127, 0.0035052585105101266), (95, 0.003532655123207304), (69, 0.0035374905500147077), (247, 0.003554830120669471), (228, 0.003554946846432156), (124, 0.0035908098022143045), (113, 0.00361311642660035), (208, 0.0036209324995676675), (170, 0.003633201950126224), (251, 0.0036342673831515843), (176, 0.0036449184020360312), (166, 0.0036471825506952074), (223, 0.003650063027938207), (35, 0.003673847350809309), (221, 0.0036799030171500314), (213, 0.0037144141064749826), (230, 0.003732498735189438), (210, 0.0037615771094957986), (23, 0.0037644741435845694), (222, 0.0037815190023846095), (220, 0.0037909352944956887), (111, 0.0038017473287052577), (98, 0.003804971774419149), (89, 0.003806736734178331), (168, 0.0038470116754372916), (146, 0.0038647825519243875), (212, 0.003888801568084293), (118, 0.0038996305730607775), (65, 0.00391651193300883), (169, 0.003916516900062561), (5, 0.003977611660957336), (43, 0.003980251650015513), (207, 0.003984830445713467), (73, 0.003997752649916543), (12, 0.004017188317245907), (19, 0.004039528469244639), (205, 0.004126477572653029), (151, 0.004126831889152527), (33, 0.004134572214550442), (7, 0.004135904212792714), (25, 0.004193995147943497), (126, 0.004222777982552846), (75, 0.004244804382324219), (97, 0.004278574138879776), (216, 0.004304512921306822), (31, 0.004313484662108951), (197, 0.00434627052810457), (46, 0.004413393636544545), (194, 0.004421113265885247), (27, 0.00442280371983846), (236, 0.004424820343653361), (246, 0.004431721236970689), (101, 0.004432431111733119), (72, 0.004444058570596907), (0, 0.004445477906200621), (211, 0.00445624440908432), (94, 0.0044593314329783125), (56, 0.004463738451401393), (26, 0.004506971273157332), (187, 0.004527885880735185), (227, 0.004587145315276252), (70, 0.004625346097681258), (109, 0.004636067897081375), (203, 0.004669654700491164), (129, 0.004693426191806793), (55, 0.004702678985065884), (224, 0.0047071754104561275), (103, 0.0047747902572155), (80, 0.004782325277725856), (87, 0.004785880446434021), (138, 0.004832205673058827), (79, 0.004850110246075524), (59, 0.004851034118069543), (77, 0.00485523458984163), (99, 0.004856524368127187), (172, 0.004857970194684135), (231, 0.004868578165769577), (60, 0.0048787399298614925), (45, 0.004917514406972461), (40, 0.004940481235583623), (206, 0.005052161299520069), (116, 0.0050635747611522675), (34, 0.005066595143742031), (189, 0.005078501171535916), (107, 0.00507913985186153), (119, 0.005155845648712582), (160, 0.005180091079738405), (183, 0.005195582078562843), (239, 0.005248800747924381), (214, 0.005250411315096749), (91, 0.0052879320250617135), (153, 0.005346356166733636), (132, 0.005386914230055279), (88, 0.005397597948710124), (200, 0.00546057853433821), (155, 0.005468141701486375), (244, 0.005481630149814818), (41, 0.005527606854836146), (115, 0.005610644817352295), (245, 0.00572800553507275), (219, 0.00584384302298228), (11, 0.005873601883649826), (86, 0.00588835734460089), (32, 0.005905667940775554), (145, 0.005950109826193916), (130, 0.006091349654727512), (143, 0.006241575711303287), (14, 0.006252702739503648), (17, 0.006373209257920583), (193, 0.006417872591151131), (252, 0.006419123874770271), (184, 0.006490592327382829), (50, 0.006647075215975444), (191, 0.006748163865672218), (157, 0.007080809937583076), (254, 0.007322504288620419), (2, 0.007333353989654117), (133, 0.007384899589750502), (15, 0.007399333847893609), (162, 0.007575380305449168), (156, 0.00782819175057941), (84, 0.009780056774616241)]\n",
            "256\n",
            "L2 norm of conv_layer7\n",
            " [(140, 0.0015460838460259968), (228, 0.0016429902364810307), (94, 0.00176919624209404), (204, 0.0018428551654020946), (170, 0.001868479781680637), (239, 0.0019028644180960124), (106, 0.0019102456669012706), (82, 0.001963922960890664), (29, 0.0020881998870107862), (177, 0.002098497831159168), (245, 0.0021059539996915394), (146, 0.0021218742347425884), (27, 0.0021400530305173662), (104, 0.002143318247463968), (16, 0.0021767140262656743), (217, 0.0021916193266709647), (215, 0.0022183451801538467), (39, 0.0022267351547876992), (237, 0.002253439277410507), (248, 0.002260584384202957), (59, 0.0022706397705607945), (20, 0.002302577512131797), (126, 0.002312391996383667), (32, 0.002320619093047248), (31, 0.002361299677027596), (9, 0.0023709628731012344), (87, 0.002392331138253212), (191, 0.0024006159769164193), (241, 0.002420529309246275), (223, 0.0024288917581240335), (88, 0.0024328266994820703), (187, 0.002452400823434194), (89, 0.0024581530855761636), (176, 0.002464414056804445), (124, 0.00246563491721948), (49, 0.002469681203365326), (51, 0.0024862434301111433), (189, 0.002487136258019341), (214, 0.00248917109436459), (110, 0.002489964167277018), (12, 0.0024899966600868437), (19, 0.0024969354271888733), (63, 0.002502806691659821), (231, 0.0025143704066673913), (69, 0.002537274112304052), (109, 0.0025478442096047932), (103, 0.00256653337015046), (50, 0.0025750346895721224), (197, 0.0025837053027417925), (76, 0.0025981461836232077), (160, 0.0026315670046541425), (212, 0.0026436830974287456), (210, 0.00264809342722098), (254, 0.0026565268635749817), (130, 0.00267117139365938), (38, 0.0026855520490143034), (209, 0.0026863416035970054), (55, 0.0026884774367014566), (90, 0.0026975439654456247), (96, 0.0027495837873882717), (30, 0.0027861499951945413), (1, 0.0028005720426638923), (178, 0.0028201349907451207), (162, 0.0028224274930026797), (25, 0.002841805418332418), (152, 0.0028431672188970777), (42, 0.0028518343137370217), (196, 0.002857547046409713), (221, 0.0029031758507092795), (121, 0.0029155976242489284), (122, 0.002929969173338678), (18, 0.002944001721011268), (249, 0.0029492444462246364), (183, 0.0029493404759301078), (80, 0.0029650754812690946), (220, 0.002965824471579658), (244, 0.0029762950208452013), (207, 0.0029907127221425376), (15, 0.0029934512244330514), (125, 0.002997353259060118), (172, 0.0030104141268465254), (112, 0.003019592207339075), (234, 0.0030247498717572954), (164, 0.0030559589051538045), (208, 0.0030655618757009506), (123, 0.003077001621325811), (144, 0.003087263968255785), (225, 0.0030881748017337588), (136, 0.003099857105149163), (159, 0.0031188002063168418), (118, 0.00312668705979983), (188, 0.0031268795331319175), (194, 0.0031558554619550705), (238, 0.0031580651799837747), (116, 0.0031596782306830087), (235, 0.003189708830581771), (7, 0.00320424594812923), (137, 0.0032268009252018398), (71, 0.0032268501818180084), (253, 0.0032283618218368953), (145, 0.003231054585840967), (98, 0.003231960866186354), (81, 0.00325461911658446), (97, 0.0032585528161790636), (195, 0.0032717943605449465), (66, 0.0032740719616413116), (102, 0.0032865338855319554), (73, 0.003313534375694063), (129, 0.003317943670683437), (24, 0.0033208096606863868), (41, 0.003340332872337765), (167, 0.0033436897728178236), (120, 0.0033520011024342645), (148, 0.003369006638725599), (213, 0.003369806334376335), (3, 0.0033827821413675943), (2, 0.0033838628894752925), (22, 0.0033861102743281257), (226, 0.0033884644508361816), (131, 0.0034345549841721854), (134, 0.0034399823182159), (92, 0.0034413283897770774), (193, 0.003443727476729287), (200, 0.00344468177192741), (192, 0.003475792706012726), (179, 0.0034762099385261536), (52, 0.0034830342564317915), (37, 0.003494551198350059), (251, 0.0034956340160634783), (77, 0.003506893085108863), (95, 0.0035096771187252468), (61, 0.003560514913664924), (67, 0.003588708738485972), (218, 0.003593818181090885), (153, 0.0036402245362599692), (216, 0.0036487244069576263), (227, 0.00365108417140113), (143, 0.0036519914865493774), (138, 0.003663848257727093), (6, 0.0036685835156175825), (44, 0.003672105156713062), (40, 0.003680044578181373), (163, 0.0037189647555351257), (13, 0.0037202350795269012), (99, 0.00373379099700186), (252, 0.003741225020753013), (168, 0.003752610749668545), (151, 0.00375643703672621), (4, 0.003783770733409458), (17, 0.003797913591066996), (119, 0.0038188041912184823), (202, 0.0038392055365774366), (181, 0.003841860426796807), (79, 0.0038602716392940944), (240, 0.003885750969250997), (115, 0.003932046393553416), (255, 0.003947959591945012), (91, 0.003969993442296982), (247, 0.003970110581980811), (211, 0.003971731497181786), (180, 0.003981992602348328), (0, 0.004011123544640011), (84, 0.004021612306435903), (203, 0.004057466983795166), (158, 0.004079370862907833), (54, 0.004080880847242143), (62, 0.004090667598777347), (93, 0.004143845703866746), (114, 0.004149916271368663), (11, 0.004164865447415246), (224, 0.0041663216220008), (135, 0.004194094489018123), (33, 0.004236546655495961), (72, 0.00423948797914717), (150, 0.0042489998870425755), (184, 0.004279822938972049), (74, 0.004294564326604207), (246, 0.00429511277212037), (8, 0.004315512461794747), (142, 0.0043341463638676535), (23, 0.004346256868706809), (219, 0.0043632810314496355), (58, 0.0044151461786694), (53, 0.004416289014948739), (68, 0.0044324008954895865), (26, 0.004433000667227639), (45, 0.0044896366695563), (48, 0.004523923827542199), (10, 0.004523969358868069), (205, 0.004533403449588352), (198, 0.004535648971796036), (132, 0.004538439628150728), (169, 0.004542236526807149), (56, 0.004552231480677922), (156, 0.004620182017485301), (36, 0.00465588519970576), (175, 0.0046594709985786015), (34, 0.004702986942397224), (222, 0.00471210562520557), (182, 0.004725152005751927), (139, 0.004746855133109623), (113, 0.00478403518597285), (75, 0.0048714859618080985), (60, 0.0048950980934831835), (165, 0.0049225592778788674), (233, 0.005039192736148834), (105, 0.005041379481554031), (47, 0.005048672358194987), (155, 0.005058799766831928), (35, 0.005100092126263512), (149, 0.005150376094712151), (85, 0.005238003200954861), (243, 0.00530977381600274), (101, 0.005359354118506114), (186, 0.005368482735421922), (28, 0.005378120475345188), (127, 0.005382237748967277), (21, 0.005410133136643304), (5, 0.005450502451923158), (232, 0.005452391588025623), (242, 0.005461230046219296), (65, 0.00546244697438346), (111, 0.005503403643767039), (64, 0.005519138028224309), (154, 0.005559109151363373), (185, 0.005574362973372142), (206, 0.005652155313226912), (83, 0.005676876339647505), (70, 0.005763904501994451), (161, 0.005821052110857434), (133, 0.005887248863776525), (174, 0.006110505097442203), (147, 0.006197585827774472), (108, 0.006214359982146157), (57, 0.006313944028483497), (173, 0.006341828654209773), (250, 0.006381362676620483), (86, 0.006417172650496165), (46, 0.0064600913061036), (201, 0.00647173242436515), (117, 0.00663640515671836), (199, 0.006734309097131093), (157, 0.006842894272671806), (100, 0.006941189782487022), (78, 0.00695081717438168), (141, 0.007245229350195991), (14, 0.007517377535502116), (236, 0.007638649808035957), (43, 0.008125528693199158), (107, 0.008128886421521505), (230, 0.008315088020430671), (171, 0.008375813563664755), (128, 0.008771488236056434), (190, 0.009029991096920438), (166, 0.0091809771127171), (229, 0.010505398942364587)]\n",
            "256\n",
            "L2 norm of conv_layer8\n",
            " [(129, 0.002573261244429482), (218, 0.0026198472413751814), (142, 0.00275567298134168), (107, 0.0027877361410193974), (39, 0.002810380318098598), (12, 0.0028720953398280675), (247, 0.002873118966817856), (73, 0.002884649568133884), (81, 0.0028876569122076035), (33, 0.0029138268695937265), (0, 0.003004384537537893), (131, 0.00303942503200637), (192, 0.003047482834921943), (214, 0.0030857231467962265), (106, 0.0030972734093666077), (69, 0.0030989876637856164), (160, 0.0031011230829689237), (190, 0.00310943979356024), (28, 0.003114309161901474), (150, 0.0031233597546815872), (182, 0.0031381241149372524), (71, 0.0031634829938411713), (222, 0.0031993364294370017), (68, 0.00322521829770671), (4, 0.0032369537899891534), (65, 0.003292271246512731), (53, 0.003315804733170403), (208, 0.0033191990935140187), (248, 0.003323667993148168), (195, 0.003341597608394093), (254, 0.0033640203376611075), (111, 0.003371145162317488), (118, 0.003392768402894338), (210, 0.003404218082626661), (3, 0.0034217143224345315), (225, 0.0034404022412167657), (235, 0.0034534970505370032), (62, 0.003463905718591478), (188, 0.0034935797254244485), (48, 0.003521705667177836), (94, 0.0035389777686860827), (228, 0.003562284012635549), (242, 0.003582336422469881), (127, 0.0035839656160937417), (36, 0.003588793178399404), (114, 0.003600127167171902), (193, 0.0036353940765062966), (249, 0.003661110583278868), (49, 0.0037045669224527148), (52, 0.0037138722836971283), (206, 0.003727688557571835), (10, 0.0037296112212869856), (237, 0.0037423090802298654), (217, 0.0037558356093035806), (155, 0.003811375548442205), (238, 0.0038162701659732396), (40, 0.0038221507436699336), (178, 0.0038237435122330985), (57, 0.003828502363628811), (43, 0.0038290839228365156), (115, 0.0038345265719625684), (159, 0.0038440583480728995), (24, 0.003847944653696484), (70, 0.00386839649743504), (86, 0.003877737455897861), (252, 0.0038801303340329062), (56, 0.0038985717627737257), (104, 0.00393020941151513), (92, 0.00394520577457216), (47, 0.003954332735803392), (88, 0.003966172536214192), (243, 0.00396922810210122), (45, 0.003987729549407959), (126, 0.003993307964669334), (17, 0.004005311677853267), (224, 0.004008397459983826), (20, 0.004054765734407637), (202, 0.004060126013225979), (21, 0.00406822810570399), (42, 0.004072394635942247), (59, 0.004078698654969533), (196, 0.00409235805273056), (145, 0.004131716986497243), (223, 0.00414760990275277), (172, 0.004155315458774567), (137, 0.004158876422378752), (76, 0.004171458383401235), (135, 0.004186747802628411), (132, 0.004206050601270463), (219, 0.004218334125147926), (55, 0.004255038996537526), (37, 0.004273956848515404), (120, 0.004311001549164454), (14, 0.004316349824269612), (174, 0.0043232859008842045), (148, 0.004323929962184694), (96, 0.004342522472143173), (87, 0.0043470097912682425), (158, 0.004355500141779582), (205, 0.004357956349849701), (184, 0.004373468458652496), (173, 0.004376318719651964), (255, 0.004376532302962409), (35, 0.004379422300391727), (170, 0.004380433509747188), (165, 0.004383191466331482), (227, 0.004385601315233443), (64, 0.004391921891106499), (78, 0.00441173298491372), (99, 0.004416509220997493), (82, 0.004458949383762147), (151, 0.004496324807405472), (83, 0.004501991801791721), (58, 0.004504000561104881), (199, 0.004513310061560737), (110, 0.004526638322406345), (169, 0.00452700008948644), (209, 0.00453731334871716), (77, 0.004572825713290108), (103, 0.004581715497705672), (112, 0.00458187030421363), (250, 0.004596882810195287), (13, 0.004598303387562434), (133, 0.004605397995975282), (31, 0.004626616421673033), (200, 0.00466860251294242), (179, 0.004675084518061744), (121, 0.004711905287371742), (226, 0.00472224172618654), (51, 0.004746139463451173), (185, 0.0047588033808602225), (244, 0.004784434205955929), (144, 0.004795326126946343), (156, 0.004798141204648548), (241, 0.004801313910219405), (176, 0.00485405284497473), (67, 0.00487337095869912), (134, 0.004881518168581856), (201, 0.004910060101085239), (102, 0.004920711119969686), (109, 0.004921812978055742), (119, 0.004964152144061195), (105, 0.004988000624709659), (1, 0.00500745822985967), (29, 0.005008331603474087), (246, 0.005013309005233977), (194, 0.005014981660577986), (212, 0.00504517803589503), (230, 0.005047745174831814), (117, 0.005067424641715156), (108, 0.005068025241295497), (253, 0.005068884127669864), (191, 0.00507005179921786), (113, 0.0051021286182933384), (211, 0.005111217498779297), (90, 0.00512081053521898), (167, 0.005135801103379991), (149, 0.005165395637353261), (72, 0.005165420886543062), (251, 0.005173464202218586), (97, 0.005190042985810174), (6, 0.005200963881280687), (2, 0.0052210431959893965), (50, 0.005244409872425927), (32, 0.005297729952467812), (16, 0.005302106754647361), (34, 0.005302686658170488), (27, 0.005310735768742031), (240, 0.005316122538513607), (15, 0.005337936182816823), (41, 0.005356850723425548), (215, 0.005366177194648319), (91, 0.005374826076957915), (183, 0.005416816307438744), (130, 0.005425685809718238), (204, 0.0054542215334044564), (168, 0.005488277309470707), (207, 0.005495025879806942), (164, 0.005506484872765011), (175, 0.0055537935760286115), (116, 0.005576604770289527), (221, 0.0055893270505799186), (101, 0.00559401594930225), (30, 0.005629223253991868), (157, 0.005652866429752774), (180, 0.005658996187978321), (181, 0.005667513029442893), (234, 0.005685968945423762), (80, 0.005705706775188446), (163, 0.005710418025652568), (44, 0.00572379802664121), (23, 0.0057243841389815016), (146, 0.005729398793644375), (147, 0.005733725511365467), (100, 0.00578141709168752), (75, 0.005795131127039592), (124, 0.0057982707189189065), (74, 0.005820670475562413), (161, 0.005825757152504391), (186, 0.005863869355784522), (189, 0.005867790016863082), (7, 0.0058718712793456185), (122, 0.005878000623650021), (123, 0.005922539366616143), (128, 0.005932917197545369), (166, 0.005962201290660434), (197, 0.006013806495401595), (25, 0.006021236379941304), (139, 0.006042912602424622), (239, 0.006120146976576911), (140, 0.006128130273686515), (9, 0.006163286666075389), (231, 0.006258843673600091), (125, 0.006264536745018429), (5, 0.006281693776448567), (46, 0.006355644100242191), (162, 0.006374206807878282), (26, 0.0064512934121820666), (18, 0.006543195909923977), (61, 0.006555274542835023), (98, 0.006761332352956136), (60, 0.006763194170263078), (8, 0.006859545906384786), (95, 0.00689115251104037), (233, 0.006974221103721195), (89, 0.007013951738675435), (143, 0.007082212302419875), (245, 0.00712457795937856), (229, 0.0071559374531110125), (85, 0.007173672318458557), (38, 0.007183167669508193), (11, 0.007188788718647427), (141, 0.007258085740937127), (171, 0.007308844890859392), (203, 0.007453334000375535), (220, 0.007538557880454593), (187, 0.00763426058822208), (216, 0.007738676336076524), (54, 0.007767444683445824), (232, 0.007771303256352742), (79, 0.007798574037022061), (63, 0.008022492130597433), (84, 0.008109307123555077), (213, 0.008171812527709536), (138, 0.008284472756915622), (22, 0.008458604415257772), (19, 0.009655912717183432), (198, 0.009742570420106253), (154, 0.009794196320904626), (66, 0.009907354911168417), (153, 0.010337709552711911), (93, 0.010704379942682054), (136, 0.010745243065887027), (152, 0.010825544595718384), (177, 0.01255907780594296), (236, 0.013148377339045206)]\n",
            "512\n",
            "L2 norm of conv_layer9\n",
            " [(351, 0.0017058576146761577), (362, 0.0017132658718360795), (40, 0.0017393678426742554), (333, 0.001776026768816842), (388, 0.001815246625079049), (364, 0.0018311476127968894), (329, 0.001860664122634464), (54, 0.0018607071704334682), (137, 0.0018730353977945116), (358, 0.0018781957527001698), (295, 0.001907395405901803), (471, 0.001912237869368659), (186, 0.0019194742457734214), (50, 0.0019315005176597172), (328, 0.0019397878398497899), (38, 0.0019444732202423944), (176, 0.0019497674786382252), (131, 0.0019547444664769703), (217, 0.0019755750480625364), (481, 0.0019816371301809945), (164, 0.001985198507706324), (76, 0.002019029524591234), (215, 0.002019073193271955), (286, 0.0020332872453663084), (335, 0.0020385686722066668), (422, 0.002039034747415119), (419, 0.002041070204642084), (8, 0.0020451901687516105), (255, 0.002053417679336336), (207, 0.0020602885633707047), (318, 0.0020622573792934418), (26, 0.0020634372615151936), (377, 0.0020652485804425347), (261, 0.0020692462308539283), (459, 0.0020848603712187875), (21, 0.002088433959417873), (80, 0.0020958251423305934), (253, 0.0020994188057051767), (247, 0.0020998037523693508), (284, 0.0021011419594287872), (432, 0.002102724173002773), (274, 0.002109040402703815), (225, 0.002117020388444265), (154, 0.0021217955897251763), (218, 0.002126069739460945), (98, 0.002129638981488016), (371, 0.0021356013086107043), (396, 0.00213735302289327), (382, 0.002148021219505204), (159, 0.0021520577785041598), (460, 0.0021538386742273965), (455, 0.00216097053554323), (509, 0.002161579206585884), (360, 0.002164230371514956), (262, 0.002167454610268275), (15, 0.002167648325363795), (118, 0.0021698292758729723), (273, 0.002179393751753701), (392, 0.002180003457599216), (339, 0.002185101724333233), (27, 0.0021901076866520774), (420, 0.002194685654507743), (10, 0.002202913992934757), (506, 0.0022060113648573556), (457, 0.002207753765914175), (488, 0.002212568289703793), (469, 0.002212924054927296), (415, 0.0022164032691054875), (239, 0.002217846612135569), (504, 0.002222747024562624), (331, 0.002223944498433007), (370, 0.0022477242681715223), (219, 0.00224940354625384), (324, 0.002252645583616363), (122, 0.002252744303809272), (168, 0.002258252145515548), (96, 0.002265102126532131), (110, 0.0022659864690568713), (109, 0.0022787368959850734), (363, 0.0022796615958213806), (198, 0.0022812996887498433), (4, 0.002295874473121431), (272, 0.00230319384071562), (202, 0.0023034819298320347), (297, 0.002312194142076704), (46, 0.002313197279969851), (205, 0.0023166899465852315), (181, 0.0023232288658618927), (355, 0.0023232725345426137), (151, 0.0023257722043328816), (104, 0.002327976334426138), (9, 0.0023311397267712485), (497, 0.0023320685658189985), (16, 0.0023327573306030696), (293, 0.00234504747721884), (304, 0.002347134053707123), (252, 0.0023599227683411706), (495, 0.0023615211248397827), (294, 0.0023641888466146258), (246, 0.0023642703890800476), (383, 0.0023711402383115557), (271, 0.0023723464045259687), (140, 0.0023806972636116874), (498, 0.002385732200410631), (41, 0.002385903149843216), (309, 0.0023928704775042003), (158, 0.0023943668024407495), (290, 0.0024044900718662473), (144, 0.002408642735746172), (156, 0.0024099089205265045), (92, 0.002410066003600756), (353, 0.0024133328762319353), (359, 0.0024168617609474394), (108, 0.002417331354485618), (167, 0.0024189170863893297), (307, 0.0024202830261654323), (316, 0.002421830263402727), (171, 0.0024236668315198687), (395, 0.0024283925692240396), (99, 0.0024315081536769867), (180, 0.0024334206763241026), (356, 0.002433442407184177), (283, 0.0024340798457463584), (33, 0.002436423053344091), (73, 0.0024374164640903473), (340, 0.0024385121133592394), (406, 0.0024408851232793597), (275, 0.002443229158719381), (31, 0.0024449266493320465), (242, 0.002447116706106398), (121, 0.0024494013438622155), (462, 0.002452218077248997), (64, 0.00245769363310602), (263, 0.002461166638467047), (49, 0.002467603319221073), (150, 0.0024683301647504172), (57, 0.002471750188204977), (494, 0.0024724346068170336), (129, 0.0024760483453671136), (231, 0.0024849192963706124), (350, 0.0024861515396171147), (323, 0.0024896996716658273), (221, 0.0024904865357610914), (510, 0.0024923812597990036), (234, 0.0024942681193351746), (312, 0.002494693630271488), (437, 0.0024962926076518167), (160, 0.0024986974895000458), (62, 0.0025021077858077157), (94, 0.002504918724298477), (489, 0.0025056679215696123), (182, 0.0025096620536512798), (315, 0.0025124349113967684), (464, 0.002512924787071016), (366, 0.002513206253449122), (440, 0.002515550288889143), (480, 0.002528506020704905), (128, 0.002530693593952391), (65, 0.002531999929083718), (439, 0.002534466485182444), (161, 0.0025380317949586445), (116, 0.0025405180123117235), (306, 0.0025410817729102243), (265, 0.0025458348294099173), (426, 0.002551715614067184), (314, 0.0025539259529776042), (361, 0.0025542800625165305), (183, 0.0025553537739647757), (175, 0.0025556273758411407), (397, 0.002555989349881808), (201, 0.002556535932752821), (418, 0.002559783144129647), (508, 0.0025625398589505088), (429, 0.0025677242212825352), (278, 0.0025724160174528756), (236, 0.0025765078349245917), (206, 0.002579269309838613), (134, 0.002586791498793496), (119, 0.0025954002307520974), (53, 0.0025970240434010825), (19, 0.0025972887459728452), (243, 0.0026014598293436896), (77, 0.002602384322219425), (458, 0.002603634777996275), (478, 0.002603866159915924), (254, 0.0026048868894577026), (34, 0.0026103154652648503), (482, 0.0026180214352077907), (143, 0.0026271724038653905), (17, 0.0026323613193300036), (170, 0.002639082363910145), (69, 0.0026403023964828914), (178, 0.002646891193257438), (405, 0.0026480998429987165), (332, 0.0026483960035774442), (14, 0.002649996222721206), (190, 0.002654322940442297), (387, 0.0026546836727195317), (184, 0.0026636229207118354), (391, 0.0026642800205283696), (58, 0.0026655281997389263), (136, 0.0026681388003958594), (336, 0.0026746096296442878), (244, 0.002678681785861651), (209, 0.0026810127827856275), (436, 0.0026867646310064527), (43, 0.002687183933125602), (200, 0.002692903909418318), (20, 0.0027063594510157904), (222, 0.0027070438696278464), (349, 0.0027087926864624023), (146, 0.0027167312800884247), (322, 0.002716810339026981), (197, 0.0027215112414624956), (477, 0.0027263924065563413), (374, 0.0027277006043328177), (410, 0.0027285096132093007), (85, 0.002731494191620085), (35, 0.002736170465747515), (233, 0.002738306505812539), (424, 0.002739579106370608), (502, 0.0027408674359321594), (248, 0.0027425742397705712), (103, 0.0027526033421357474), (256, 0.002758401549524731), (84, 0.0027588469286759696), (173, 0.0027596130967140198), (149, 0.0027601151830620235), (71, 0.0027662134832806056), (320, 0.002769686074720489), (162, 0.0027755842440658146), (321, 0.002778473206692272), (368, 0.0027785425384839377), (42, 0.002780862980418735), (216, 0.0027812483410040536), (25, 0.0027818909535805383), (269, 0.0027824238770537907), (196, 0.0027849769426716697), (438, 0.002786563295457098), (78, 0.002787782293226984), (372, 0.0027986055033074487), (189, 0.0027994405892160204), (223, 0.0028023657699426017), (91, 0.002804972438348664), (452, 0.0028068131456772485), (192, 0.0028129685670137405), (281, 0.0028155214256710475), (193, 0.0028182913859685263), (400, 0.00281919642455048), (228, 0.002822563880019718), (503, 0.0028231321937508052), (245, 0.0028254236612055036), (292, 0.0028266463842656878), (327, 0.0028269092241923013), (240, 0.0028289974563651616), (453, 0.0028305831882688734), (60, 0.002831551970707046), (138, 0.002833888762527042), (68, 0.0028406737579239737), (490, 0.0028407772382100425), (373, 0.0028411073403226007), (385, 0.0028424211260345248), (125, 0.002843338582250807), (484, 0.0028436105284425947), (298, 0.002845363070567449), (213, 0.0028469405240482753), (451, 0.002850087152587043), (163, 0.002852926237715615), (81, 0.0028530415147542953), (475, 0.002854062037335502), (270, 0.0028582877582973903), (301, 0.002859530763493644), (456, 0.002860764662424723), (32, 0.002868346869945526), (6, 0.0028717584080166286), (348, 0.002880862603584925), (326, 0.0028875679191615847), (430, 0.002888797471920649), (431, 0.0028934338026576573), (0, 0.0028970541639460456), (95, 0.002897233184840944), (123, 0.0028999226374758613), (496, 0.0029078732348150676), (266, 0.0029247477650642395), (434, 0.0029362404925955665), (204, 0.002936956783135732), (212, 0.002938211378124025), (472, 0.0029396783146593305), (468, 0.0029512981159819495), (287, 0.0029575911660989127), (47, 0.002958483166164822), (446, 0.0029616521464453805), (492, 0.002970222383737564), (185, 0.0029741227626800537), (299, 0.0029756948351860046), (311, 0.002976741227838728), (30, 0.0029771429383092457), (199, 0.002981116788254844), (155, 0.002986110953821076), (142, 0.002992744661039776), (179, 0.0029969732794496748), (344, 0.0030009299516677856), (399, 0.0030036469300587973), (291, 0.0030164021170801586), (3, 0.003018786923752891), (325, 0.0030293516400787565), (493, 0.00303739495575428), (165, 0.003045101546578937), (414, 0.00304883180393113), (97, 0.003060254371828503), (444, 0.003066804880897204), (172, 0.0030752610829141405), (249, 0.0030898327628771463), (403, 0.003092508763074875), (341, 0.003098919987678528), (70, 0.0031052488419744703), (346, 0.0031055348614851632), (259, 0.003111075609922409), (120, 0.0031123438643084634), (448, 0.0031196255650785235), (473, 0.0031284085578388637), (369, 0.0031399490932623544), (208, 0.003153562131855223), (296, 0.0031613146679268945), (29, 0.0031671010785632664), (476, 0.0031717351327339807), (177, 0.0031758536481195027), (7, 0.003176053985953331), (226, 0.0031785331666469574), (260, 0.0031787074274486965), (13, 0.0031935109032524955), (319, 0.0031992108043697146), (483, 0.003201045509841707), (227, 0.0032122207598553765), (23, 0.003215684038069513), (86, 0.003217879061897596), (2, 0.0032301992177963257), (36, 0.00323500567012363), (229, 0.0032382185260454812), (402, 0.0032415826701455647), (139, 0.003247887310054567), (303, 0.003247949191265636), (416, 0.003248982545402315), (342, 0.0032510078615612453), (24, 0.003257900062534544), (479, 0.0032592061907052994), (338, 0.003282402124669817), (501, 0.003286586039596134), (141, 0.0033101367039812934), (5, 0.003320150077342987), (126, 0.0033220892979039084), (317, 0.0033264776898754966), (487, 0.0033271275460720062), (280, 0.003328940520683924), (214, 0.0033314997951189675), (276, 0.0033368213723103204), (379, 0.003339078484310044), (55, 0.003339398445354568), (88, 0.0033502199997504554), (235, 0.0033589237266116673), (300, 0.003360062837600708), (463, 0.0033612919764386285), (267, 0.0033649251692824894), (174, 0.003367112949490547), (378, 0.0033725036515129935), (111, 0.0033842788802252877), (423, 0.0033897004193729824), (365, 0.003400451193253199), (210, 0.00341056018239922), (417, 0.003412123355600569), (354, 0.0034168532325161826), (264, 0.003438803263836437), (305, 0.0034411483340793187), (289, 0.0034710499975416395), (345, 0.0034875464108255175), (404, 0.0034907253252135385), (390, 0.003494648055897819), (93, 0.003499569578303231), (44, 0.0035109023253122964), (357, 0.0035158180528216893), (470, 0.0035171707471211753), (375, 0.00351842161681917), (112, 0.003528746465841929), (102, 0.00353717886739307), (166, 0.0035374541249540118), (407, 0.003543094214465883), (101, 0.0035457656615310246), (230, 0.003553430653280682), (408, 0.003554588390721215), (288, 0.003575963278611501), (330, 0.0035796004037062326), (465, 0.003583167162206438), (37, 0.0035885940823290083), (51, 0.003603782918718126), (435, 0.003614644209543864), (250, 0.0036172974440786573), (384, 0.0036452652679549325), (449, 0.003653396334913042), (220, 0.003665209644370609), (398, 0.0036788342727555167), (132, 0.0036793177326520285), (343, 0.0036844064791997275), (409, 0.0036904141306877136), (115, 0.0037047341465950012), (313, 0.0037147444155481127), (1, 0.0037450575166278416), (454, 0.003753090484274758), (450, 0.0037597931093639797), (106, 0.0037620034482744005), (302, 0.0037718332476086086), (499, 0.003780694885386361), (195, 0.0037834925784005057), (427, 0.003798914866314994), (194, 0.0038070455193519592), (380, 0.0038423314690589905), (491, 0.0038534079988797507), (187, 0.003903364141782125), (39, 0.003915964315334956), (376, 0.003949413696924846), (474, 0.003959173957506816), (428, 0.00396117443839709), (507, 0.0039642614622910815), (45, 0.003964641855822669), (224, 0.003986394239796532), (485, 0.003991175029012892), (421, 0.004015237092971802), (148, 0.0040202149086528355), (442, 0.004025688601864709), (211, 0.004030692080656688), (191, 0.004045893748601277), (74, 0.004049488653739293), (347, 0.004050912956396739), (282, 0.004086524662044313), (48, 0.004143110579914517), (411, 0.004146282871564229), (67, 0.004156307213836246), (188, 0.004161307381259071), (367, 0.0041706230905320905), (135, 0.00418920980559455), (466, 0.00423178697625796), (145, 0.004279062979751163), (500, 0.004282260106669532), (157, 0.004304576251241896), (153, 0.00431108930044704), (66, 0.004313129517767165), (59, 0.004355439709292518), (279, 0.00437201311190923), (486, 0.004395882288614909), (268, 0.00440833427839809), (113, 0.004451339443524678), (310, 0.004459181593524085), (334, 0.0044661156005329555), (100, 0.00447591890891393), (152, 0.004499414728747474), (238, 0.004514096097813712), (401, 0.004519795378049214), (412, 0.004523497488763597), (75, 0.0045662617517842185), (12, 0.004579451349046495), (133, 0.004605761832661099), (72, 0.00461598320139779), (505, 0.004619133141305711), (447, 0.004623129963874817), (258, 0.004705095870627297), (107, 0.004732863770590888), (308, 0.004763265864716636), (393, 0.004770556257830726), (251, 0.004794526431295607), (79, 0.004800272484620412), (394, 0.0048085591859287685), (11, 0.004848969479401906), (232, 0.004864227440622117), (63, 0.004955701529979706), (461, 0.004967309948470857), (147, 0.004990128179391225), (18, 0.005009593235121833), (90, 0.005010474887159135), (443, 0.005026102893882328), (277, 0.005037782920731438), (56, 0.005052507751517826), (105, 0.005055644445949131), (114, 0.005111842933628295), (83, 0.005150584297047721), (381, 0.0051766580177678), (237, 0.0052387093504269915), (169, 0.005254554251829783), (87, 0.005274071461624569), (203, 0.005274126927057902), (337, 0.005373280909326341), (28, 0.005502066678471035), (82, 0.005544716699255837), (61, 0.0055860694911744856), (389, 0.0055870624879995985), (124, 0.005668082584937413), (285, 0.00573268946674135), (413, 0.005766746484571033), (130, 0.005775316721863217), (257, 0.00617816299200058), (22, 0.006342327843109767), (52, 0.006364409294393327), (425, 0.006403500007258521), (386, 0.006508462544944551), (241, 0.006596078061395221), (445, 0.006816966666115655), (352, 0.006885100569989946), (89, 0.00700077580081092), (117, 0.007028283344374763), (511, 0.007286182708210415), (433, 0.007322776648733351), (467, 0.007476804984940423), (127, 0.008324111501375834), (441, 0.009377303222815195)]\n",
            "512\n",
            "L2 norm of conv_layer10\n",
            " [(195, 0.00195110941098796), (377, 0.001956076050798098), (396, 0.0019658178918891484), (379, 0.0019658305164840487), (13, 0.0020744560493363273), (505, 0.0020898357033729553), (459, 0.002105549391773012), (461, 0.0021079882151550716), (380, 0.0021600487331549325), (448, 0.0021643986304601035), (71, 0.0021702837612893847), (456, 0.0021908440523677403), (168, 0.0022070014642344583), (312, 0.002207063138484955), (469, 0.0022096816036436292), (470, 0.00220972527232435), (138, 0.0022108852863311768), (36, 0.0022255869375334848), (361, 0.002243529591295454), (93, 0.0022591733270221287), (231, 0.002267608212100135), (463, 0.0022785827103588316), (75, 0.0022878112892309823), (129, 0.0023070377194219166), (286, 0.002312764525413513), (293, 0.002337460923526022), (142, 0.002344834721750683), (391, 0.00234517434404956), (424, 0.0023460379905170864), (157, 0.0023464767469300162), (185, 0.0023493129346105787), (340, 0.00235495881901847), (31, 0.0023550687150822747), (336, 0.0023644835584693486), (381, 0.0023758121662669713), (511, 0.002386631030175421), (334, 0.002390924013323254), (408, 0.0023963136805428397), (465, 0.002399350619978375), (170, 0.0024048234853479597), (19, 0.0024193504618273843), (211, 0.002420615404844284), (480, 0.0024211961362097), (467, 0.0024259740279780496), (152, 0.002433050630821122), (326, 0.002434194708863894), (311, 0.0024418067187070847), (119, 0.0024426269034544625), (236, 0.002442852490478092), (484, 0.00244501709110207), (400, 0.0024451236757967207), (387, 0.0024487759090132183), (246, 0.0024567010502020517), (473, 0.0024619479146268633), (328, 0.0024640833338101706), (128, 0.002468554510010613), (172, 0.0024694750706354776), (148, 0.002469942801528507), (70, 0.0024713476498921714), (302, 0.0024855033391051823), (283, 0.002486909015311135), (439, 0.002487697328130404), (274, 0.0024914551112386915), (301, 0.002493389985627598), (342, 0.0024960761268933616), (441, 0.0024989967544873557), (240, 0.002505883988406923), (365, 0.0025143737180365455), (275, 0.0025183111429214478), (378, 0.0025196605258517796), (401, 0.0025327226354016196), (460, 0.0025340786410702597), (18, 0.002543416495124499), (322, 0.0025507124761740365), (299, 0.0025599367088741725), (222, 0.0025684494111273023), (291, 0.00256936252117157), (411, 0.002569904343949424), (223, 0.0025711076127158273), (344, 0.0025728419423103333), (496, 0.002583224740293291), (165, 0.0025874372157785627), (162, 0.0025887799759705863), (208, 0.002588808329568969), (341, 0.0025889575481414795), (252, 0.0025966916647222307), (217, 0.0026015895936224195), (39, 0.00260317325592041), (213, 0.0026099462476041582), (230, 0.0026166424569156435), (370, 0.00262153728140725), (111, 0.0026262284566958747), (95, 0.0026285333765877616), (56, 0.002631815771261851), (479, 0.0026326804525322383), (69, 0.0026423397163550058), (474, 0.002648719275991122), (101, 0.0026520730720625985), (281, 0.0026543454991446603), (478, 0.0026592982725964654), (426, 0.0026595722883939743), (372, 0.00266007168425454), (393, 0.0026614757047759164), (417, 0.0026637566172414357), (433, 0.0026637806246678033), (205, 0.002664103690120909), (282, 0.0026691845721668666), (255, 0.0026719806094964347), (4, 0.0026721180313163334), (305, 0.0026778092400895227), (358, 0.002677985363536411), (492, 0.002680818239847819), (116, 0.0026820173694027793), (189, 0.0026830602437257767), (298, 0.002683244231674406), (481, 0.002686296072271135), (192, 0.0026877648714515897), (304, 0.0026951063838269976), (251, 0.002708566685517629), (257, 0.002714732454882728), (50, 0.0027232240471574995), (453, 0.0027232950346337426), (268, 0.002725844168000751), (310, 0.002735253009531233), (450, 0.002735844916767544), (202, 0.0027367634077866874), (244, 0.002737419472800361), (124, 0.0027379499127467475), (279, 0.0027385943879683814), (121, 0.002740210543076197), (353, 0.002741145590941111), (78, 0.0027579770733912787), (508, 0.00275941358672248), (289, 0.0027602345993121466), (72, 0.0027631082468562657), (498, 0.002763851649231381), (294, 0.002765316516160965), (444, 0.002767447382211685), (254, 0.00277026059726874), (238, 0.002774248934454388), (423, 0.0027852991802824866), (109, 0.0027863598532146877), (102, 0.0027865891655286155), (17, 0.0027919920782248178), (277, 0.002792482781741354), (188, 0.0027993698087003496), (250, 0.0028036344382498), (466, 0.0028096818261676365), (491, 0.0028138491842481825), (237, 0.002816284696261088), (167, 0.002817664709356096), (174, 0.002820530285437902), (84, 0.0028247361381848655), (410, 0.0028274872650702796), (245, 0.0028369720611307356), (249, 0.0028386952148543466), (290, 0.002841886132955551), (390, 0.002843259937233395), (316, 0.0028432936718066535), (76, 0.0028448489805062613), (216, 0.0028470419347286224), (64, 0.002851462819510036), (45, 0.002851735179622968), (338, 0.0028562924514214196), (49, 0.002858560946252611), (507, 0.0028602267718977397), (495, 0.002874794312649303), (266, 0.0028757045252455603), (104, 0.0028787189059787327), (269, 0.0028800538016690146), (212, 0.002881477897365888), (258, 0.0028855864786439473), (89, 0.002888219017121527), (30, 0.0028890280259980094), (233, 0.002889924579196506), (153, 0.0028928942564460966), (510, 0.0029002527395884195), (6, 0.0029006896333562005), (73, 0.0029019578877422544), (421, 0.0029061995446681976), (96, 0.002906468179490831), (399, 0.002906849814785851), (139, 0.0029068849980831146), (415, 0.0029080986148781246), (329, 0.002908474455277125), (86, 0.002916354686021805), (323, 0.0029201184709866843), (196, 0.0029289734860261283), (227, 0.002930175099107954), (501, 0.002931152159969012), (502, 0.0029321379131740993), (468, 0.0029342702279488244), (87, 0.002935107176502546), (99, 0.0029359819988409677), (306, 0.00293877845009168), (493, 0.0029395903564161724), (447, 0.002940710633993149), (330, 0.002947017964389589), (504, 0.002950342579020394), (44, 0.002959902501768536), (194, 0.0029646634227699703), (397, 0.00297160798476802), (220, 0.0029916444586382974), (178, 0.002992386826210552), (384, 0.0029933307733800677), (103, 0.002997943510611852), (176, 0.0030023521847195095), (475, 0.003002799219555325), (309, 0.003003722470667627), (307, 0.003011337791879972), (386, 0.0030195359140634537), (126, 0.0030210291345914206), (40, 0.003022008885939916), (455, 0.0030284331490596137), (327, 0.0030311176346408), (173, 0.003042992204427719), (83, 0.0030455518927839068), (48, 0.003045884685383903), (32, 0.0030501940184169346), (155, 0.003053225783838166), (383, 0.00306582719915443), (368, 0.003073532548215654), (130, 0.003078622536526786), (204, 0.0030797533690929413), (435, 0.0030815433710813522), (395, 0.0030835308134555817), (402, 0.0030859149992465973), (25, 0.0030936766415834427), (127, 0.0030939864615599313), (488, 0.0030998877353138393), (490, 0.0031052471862898934), (262, 0.003106290267573463), (443, 0.003115259731809298), (199, 0.003115460690524843), (509, 0.0031177525719006858), (457, 0.003118375523222817), (436, 0.0031216206649939218), (317, 0.003121970428360833), (499, 0.003123174938890669), (27, 0.003127182109488381), (242, 0.003131875561343299), (91, 0.0031391746468014186), (67, 0.0031446023947662776), (144, 0.0031469913406504523), (363, 0.003148694626159138), (285, 0.00315419625904825), (10, 0.0031561930146482256), (29, 0.0031578650491105188), (184, 0.0031602074288659627), (98, 0.003160347127252155), (382, 0.0031633141140143075), (234, 0.0031639461716016135), (376, 0.0031643671294053397), (7, 0.0031650749345620475), (357, 0.0031702793720695707), (160, 0.0031768567860126495), (77, 0.0031773286561171212), (454, 0.003178172434369723), (141, 0.0031795849402745566), (68, 0.003180233968628777), (66, 0.003183972090482712), (348, 0.0031845722761419085), (430, 0.0031855127049816977), (53, 0.0031909445921579995), (57, 0.003191736423306995), (295, 0.0031988399310244452), (278, 0.003200874560409122), (156, 0.003202112598551644), (419, 0.003202815850575765), (65, 0.0032029240909549925), (146, 0.003222751741607984), (346, 0.003233301763733228), (164, 0.003233764734533098), (0, 0.003234848380088806), (413, 0.0032404797772566476), (100, 0.0032443799492385653), (438, 0.0032447075678242576), (445, 0.003251066224442588), (108, 0.0032517568518718085), (420, 0.0032595578167173597), (214, 0.003260065077079667), (60, 0.003263927168316311), (187, 0.003269865488012632), (149, 0.0032718893554475573), (177, 0.0032784388297133977), (134, 0.0032856373323334586), (487, 0.0032889188991652597), (389, 0.003296302424536811), (74, 0.0033072976188527215), (414, 0.0033092726435926226), (362, 0.0033180034822887844), (209, 0.003322130690018336), (416, 0.0033259447664022446), (140, 0.003334615793493059), (224, 0.0033450259102715384), (347, 0.003347190717856089), (106, 0.0033492748108175066), (352, 0.0033498460219966043), (113, 0.0033513415190908643), (427, 0.003360336439477073), (271, 0.0033609308302402496), (486, 0.0033619668748643664), (2, 0.00336755584511492), (351, 0.0033751146660910714), (345, 0.003377538381351365), (37, 0.0033826749357912275), (270, 0.0033833011984825134), (11, 0.003399079458581077), (405, 0.003409887353579203), (145, 0.0034110411587688657), (394, 0.003412681735224194), (88, 0.0034194567965136636), (284, 0.0034238037963708243), (431, 0.0034248634345001644), (163, 0.0034262179914447996), (9, 0.0034291257874833215), (229, 0.0034663451628552545), (203, 0.0034732710984018114), (354, 0.003477868934472402), (247, 0.003481394714779324), (110, 0.003482204344537523), (300, 0.003484484222200182), (58, 0.003490462899208069), (432, 0.003493193123075697), (94, 0.0035014160805278355), (398, 0.0035052593383524152), (1, 0.0035057556298043993), (264, 0.0035101034575038487), (55, 0.0035184799797005123), (193, 0.0035330408977137674), (92, 0.003533661365509033), (273, 0.003536905679437849), (5, 0.0035439406832059226), (462, 0.0035550097624460855), (337, 0.0035564746293756696), (175, 0.0035586580634117126), (207, 0.0035718832578923968), (135, 0.0035759595533212027), (61, 0.0036039513846238456), (369, 0.003605029649204678), (115, 0.003606403867403666), (241, 0.0036147994299729667), (359, 0.0036153768499692283), (494, 0.0036264417899979483), (210, 0.00362688841091262), (228, 0.0036348849534988403), (497, 0.003638337469763226), (485, 0.0036409770449002585), (288, 0.0036474785043133628), (412, 0.0036531943413946363), (335, 0.0036559460891617667), (464, 0.0036666111813651193), (248, 0.0036744545731279585), (117, 0.0036744938956366647), (136, 0.0036754384636878967), (125, 0.00368566686908404), (428, 0.003691753993431727), (131, 0.003697836564646827), (374, 0.003700601557890574), (169, 0.0037038574616114297), (482, 0.003710562984148661), (150, 0.003712825063202116), (319, 0.0037162635061475965), (154, 0.003724269154998991), (225, 0.003724281986554464), (407, 0.0037261943022410073), (219, 0.0037329792976379395), (180, 0.0037342078155941432), (458, 0.0037359388338194955), (33, 0.0037443811694780984), (179, 0.0037531757520304788), (143, 0.0037538218829366895), (182, 0.003754453112681707), (171, 0.0037573998173077903), (201, 0.0037689494589964547), (114, 0.0037733622723155552), (122, 0.003775521285004086), (20, 0.0037785019311639997), (34, 0.003789562318060133), (333, 0.003793545895152622), (133, 0.003794801731904348), (392, 0.0038012833231025273), (503, 0.0038026058011584813), (123, 0.0038066663675838048), (261, 0.003808880845705668), (452, 0.0038200608558124965), (403, 0.0038257700701554618), (21, 0.003832627087831497), (166, 0.003848675224516127), (297, 0.003869537678029802), (232, 0.003870996336142222), (52, 0.0038806754681799146), (429, 0.00388103144036399), (80, 0.003890859997934765), (343, 0.0038978498842981127), (388, 0.0038983337581157684), (198, 0.003898339139090644), (8, 0.0039036555422676932), (159, 0.003913223743438721), (440, 0.003921926021575928), (409, 0.003922405342260997), (256, 0.00392909554971589), (265, 0.003934066328737471), (200, 0.0039399369723267024), (315, 0.003962325553099315), (24, 0.0039723896318011815), (437, 0.003982972767617967), (267, 0.003985029541783863), (239, 0.003988304485877355), (112, 0.003991875797510147), (418, 0.004001522229777442), (197, 0.0040015975634257), (449, 0.004002950257725186), (375, 0.004005703661176894), (367, 0.00402555118004481), (325, 0.004026220904456245), (303, 0.004034794039196438), (451, 0.004040220545397865), (489, 0.004056364297866821), (12, 0.0040651899245050215), (82, 0.0040704744557539625), (23, 0.004081129613849852), (308, 0.004086034993330638), (366, 0.004102957331471973), (276, 0.0041172347135014), (235, 0.004149109952979618), (260, 0.004175189882516861), (472, 0.004184284971819984), (191, 0.004187639388773177), (26, 0.004193596127960417), (313, 0.004211067325539059), (385, 0.004222240712907579), (15, 0.004246154593096839), (38, 0.0042474062906371225), (46, 0.004248129824797313), (477, 0.004294340809186299), (81, 0.004311202300919427), (85, 0.0043175241185559165), (321, 0.00432358475195037), (181, 0.004351229717334111), (483, 0.0043698979748619925), (151, 0.0043701376352045275), (105, 0.00440530851483345), (161, 0.004408312754498588), (226, 0.004417213300863902), (22, 0.004431777944167455), (97, 0.004437100556161668), (272, 0.004440894143448936), (79, 0.004455334196488063), (296, 0.004490541501177682), (320, 0.004527905748950111), (314, 0.004564014159970813), (259, 0.00456777670317226), (500, 0.004600154028998481), (107, 0.004613695873154534), (183, 0.004629937724934684), (215, 0.004631535046630436), (28, 0.004633814096450806), (446, 0.004637934681442048), (471, 0.004643130633566115), (14, 0.0046500278015931444), (206, 0.004656987057791816), (422, 0.0046597739888562095), (90, 0.004660922206110424), (355, 0.00469731373919381), (190, 0.004711762484576967), (186, 0.0047408656941519845), (54, 0.00477104095949067), (51, 0.004772935062646866), (263, 0.004791713423199124), (35, 0.004814171128802829), (120, 0.004821533130274879), (287, 0.004823135419024361), (16, 0.004828099575307634), (404, 0.0048551228311326765), (406, 0.004884350630972121), (434, 0.004887073404259152), (332, 0.004888866096735001), (476, 0.0048939792646302115), (221, 0.004896344410048591), (506, 0.004944519036346012), (118, 0.004967247446378072), (59, 0.004987367739280065), (147, 0.005058891657325957), (371, 0.005128108378913667), (253, 0.005149014708068635), (331, 0.005154963168832991), (360, 0.005175396800041199), (137, 0.005179169277350108), (318, 0.005204949114057753), (373, 0.005329854786396027), (63, 0.005495650900734795), (3, 0.005559336807992723), (62, 0.005589865148067474), (43, 0.005695446497864193), (442, 0.0058101146585411495), (42, 0.005834713992145326), (349, 0.005896990083985859), (356, 0.00595134910609987), (158, 0.006077812363704045), (218, 0.006190342207749684), (292, 0.006217173818084929), (47, 0.006302913857830895), (280, 0.006314338909255134), (364, 0.0063397255208757185), (132, 0.006357916113403108), (339, 0.006765394161144893), (324, 0.006808701902627945), (41, 0.008125459982289208), (425, 0.009358467327223884), (243, 0.009726582301987542), (350, 0.01186174319850074)]\n",
            "512\n",
            "L2 norm of conv_layer11\n",
            " [(504, 0.001495065995388561), (58, 0.0016776197072532442), (129, 0.0023144661552376216), (0, 0.0024159749348958335), (2, 0.0024984214040968153), (202, 0.0025135758850309583), (484, 0.0025265316168467202), (386, 0.0025782183640533024), (395, 0.0025828925685750116), (503, 0.0026126830942100948), (131, 0.0026228328545888266), (84, 0.0026465155598190096), (316, 0.0026638288464811114), (173, 0.0026658249811993707), (229, 0.0027365628629922867), (83, 0.002757257264521387), (511, 0.0027739202810658347), (315, 0.002776536676618788), (193, 0.002777034209834205), (180, 0.00277802265352673), (63, 0.0027884915471076965), (294, 0.0027984916749927732), (153, 0.0028067860338422987), (290, 0.002821400140722593), (213, 0.0028318696551852757), (333, 0.00284440815448761), (409, 0.0028535729895035424), (39, 0.0028615910559892654), (321, 0.0028779922674099603), (189, 0.002891437460978826), (271, 0.0028920177784230974), (464, 0.0028969223300615945), (300, 0.002904795938067966), (138, 0.0029417893124951255), (412, 0.002950487037499746), (499, 0.0029527822302447427), (81, 0.002969292716847526), (312, 0.0029750333891974557), (72, 0.00297677434153027), (127, 0.002979614254501131), (279, 0.0029803473088476392), (337, 0.00298134113351504), (458, 0.0029832813888788223), (323, 0.0029875257362922034), (36, 0.0029895945141712823), (31, 0.0030008951822916665), (133, 0.00300306992398368), (259, 0.0030193705525663164), (253, 0.0030197836458683014), (269, 0.0030281876938210595), (151, 0.0030306639770666757), (397, 0.003033087899287542), (56, 0.0030354460080464682), (431, 0.0030406423740916783), (13, 0.003040966267387072), (158, 0.003042440033621258), (115, 0.0030444196114937463), (94, 0.003045556445916494), (364, 0.0030509837799602086), (5, 0.003054694583018621), (106, 0.0030578432811631095), (390, 0.0030593578186300066), (132, 0.003061655494901869), (33, 0.0030689934889475503), (121, 0.003078100168042713), (459, 0.003080271598365572), (340, 0.003080712838305367), (427, 0.0030828010704782275), (303, 0.0030832719057798386), (415, 0.00309504403008355), (495, 0.0030965858863459695), (239, 0.0030991832415262857), (350, 0.0031002466049459246), (22, 0.0031003310448593563), (374, 0.0031027417216036054), (408, 0.0031143085410197577), (224, 0.0031231819755501216), (355, 0.0031244270503520966), (61, 0.0031320293330483967), (103, 0.0031403063072098624), (367, 0.003147121932771471), (122, 0.003150616255071428), (165, 0.003154370519849989), (174, 0.003158247305287255), (353, 0.0031608357611629698), (400, 0.0031677213393979603), (226, 0.003173179096645779), (68, 0.003173448559310701), (387, 0.0031764027145173815), (429, 0.0031796319203244317), (356, 0.0031798690971401003), (281, 0.0031865487496058145), (254, 0.0031871673547559315), (235, 0.0031908216575781503), (210, 0.0031909381763802636), (341, 0.003193438880973392), (416, 0.0032005260388056436), (147, 0.0032180030312803057), (183, 0.003218283255894979), (257, 0.0032360462678803336), (190, 0.0032403158644835153), (141, 0.0032409640649954477), (299, 0.0032446355455451542), (348, 0.0032472627030478585), (220, 0.0032479965852366555), (107, 0.00325605645775795), (305, 0.0032583054982953602), (252, 0.003262425876326031), (494, 0.0032651500983370673), (261, 0.003265769531329473), (382, 0.0032681512335936227), (401, 0.0032688391705354056), (304, 0.003273194862736596), (204, 0.003280598877204789), (26, 0.003284682830174764), (38, 0.0032855975959036085), (232, 0.0032916197346316445), (392, 0.0032950308587816027), (449, 0.003304346568054623), (144, 0.0033100288775232104), (30, 0.0033141947868797514), (455, 0.003314429687129127), (347, 0.0033152256574895647), (74, 0.003317818666497866), (482, 0.003320760817991363), (134, 0.003321383148431778), (282, 0.003323666130503019), (136, 0.003341137535042233), (25, 0.0033420438153876197), (436, 0.0033426942924658456), (311, 0.0033434948159588706), (90, 0.0033498385714160073), (98, 0.003352152183651924), (120, 0.003352772237526046), (185, 0.003362826175159878), (450, 0.0033646534300512737), (28, 0.0033648808797200522), (43, 0.00338288437989023), (437, 0.0033855351308981576), (139, 0.0033944712744818795), (97, 0.0033986754715442657), (218, 0.0033996146586206225), (471, 0.003404890497525533), (417, 0.0034131335301531684), (214, 0.0034214320282141366), (493, 0.003422273943821589), (260, 0.0034230233480532966), (465, 0.003423376836710506), (135, 0.003423428783814112), (45, 0.003428641292783949), (288, 0.003431534187661277), (18, 0.0034373102502690423), (456, 0.0034383158716890547), (178, 0.0034509613696071836), (505, 0.003451144943634669), (32, 0.0034522225873337854), (255, 0.0034538552992873723), (265, 0.003459632396697998), (44, 0.003460093918773863), (243, 0.0034609265211555692), (402, 0.0034612512422932517), (326, 0.0034620436943239635), (453, 0.0034633506503370074), (283, 0.003467569127678871), (262, 0.0034696852995289695), (331, 0.00347083889775806), (492, 0.0034749193323983085), (85, 0.0034774442513783774), (276, 0.0034779256416691672), (470, 0.003478251811530855), (60, 0.003481308619181315), (345, 0.0034837664829360116), (170, 0.0034912005066871643), (506, 0.0034942395157284206), (330, 0.003504995670583513), (302, 0.0035084312160809836), (75, 0.003509850965605842), (378, 0.003510576155450609), (231, 0.0035216067400243548), (110, 0.003522002034717136), (273, 0.0035298321810033587), (142, 0.003540250990125868), (55, 0.0035422026283211177), (301, 0.0035452350146240657), (433, 0.0035504471096727583), (366, 0.003550862272580465), (485, 0.00356433168053627), (476, 0.003565290735827552), (286, 0.003565810206863615), (179, 0.003576671911610497), (435, 0.0035797680417696633), (206, 0.00358158184422387), (475, 0.0035847926305400003), (446, 0.0035889152851369646), (237, 0.0036044038004345363), (73, 0.0036099511716100904), (12, 0.00361109690533744), (381, 0.0036139090855916343), (339, 0.003619687838686837), (468, 0.0036201493607627023), (463, 0.003620290093951755), (186, 0.003626336240106159), (317, 0.003636066284444597), (150, 0.003639643390973409), (51, 0.00364077091217041), (411, 0.0036416364212830863), (422, 0.003642374442683326), (116, 0.0036441427138116625), (201, 0.003649387922551897), (479, 0.003661825011173884), (454, 0.0036644256777233547), (37, 0.0036658019655280644), (112, 0.003666691482067108), (54, 0.0036667022440168592), (306, 0.0036768660777144963), (490, 0.0036806795332166883), (293, 0.003682052923573388), (373, 0.0036901748842663234), (225, 0.0036943480372428894), (191, 0.0036958654721577964), (130, 0.003699522465467453), (164, 0.0037010047170850965), (342, 0.003701412015491062), (338, 0.003703046590089798), (217, 0.003707064522637261), (87, 0.003710992220375273), (172, 0.0037164679831928676), (23, 0.0037297668556372323), (238, 0.0037316733764277566), (369, 0.0037448787026935155), (406, 0.0037498242325252956), (278, 0.0037515146864785087), (451, 0.003757236732376946), (501, 0.0037618474000030095), (171, 0.0037651595969994864), (15, 0.0037655006680223676), (27, 0.0037676642338434854), (69, 0.003767913414372338), (234, 0.0037763938307762146), (487, 0.0037804386681980556), (155, 0.003780937443176905), (357, 0.003798831668164995), (425, 0.003799326303932402), (319, 0.0038000792264938354), (320, 0.0038034493724505105), (168, 0.003805985467301475), (152, 0.0038212359779410893), (10, 0.0038213510480191973), (430, 0.0038230249451266397), (297, 0.0038292474216885036), (207, 0.0038332839806874595), (318, 0.003834926419787937), (77, 0.003837388422754076), (307, 0.003839184840520223), (101, 0.0038480108810795676), (361, 0.0038491677906778124), (216, 0.003853792945543925), (245, 0.003855696568886439), (325, 0.003856481777297126), (95, 0.003868160976303948), (105, 0.0038706308437718284), (200, 0.0038707243899504342), (113, 0.003873166110780504), (508, 0.003875910821888182), (328, 0.0038774762716558245), (267, 0.0038779866364267138), (478, 0.003888496922122108), (92, 0.0038902171783977086), (148, 0.003890758587254418), (393, 0.003892049193382263), (457, 0.003894661863644918), (228, 0.003913297421402401), (198, 0.003915586819251378), (96, 0.003916090147362815), (391, 0.003916414247618781), (159, 0.0039202020400100285), (310, 0.00392088500989808), (473, 0.003927482499016656), (287, 0.003930882861216863), (188, 0.003931114657057656), (47, 0.003931802180078294), (100, 0.003932634989420573), (403, 0.003934854020675023), (52, 0.00393631723192003), (428, 0.003936988612016042), (7, 0.003937573068671756), (71, 0.003949366095993254), (263, 0.003950181520647473), (414, 0.003955172167883979), (491, 0.003958543141682942), (67, 0.003974981606006622), (181, 0.003979129923714532), (448, 0.003993525687191222), (497, 0.004004124965932634), (274, 0.004006121721532609), (327, 0.004023720406823688), (154, 0.004026273058520423), (19, 0.004034886757532756), (114, 0.004036323063903385), (48, 0.004044632944795821), (223, 0.004046928137540817), (230, 0.004052990426619847), (146, 0.004058320489194658), (399, 0.004060607817437913), (461, 0.00406083216269811), (372, 0.004071266286902958), (182, 0.004073816041151683), (385, 0.004077231718434228), (211, 0.004078232579761081), (137, 0.004085746076371934), (46, 0.004087960554493798), (14, 0.004092024432288276), (440, 0.004093477295504676), (285, 0.00410739208261172), (486, 0.00411856836742825), (163, 0.00412506361802419), (64, 0.004147701793246799), (447, 0.004148033758004506), (398, 0.004151434534125858), (50, 0.004154351436429554), (329, 0.00415763548678822), (352, 0.0041595275203386945), (102, 0.004159613202015559), (379, 0.0041606177886327105), (266, 0.004167199962668949), (462, 0.004174614118205177), (434, 0.004175451894601186), (360, 0.004189305007457733), (268, 0.004192610581715901), (62, 0.004197405030330022), (480, 0.004203940845198101), (426, 0.004204463627603319), (380, 0.0042100730869505144), (314, 0.004210689001613193), (343, 0.004219171073701646), (477, 0.0042205022441016305), (421, 0.00422421470284462), (502, 0.00422514933678839), (65, 0.004226531419489119), (249, 0.004227579053905275), (222, 0.004229540212286843), (358, 0.004234920773241255), (469, 0.004243602355321248), (472, 0.004246097885900074), (99, 0.004273238281408946), (375, 0.0042868513200018145), (35, 0.004287129475010766), (264, 0.004289627489116456), (119, 0.004295368989308675), (298, 0.004296268853876326), (160, 0.004301735096507602), (410, 0.004315369658999973), (247, 0.00432043108675215), (6, 0.004328945444689857), (140, 0.004329533212714725), (419, 0.004337907251384523), (295, 0.004354288594590293), (289, 0.0043624138666523826), (322, 0.004373903075853984), (363, 0.004387225541803572), (126, 0.0044017744561036425), (176, 0.00440356218152576), (187, 0.004405909114413791), (423, 0.004408528821335899), (365, 0.004440938433011373), (291, 0.004447896447446611), (109, 0.004451322058836619), (175, 0.00445183159576522), (86, 0.00445597411857711), (169, 0.004457169936762916), (161, 0.004458583891391754), (460, 0.004462977250417073), (166, 0.004476447072294023), (407, 0.004483995338280995), (404, 0.004488692929347356), (212, 0.004490182631545597), (394, 0.00449088422788514), (362, 0.00449901239739524), (162, 0.00450650230050087), (128, 0.004508776797188653), (405, 0.00451209478908115), (292, 0.004524374173747169), (221, 0.004525677611430486), (89, 0.00453331031733089), (149, 0.004535213112831116), (474, 0.004545501536793179), (368, 0.0045490918887986075), (49, 0.0045492276549339294), (240, 0.004550073709752824), (335, 0.004563561744160122), (3, 0.004563593202167087), (383, 0.004565332912736469), (483, 0.00457836604780621), (29, 0.00460343642367257), (145, 0.004620439476437039), (354, 0.004625894957118564), (376, 0.004635773599147797), (509, 0.004638094868924882), (1, 0.004640759693251716), (452, 0.004643195619185765), (270, 0.004643835127353668), (111, 0.0046638080643283), (284, 0.004692398839526706), (34, 0.004703872319724824), (118, 0.004721049633291032), (420, 0.004723025692833794), (123, 0.004724899099932777), (53, 0.004749630060460832), (17, 0.004773873421880934), (79, 0.00477642234828737), (272, 0.004776480297247569), (196, 0.004805569847424825), (498, 0.004811298929982715), (184, 0.004814074271255069), (195, 0.004816734128528171), (9, 0.0048208894828955335), (108, 0.004825147075785531), (277, 0.004854220896959305), (156, 0.004866417911317613), (215, 0.004911589953634474), (197, 0.004957160188092126), (258, 0.004957844813664754), (432, 0.004960787793000539), (351, 0.00497231673863199), (388, 0.004975431495242649), (24, 0.004983653210931354), (441, 0.004987724953227573), (445, 0.005001131445169449), (384, 0.0050059350000487435), (78, 0.0050151464011934065), (192, 0.005016887353526222), (296, 0.005033504631784227), (143, 0.0050500598218705915), (500, 0.005096654925081465), (41, 0.005116734239790175), (8, 0.005140802098645104), (93, 0.005153396477301915), (481, 0.005158858994642894), (233, 0.005165279739432865), (91, 0.005166076123714447), (507, 0.005212797886795468), (199, 0.005219000081221263), (236, 0.005227901041507721), (443, 0.005268829150332345), (377, 0.005284688125054042), (280, 0.005344260897901323), (66, 0.0053474936220381), (20, 0.005349304113123152), (413, 0.005350216395325131), (177, 0.005377386179235246), (82, 0.0053820353415277265), (336, 0.005408090021875169), (124, 0.005429033603933122), (242, 0.005492268337143792), (418, 0.005506130556265513), (80, 0.005556405418448978), (227, 0.0055598968433009256), (244, 0.005574707355764177), (313, 0.005599555042054918), (275, 0.005618754360410903), (104, 0.005621262308624055), (167, 0.005627146197689904), (349, 0.005634249912367927), (42, 0.005659845140245225), (467, 0.005674388259649277), (241, 0.005738248427708943), (424, 0.0057469399438964), (442, 0.00574968589676751), (371, 0.005843585977951686), (510, 0.005856869535313712), (438, 0.005872874624199337), (489, 0.005928396350807614), (256, 0.0059891318281491595), (346, 0.00600310539205869), (439, 0.006010774109098647), (76, 0.006048080821832021), (344, 0.006062485691573884), (125, 0.006063246064715915), (466, 0.0060886310206519235), (157, 0.006181835714313719), (250, 0.006274198078446918), (370, 0.006306969457202488), (194, 0.006345162375105752), (88, 0.00635551040371259), (11, 0.0063896386159790885), (16, 0.0064334919055302935), (389, 0.006487725509537591), (59, 0.006621394720342424), (209, 0.00665180053975847), (334, 0.006659150123596191), (488, 0.006847913894388411), (4, 0.0069283681611220045), (40, 0.006967466738488939), (332, 0.006977433959643046), (444, 0.007026231951183743), (203, 0.007039934396743774), (205, 0.007147211167547438), (396, 0.007229186594486237), (308, 0.0074907806184556745), (324, 0.007734961807727814), (70, 0.007993201414744059), (208, 0.008228377335601382), (359, 0.008272399504979452), (246, 0.00836365090476142), (219, 0.008956650892893473), (496, 0.009151349465052286), (248, 0.00939994388156467), (309, 0.010455300410588583), (117, 0.010821301076147292), (21, 0.011101920571592119), (251, 0.014336066113577949), (57, 0.015299845072958205)]\n",
            "512\n",
            "L2 norm of conv_layer12\n",
            " [(196, 0.002443715516063902), (423, 0.0024861200816101497), (157, 0.002576132615407308), (400, 0.0026248956306113135), (474, 0.0026502611322535407), (179, 0.0026824656460020277), (308, 0.00269656235145198), (25, 0.00269957073032856), (422, 0.0027114806903733146), (387, 0.00272168405354023), (132, 0.002734306992755996), (197, 0.002745903821455108), (53, 0.002749066799879074), (240, 0.0027662358350223964), (258, 0.002791004048453437), (95, 0.0027987522383530936), (177, 0.0028109782271915013), (24, 0.002812824108534389), (60, 0.0028286948800086975), (65, 0.0028745300239986843), (77, 0.002875234931707382), (89, 0.002885345783498552), (402, 0.002895849032534493), (162, 0.002917792648077011), (217, 0.002918697272737821), (139, 0.002925136850939857), (386, 0.002943587592906422), (63, 0.00294681079685688), (4, 0.002949249413278368), (220, 0.0029543425059980815), (252, 0.002963673323392868), (3, 0.002980852706564797), (136, 0.0029813808699448905), (158, 0.0029820919864707524), (222, 0.0030072112050321368), (304, 0.0030081671559148366), (469, 0.0030282247397634718), (184, 0.003028411625160111), (438, 0.0030367359932925967), (5, 0.003047192262278663), (458, 0.0030480867458714377), (251, 0.0030546308391624028), (398, 0.0030559392438994516), (91, 0.003057323396205902), (239, 0.0030847138000859153), (405, 0.003100223011440701), (36, 0.0031005568388435575), (441, 0.0031018079155021245), (476, 0.0031060802025927436), (19, 0.0031133265131049687), (67, 0.003114681277010176), (160, 0.0031167411555846534), (107, 0.0031188949942588806), (166, 0.0031226368414031137), (336, 0.0031348752478758493), (44, 0.003141985999213325), (66, 0.0031529805726475185), (121, 0.0031580900152524314), (340, 0.0031587088273631204), (370, 0.003164908538262049), (349, 0.0031700171530246735), (145, 0.003174005283249749), (362, 0.0031750096629063287), (464, 0.003181121622522672), (359, 0.003197403831614388), (213, 0.003199096769094467), (269, 0.0032082514630423654), (459, 0.0032106577936145994), (337, 0.0032141877131329644), (279, 0.0032213740050792694), (466, 0.0032248927487267386), (195, 0.0032333661284711626), (303, 0.00323441190024217), (271, 0.0032350069118870627), (505, 0.00323802274134424), (173, 0.0032452895409531063), (131, 0.0032457028412156636), (187, 0.0032546367082330915), (265, 0.0032577315966288247), (460, 0.0032607662594980663), (431, 0.0032672014915280873), (78, 0.0032725706696510315), (68, 0.0032789895517958533), (502, 0.003279690941174825), (0, 0.003282304232319196), (245, 0.003288837977581554), (174, 0.0032904139823383754), (510, 0.0032963380217552185), (83, 0.003297878843214777), (427, 0.0032996611876620185), (1, 0.0033023307720820108), (433, 0.0033032078709867266), (406, 0.003306333596507708), (355, 0.003317004276646508), (170, 0.0033210795372724533), (148, 0.0033236040423313775), (307, 0.003329857976900207), (290, 0.003331889294915729), (383, 0.0033367290678951475), (499, 0.003337383684184816), (146, 0.003339055304725965), (294, 0.003340906567043728), (385, 0.0033450155622429317), (352, 0.0033541803972588647), (339, 0.0033563710749149323), (109, 0.003363303633199798), (93, 0.003363880432314343), (393, 0.0033642659998602336), (490, 0.003383249044418335), (209, 0.003383468215664228), (492, 0.0033917518125640023), (384, 0.0033923188845316568), (75, 0.003392338959707154), (435, 0.003396136893166436), (416, 0.003398550053437551), (353, 0.003400468991862403), (364, 0.0034008237222830453), (312, 0.00341028802924686), (452, 0.003410689118835661), (473, 0.0034115962270233366), (96, 0.0034142322838306427), (194, 0.0034263022243976593), (214, 0.00343208946287632), (453, 0.0034322082582447263), (133, 0.003440137952566147), (164, 0.0034441834108697045), (328, 0.003446578151649899), (255, 0.003446983794371287), (127, 0.0034537031832668516), (101, 0.003459181015690168), (305, 0.003460977019535171), (421, 0.0034631221658653682), (225, 0.003474030229780409), (205, 0.0034844448996914756), (21, 0.0034870869583553737), (330, 0.0034889140062861973), (485, 0.003490793208281199), (395, 0.00349441087908215), (46, 0.003502640045351452), (496, 0.003509050856033961), (99, 0.0035123477379480996), (429, 0.0035240650177001953), (319, 0.0035340446564886305), (298, 0.003545740826262368), (58, 0.0035462818211979335), (480, 0.0035494930214352077), (288, 0.0035501056247287327), (49, 0.0035564088159137303), (11, 0.0035576195352607304), (22, 0.0035614946650134195), (356, 0.003565352823999193), (285, 0.003566552781396442), (273, 0.0035748353434933555), (94, 0.0035755683978398642), (198, 0.003578110287586848), (223, 0.003580673701233334), (249, 0.0035812610553370584), (140, 0.0035881217983033922), (114, 0.0035902783274650574), (203, 0.0036004305713706547), (117, 0.0036072019073698255), (143, 0.003608201113012102), (224, 0.0036118866668807138), (87, 0.0036156272722615134), (396, 0.003616123149792353), (200, 0.0036202996141380733), (486, 0.003621550897757212), (369, 0.0036266855895519257), (363, 0.003627434786823061), (14, 0.003629886441760593), (228, 0.0036434481541315713), (367, 0.0036469722787539163), (358, 0.0036503742966387006), (212, 0.0036534153752856785), (379, 0.0036539865864647757), (35, 0.0036620344552728864), (313, 0.0036826754609743753), (507, 0.0036857256458865274), (123, 0.00368903163406584), (329, 0.0036900705761379665), (138, 0.003690857854154375), (215, 0.00369340181350708), (411, 0.00369811968670951), (153, 0.0036995605462127263), (360, 0.0037000030279159546), (181, 0.0037118072311083474), (230, 0.003713946375581953), (283, 0.003715001874499851), (9, 0.0037202445997132193), (69, 0.00372111052274704), (90, 0.0037213671538564893), (134, 0.003725348247422112), (124, 0.0037280345956484475), (85, 0.003731822801960839), (147, 0.003739145894845327), (126, 0.003752507683303621), (451, 0.003752717541323768), (403, 0.003755248255199856), (284, 0.0037569511267873975), (426, 0.003757133666012022), (27, 0.003765015552441279), (221, 0.003767503632439507), (447, 0.003769061631626553), (199, 0.0037757601175043318), (204, 0.0037776190373632642), (274, 0.003789835506015354), (116, 0.0037914042671521506), (247, 0.003794011970361074), (467, 0.003804357929362191), (29, 0.0038047764036390516), (144, 0.0038094561960962084), (2, 0.0038108999530474343), (487, 0.003816102941830953), (404, 0.003818696571720971), (440, 0.0038201709588368735), (206, 0.0038232310778564876), (444, 0.0038234715660413108), (494, 0.0038411476545863682), (389, 0.00384156819846895), (120, 0.0038427975442674425), (420, 0.003843854698869917), (341, 0.0038465865784221226), (202, 0.003847324185901218), (442, 0.0038475187288390267), (119, 0.0038497373461723328), (508, 0.0038556986384921605), (257, 0.003867334789699978), (449, 0.0038756123847431606), (80, 0.0038775851329167685), (141, 0.0038806580834918553), (229, 0.003886053131686317), (208, 0.003889476259549459), (412, 0.003892146878772312), (428, 0.003892207311259376), (504, 0.0038963937097125584), (10, 0.0039035239153438145), (250, 0.003910507592889998), (394, 0.003910635908444722), (59, 0.003916114568710327), (382, 0.003919084038999345), (263, 0.0039271095560656655), (260, 0.003933460762103398), (190, 0.0039342790842056274), (172, 0.0039359645711051095), (188, 0.003950194766124089), (167, 0.003985005120436351), (72, 0.003988301588429345), (254, 0.003990090141693751), (270, 0.0039918828341696), (192, 0.003992419275972579), (81, 0.0040090787741873), (151, 0.004015119539366828), (235, 0.004027698602941301), (84, 0.004034994790951411), (207, 0.004035196784469817), (488, 0.004037209682994419), (113, 0.00403736862871382), (324, 0.0040453751054075025), (128, 0.004048593756225374), (468, 0.00405295193195343), (300, 0.004053187039163377), (371, 0.004057504236698151), (150, 0.00405912846326828), (432, 0.004062911288605796), (388, 0.004064151396354039), (86, 0.004074176980389489), (125, 0.004076748258537716), (489, 0.0040794677204555934), (511, 0.004082897884978188), (193, 0.004090531004799737), (256, 0.004096801496214337), (391, 0.004102299196852578), (246, 0.004108353207508723), (439, 0.004110021723641289), (40, 0.004111808207299974), (76, 0.004117557571993934), (503, 0.00412211815516154), (142, 0.004124173687564002), (275, 0.004132657415337033), (51, 0.004133719950914383), (165, 0.004134109864632289), (306, 0.004157693849669563), (419, 0.004158577571312587), (8, 0.004164717677566741), (407, 0.004164731336964501), (347, 0.004165861755609512), (18, 0.004169337451457977), (32, 0.004171388016806709), (436, 0.004175059497356415), (176, 0.004177018172211117), (33, 0.004189875390794542), (7, 0.004204582009050582), (354, 0.004213767333163155), (310, 0.004217327468925052), (325, 0.0042180998457802665), (100, 0.004221851627031962), (302, 0.004223117397891151), (372, 0.004229290203915702), (318, 0.004233150432507197), (248, 0.004243554754389657), (15, 0.00424488302734163), (374, 0.004245176911354065), (152, 0.004252289732297261), (280, 0.004254848592811161), (320, 0.004259189797772301), (73, 0.00425992285211881), (47, 0.00426002550456259), (61, 0.004267901182174683), (282, 0.004275466005007426), (346, 0.004281130101945665), (12, 0.004285274280442132), (455, 0.004286095499992371), (316, 0.0042862676911883885), (231, 0.004287969734933641), (482, 0.004296086314651702), (129, 0.0043021726111571), (71, 0.004314192467265659), (448, 0.004316040211253696), (343, 0.004316139552328322), (315, 0.004327746729056041), (159, 0.0043282947606510585), (201, 0.004329231878121694), (479, 0.004348798344532649), (115, 0.004352076186074151), (368, 0.00435283738705847), (509, 0.004357259306642745), (185, 0.004359222120708889), (97, 0.004369499782721202), (477, 0.004373279710610707), (463, 0.004378239727682537), (293, 0.004385870777898365), (350, 0.00438625779416826), (399, 0.004396513104438782), (457, 0.004400020672215356), (311, 0.004402678045961592), (484, 0.004420570615265105), (57, 0.004440115557776557), (106, 0.004441894590854645), (39, 0.004444482839769787), (430, 0.00445210768116845), (417, 0.004453136689133114), (361, 0.00445634416408009), (155, 0.004464554289976756), (456, 0.004468169063329697), (333, 0.004469258917702569), (415, 0.004473292993174659), (309, 0.004480662859148449), (149, 0.004498552117082808), (327, 0.004506397578451369), (253, 0.004521483762396706), (287, 0.004527643322944641), (6, 0.004531905468967225), (219, 0.00454154693418079), (108, 0.004544915838374032), (446, 0.004547467662228478), (178, 0.004553110235267215), (130, 0.004564746386475033), (295, 0.0045679716600312125), (381, 0.004568020502726237), (233, 0.004575060473548042), (332, 0.004581313166353438), (277, 0.004591224922074212), (103, 0.00459326555331548), (20, 0.004601985216140747), (301, 0.004605374402470059), (501, 0.0046113042367829215), (375, 0.004620340135362413), (357, 0.004626129236486223), (377, 0.004626646637916565), (278, 0.004634117914570702), (79, 0.00464179159866439), (261, 0.004647028528981739), (276, 0.00465023559000757), (454, 0.004662685924106174), (314, 0.004680139323075612), (182, 0.0046856846246454455), (17, 0.004690408292743895), (292, 0.004690568066305584), (408, 0.00469129698144065), (210, 0.004693235374159283), (365, 0.004710197448730469), (243, 0.004736218601465225), (118, 0.00473928948243459), (163, 0.004751177297698127), (281, 0.004762142068809933), (437, 0.004769930409060584), (180, 0.00477440282702446), (50, 0.004788827978902393), (13, 0.00482397692071067), (491, 0.004826400842931535), (236, 0.004829770988888211), (41, 0.004836480650636885), (154, 0.0048509397440486485), (272, 0.004857692867517471), (443, 0.004875714166296853), (156, 0.004877170754803551), (462, 0.004888121038675308), (168, 0.0048985179099771715), (289, 0.004913341253995895), (483, 0.004920695390966203), (326, 0.004926760577493244), (475, 0.004927533782190747), (331, 0.004936380104886161), (38, 0.00494404426879353), (34, 0.0049466755655076765), (334, 0.004972950451903873), (317, 0.004984674768315421), (373, 0.00499870917863316), (414, 0.005018077790737152), (472, 0.0050221797492769026), (493, 0.005027691937155194), (64, 0.005027899311648475), (299, 0.005036413669586182), (390, 0.005040814479192098), (54, 0.005050526311000188), (342, 0.005053079790539212), (183, 0.0050575948423809474), (434, 0.005058211584885915), (366, 0.005061914109521442), (322, 0.005063796622885598), (470, 0.005064291258653005), (175, 0.005064358727799522), (471, 0.00508731934759352), (122, 0.005099607838524712), (268, 0.005099790791670482), (267, 0.0051109496917989515), (30, 0.0051210688220130075), (450, 0.005127073162131839), (401, 0.00513119250535965), (161, 0.005136352446344163), (291, 0.005162429064512253), (48, 0.005170647468831804), (418, 0.005181391206052568), (266, 0.005208826313416163), (286, 0.005230279432402717), (424, 0.005249564018514421), (242, 0.005260868204964532), (45, 0.0052685605155097116), (378, 0.005272469586796231), (297, 0.005277300046549903), (31, 0.005307348238097297), (232, 0.0053166358007325065), (481, 0.005317217773861355), (323, 0.005336126105652915), (171, 0.0053459422455893624), (380, 0.005375782648722331), (348, 0.00538164046075609), (506, 0.005386529697312249), (28, 0.005398380673593945), (296, 0.005407537851068709), (244, 0.0054191528922981685), (186, 0.005486106706990136), (335, 0.005642822219265832), (227, 0.0056517790589067675), (500, 0.005691550672054291), (237, 0.005698957377009922), (102, 0.00570570429166158), (216, 0.005707699391576979), (495, 0.0057101208302709795), (218, 0.00571587226457066), (445, 0.0057223935921986895), (345, 0.005739048537280824), (55, 0.005753825108210246), (169, 0.005826196322838466), (70, 0.005875448385874431), (264, 0.005895338952541351), (111, 0.005901653319597244), (88, 0.0059264227747917175), (26, 0.005960322088665432), (105, 0.005977775487634871), (238, 0.006001063105132844), (52, 0.006007842305633757), (137, 0.006008329076899422), (112, 0.0060211171706517535), (56, 0.00606098688311047), (465, 0.006069832377963596), (43, 0.006148057679335277), (351, 0.006200237406624688), (189, 0.0062104761600494385), (461, 0.006212009737888972), (16, 0.0062225328551398385), (37, 0.006311313973532783), (135, 0.006373551984628041), (211, 0.006396112342675527), (425, 0.006430796864959929), (321, 0.006464956121312248), (397, 0.0065070220993624795), (376, 0.006563490049706565), (497, 0.006683833069271511), (392, 0.00670463095108668), (259, 0.0068668598930041), (409, 0.006890693886412514), (98, 0.006947315401501126), (74, 0.006978581349054973), (62, 0.007283197508917915), (410, 0.0074860867526796125), (191, 0.007496854497326745), (110, 0.007527284324169159), (42, 0.007557170258627998), (241, 0.007633252276314629), (498, 0.00768918792406718), (478, 0.007871280113855997), (104, 0.007956417070494758), (338, 0.008049502968788147), (82, 0.0081470873620775), (234, 0.008247032761573792), (92, 0.008590471413400438), (226, 0.008827779855993059), (262, 0.010140635901027255), (344, 0.010671884649329715), (413, 0.011552997761302523), (23, 0.017802571256955464)]\n",
            "512\n",
            "L2 norm of conv_layer13\n",
            " [(207, 0.0022288945813973746), (452, 0.0026075285342004565), (37, 0.0026493420203526816), (41, 0.002666804939508438), (321, 0.0027226248963011634), (482, 0.002723725305663215), (350, 0.0028178880198134314), (48, 0.0029022093448374006), (87, 0.0029124576184484693), (196, 0.0029152159889539084), (373, 0.0029225084516737196), (82, 0.0029282505727476543), (457, 0.002938898487223519), (211, 0.0029918505913681453), (223, 0.0030079210797945657), (504, 0.003020031584633721), (191, 0.003027321149905523), (348, 0.0030298084020614624), (414, 0.003033717473347982), (88, 0.0030468611253632438), (352, 0.0030532098478741115), (443, 0.0030544932103819316), (430, 0.0030703465971681806), (104, 0.003076215171151691), (384, 0.003080737880534596), (252, 0.0030833615197075736), (426, 0.0030848061045010886), (386, 0.003096742762459649), (40, 0.00309898994035191), (188, 0.0031024511489603254), (281, 0.003108984480301539), (58, 0.0031273787220319114), (333, 0.0031292198432816398), (306, 0.0031383285919825235), (330, 0.0031452433516581855), (343, 0.003147479560640123), (173, 0.003149663201636738), (441, 0.0031500005473693213), (413, 0.0031754889835913977), (354, 0.0031866091820928785), (208, 0.0032009726597203147), (179, 0.0032166867620415157), (296, 0.0032172794971201154), (147, 0.0032208232829968133), (203, 0.0032241112656063503), (193, 0.003226867980427212), (467, 0.003228498415814506), (400, 0.003234566499789556), (489, 0.003236137123571502), (447, 0.0032389511664708457), (462, 0.003246609949403339), (154, 0.003246897210677465), (394, 0.003249842259618971), (181, 0.0032591064357095295), (445, 0.0032599280691809123), (500, 0.003262575094898542), (294, 0.0032653905865218905), (209, 0.003269301106532415), (106, 0.0032731915513674417), (162, 0.003276422205898497), (239, 0.0032807497514618766), (159, 0.003280753476752175), (183, 0.0032817135668463176), (272, 0.003282238625817829), (397, 0.003285137108630604), (49, 0.00328729757004314), (167, 0.0032905369169182247), (227, 0.003291315502590603), (398, 0.0032953015632099575), (117, 0.0032958537340164185), (311, 0.003295980600847138), (30, 0.0032984125945303175), (351, 0.003298711445596483), (496, 0.003308995937307676), (260, 0.0033138630290826163), (180, 0.0033159098691410488), (261, 0.0033173056112395394), (249, 0.003317839569515652), (449, 0.003321384597155783), (67, 0.00332635206480821), (453, 0.0033291218181451163), (283, 0.003330560194121467), (12, 0.003334636075629128), (486, 0.0033350514454974067), (396, 0.0033518384314245647), (498, 0.0033566742721531126), (14, 0.003370252541369862), (390, 0.0033749395774470437), (492, 0.0033753783338599736), (364, 0.0033793687406513426), (497, 0.003379587291015519), (65, 0.0033940602507856158), (45, 0.003394265141752031), (337, 0.0034010952545536887), (421, 0.0034039647628863654), (145, 0.0034041336427132287), (1, 0.0034045285234848657), (57, 0.003405816439125273), (429, 0.0034089446481731203), (121, 0.003410411791668998), (256, 0.0034120927254358926), (416, 0.003424357622861862), (353, 0.0034310931546820533), (190, 0.0034322626888751984), (344, 0.003443304035398695), (494, 0.0034443578786320156), (465, 0.0034447800781991747), (135, 0.0034455015427536434), (38, 0.00344955465859837), (155, 0.003449890348646376), (478, 0.003450633337100347), (92, 0.003450947089327706), (310, 0.0034543886366817686), (287, 0.003459751605987549), (24, 0.0034649715655379826), (362, 0.0034710117098357943), (158, 0.003472055825922224), (7, 0.0034761238429281446), (170, 0.00347885861992836), (483, 0.0034887914856274924), (237, 0.003493222097555796), (19, 0.0034937324623266854), (417, 0.00349660755859481), (50, 0.0035022530290815565), (174, 0.00350756405128373), (292, 0.003509008222156101), (73, 0.0035093161794874403), (270, 0.0035093617108133105), (393, 0.0035094693303108215), (70, 0.0035114379392729867), (510, 0.0035137306484911176), (123, 0.003517244839006), (304, 0.00351827343304952), (340, 0.0035188905894756317), (115, 0.003519957264264425), (4, 0.0035304812093575797), (182, 0.0035369466576311323), (20, 0.0035373494029045105), (322, 0.003538578748703003), (406, 0.00353989087873035), (464, 0.003542903396818373), (229, 0.0035468190908432007), (479, 0.0035476175447305045), (163, 0.003550569216410319), (111, 0.003551760067542394), (80, 0.003552079200744629), (389, 0.0035617686808109283), (357, 0.0035645696851942274), (177, 0.003569209741221534), (36, 0.003569499072101381), (71, 0.003570839762687683), (247, 0.0035731949739985997), (125, 0.0035754901667435965), (410, 0.003576500134335624), (75, 0.0035766934355099997), (502, 0.0035786570774184335), (52, 0.003579984108606974), (289, 0.0035824349357022178), (408, 0.0035836369627051884), (59, 0.003584961924288008), (411, 0.0035853791568014356), (112, 0.0035875261657767827), (284, 0.0035928181476063198), (278, 0.0035939630534913805), (146, 0.003596445752514733), (204, 0.003604763083987766), (491, 0.0036085997190740374), (234, 0.0036116792923874324), (189, 0.0036122906539175245), (355, 0.0036139562726020813), (401, 0.0036143126587073007), (484, 0.0036162791980637442), (403, 0.0036225029163890416), (21, 0.003622728917333815), (415, 0.0036240236626731027), (382, 0.0036243312060832977), (152, 0.0036297067999839783), (31, 0.0036313417885038587), (232, 0.0036314986646175385), (263, 0.0036334308485190072), (128, 0.0036344842778311837), (46, 0.003636496348513497), (221, 0.0036371234390470716), (228, 0.0036377588080035318), (127, 0.0036378084785408443), (157, 0.0036378328998883567), (295, 0.0036383618911107383), (236, 0.0036414658857716452), (468, 0.003641681124766668), (25, 0.003646497925122579), (144, 0.0036489367485046387), (285, 0.003649891664584478), (458, 0.003655204342471229), (150, 0.003655391020907296), (302, 0.0036567780706617567), (420, 0.003659651925166448), (315, 0.003662318405177858), (242, 0.0036628726455900404), (480, 0.0036691303054491677), (324, 0.0036750779383712346), (9, 0.003675764633549584), (18, 0.0036802002125316197), (212, 0.003680647247367435), (113, 0.0036849139465226066), (0, 0.0036850281887584263), (100, 0.0036859561999638877), (215, 0.0036871408422787986), (161, 0.0036928214960628087), (387, 0.003692838880750868), (303, 0.0036977028681172263), (3, 0.0036997770269711814), (276, 0.0037000630464818743), (379, 0.003704206811057197), (380, 0.003715026709768507), (129, 0.0037150676879617902), (165, 0.0037195243769221837), (176, 0.0037218170861403146), (243, 0.0037273441751797995), (142, 0.00372878834605217), (297, 0.0037349677748150295), (264, 0.003735007925166024), (84, 0.0037398330039448207), (434, 0.003742673330836826), (254, 0.0037447594934039647), (96, 0.003746533973349465), (238, 0.003747774495018853), (105, 0.003748832477463616), (197, 0.003749459981918335), (299, 0.0037543049289120566), (69, 0.0037602616680992972), (241, 0.0037620796097649466), (224, 0.0037678579489390054), (250, 0.003768722630209393), (103, 0.0037688244548108843), (425, 0.0037696522970994315), (291, 0.0037720460030767652), (94, 0.003773369722896152), (370, 0.0037830140855577257), (114, 0.003783383303218418), (85, 0.0037836978832880654), (463, 0.0037846689422925315), (23, 0.0037864852282736036), (422, 0.0037917171915372214), (138, 0.0037975824541515773), (13, 0.0037997249099943372), (442, 0.003811176452371809), (404, 0.0038139426873789895), (437, 0.003814135988553365), (42, 0.0038151037361886767), (338, 0.0038169316119617885), (95, 0.0038196874989403617), (432, 0.00382076534960005), (349, 0.0038255121972825793), (8, 0.003826265533765157), (60, 0.0038305570681889853), (456, 0.0038344450294971466), (153, 0.0038345716893672943), (342, 0.003834664821624756), (5, 0.0038351035780376857), (499, 0.003835678514507082), (122, 0.0038380432460043165), (255, 0.0038404266039530435), (269, 0.003841432432333628), (334, 0.0038427329725689357), (300, 0.0038432321614689296), (116, 0.003851150472958883), (83, 0.003854850927988688), (371, 0.0038574693931473624), (314, 0.0038577214711242253), (32, 0.0038608391251828936), (366, 0.003863039943906996), (377, 0.003863133490085602), (166, 0.0038667461938328212), (273, 0.0038680562542544473), (118, 0.0038717505004670885), (2, 0.003876452230744892), (444, 0.003876891401078966), (63, 0.0038771985305680167), (11, 0.003880766530831655), (240, 0.0038815082775221933), (424, 0.003887366917398241), (274, 0.00389075775941213), (143, 0.003894591083129247), (210, 0.0038959508140881858), (395, 0.0039003309276368883), (136, 0.003904709385501014), (206, 0.003907358480824364), (186, 0.003907512459490035), (391, 0.003907519910070632), (280, 0.003909728593296475), (214, 0.003920993043316735), (471, 0.003923123909367455), (383, 0.003925875243213441), (51, 0.003930650237533782), (235, 0.00393139984872606), (359, 0.003931705322530534), (318, 0.003935563895437453), (66, 0.003939359552330441), (368, 0.003945397833983104), (501, 0.003946055554681354), (323, 0.0039485957887437605), (26, 0.003959241012732188), (248, 0.003961389677392112), (495, 0.003964051604270935), (505, 0.003975977500279744), (392, 0.003976842181550132), (226, 0.003977215538422267), (216, 0.003977997021542655), (76, 0.003980483031935162), (91, 0.003981089012490379), (140, 0.0039831896622975664), (97, 0.003984309732913971), (72, 0.003984667774703767), (435, 0.003989023466904958), (374, 0.003989189035362667), (124, 0.0039900251560741), (293, 0.003994200792577531), (279, 0.00400064554479387), (363, 0.00400289065308041), (56, 0.0040090373820728725), (506, 0.004010985294977824), (265, 0.004012345853779051), (298, 0.0040145280460516615), (61, 0.0040197715991073186), (222, 0.004026952717039321), (231, 0.004028140670723385), (164, 0.004030713190635045), (102, 0.004036098304722045), (141, 0.004038507739702861), (6, 0.004041520257790883), (317, 0.004046262138419681), (473, 0.004046501384841071), (151, 0.004047228230370415), (369, 0.004052773945861393), (313, 0.004053102599249946), (367, 0.004057036091883977), (320, 0.004062594638930427), (185, 0.004062973376777437), (81, 0.004066978063848283), (77, 0.0040683017836676705), (202, 0.004075022207366096), (282, 0.004075460549857881), (335, 0.004075942354069816), (385, 0.004081413977675968), (308, 0.004084739006227917), (455, 0.004085507657792833), (205, 0.0040862419539027745), (470, 0.004087420801321666), (475, 0.004090276857217153), (133, 0.00409042669667138), (131, 0.004108969950013691), (110, 0.00411712709400389), (446, 0.00411825171775288), (201, 0.0041214823722839355), (405, 0.004122558567259047), (89, 0.0041239216095871395), (332, 0.004129133290714688), (485, 0.004132354838980569), (62, 0.004132792353630066), (436, 0.004137864543331994), (511, 0.004139666342073017), (409, 0.004141088161203597), (375, 0.004144139587879181), (472, 0.004144800206025441), (451, 0.004147482415040334), (267, 0.004150469270017412), (372, 0.004156012501981523), (130, 0.004159240259064568), (132, 0.004170501397715675), (286, 0.004173424922757679), (220, 0.004174036698208915), (466, 0.004175117446316613), (345, 0.004178555475340949), (347, 0.004183093706766765), (34, 0.0041849058535363935), (28, 0.004185003125005298), (507, 0.004186633560392592), (454, 0.004191896981663174), (78, 0.0041990263594521415), (245, 0.0042006754212909276), (230, 0.00420696743660503), (388, 0.004208284119764964), (200, 0.004209109892447789), (54, 0.004214605523480309), (358, 0.00421857088804245), (101, 0.004231492678324382), (171, 0.004231847822666168), (195, 0.004232162402735816), (271, 0.0042360226313273115), (331, 0.004258547392156389), (319, 0.004259895119402144), (22, 0.004261967622571521), (336, 0.004263624548912048), (481, 0.00426575168967247), (148, 0.004266132083204057), (328, 0.004280906170606613), (327, 0.004284482035371993), (339, 0.004286752806769477), (509, 0.004292653252681096), (184, 0.004292709545956718), (119, 0.004294678568840027), (346, 0.004306527475516002), (27, 0.00431075899137391), (93, 0.00431409478187561), (305, 0.0043187542921966976), (325, 0.0043208421104484135), (266, 0.004325174623065525), (217, 0.004325373305214776), (47, 0.004333341287242042), (244, 0.004337136116292741), (15, 0.004338633682992723), (419, 0.004340664794047673), (39, 0.004345554444524977), (134, 0.004353387488259209), (253, 0.004374749958515167), (137, 0.0043782248265213436), (90, 0.004379242244693968), (312, 0.0043841708037588335), (79, 0.004386407633622487), (399, 0.004404309723112319), (35, 0.004415171013938056), (493, 0.004419448888964123), (213, 0.004429350296656291), (450, 0.004432640141910977), (258, 0.004435920466979344), (356, 0.004438023600313399), (378, 0.00443810804022683), (68, 0.004453601936499278), (402, 0.004469773835606045), (307, 0.004479116035832299), (423, 0.004487332370546129), (225, 0.004498218910561668), (460, 0.004501518276002672), (156, 0.004513685488038593), (64, 0.004513830774360233), (503, 0.004536306692494286), (160, 0.004540929363833534), (187, 0.004548366698953841), (407, 0.004549764924579197), (326, 0.0045529864728450775), (360, 0.004562666846646203), (139, 0.004564782811535729), (439, 0.004591998126771715), (74, 0.0045955607460604776), (246, 0.004597065349419911), (257, 0.004627221160464817), (194, 0.0046389297478728825), (120, 0.00464973971247673), (476, 0.0046581120954619516), (55, 0.0046604300538698835), (474, 0.004662415633598964), (44, 0.004667735762066311), (309, 0.004668461365832223), (251, 0.004677607367436091), (277, 0.004703914953602685), (440, 0.004739452567365434), (329, 0.004746990071402656), (412, 0.004749647031227748), (288, 0.004759734289513694), (198, 0.004767492827441957), (438, 0.004776064720418718), (428, 0.004783567869000965), (33, 0.004787349038653904), (149, 0.0048279377321402235), (16, 0.004858276496330897), (508, 0.004861415260367923), (218, 0.004866453508536021), (365, 0.00488777831196785), (126, 0.0049018243120776284), (178, 0.004904843038982815), (172, 0.004909256680144204), (461, 0.004916595915953319), (107, 0.0049258458117643995), (275, 0.004958008312516742), (10, 0.0049732766217655605), (487, 0.004974279966619279), (459, 0.004993422577778499), (301, 0.005009575850433773), (168, 0.005012287033928765), (219, 0.0050370461410946315), (53, 0.005060501396656036), (175, 0.00507775280210707), (361, 0.005117626653777229), (268, 0.005119493438137902), (477, 0.005133146213160621), (199, 0.00514711191256841), (341, 0.005256029880709118), (262, 0.005268673929903243), (233, 0.005361689461602105), (448, 0.0054038166999816895), (43, 0.005465499228901333), (431, 0.005517454197009404), (169, 0.005568228662014008), (488, 0.0055819472504986655), (192, 0.005693622761302524), (259, 0.005700683842102687), (316, 0.005711618810892105), (490, 0.005798441668351491), (290, 0.0058000874188211225), (29, 0.005918218029869927), (109, 0.005925844113032023), (17, 0.0060113101369804805), (381, 0.006144139915704727), (433, 0.006164822313520644), (427, 0.006232635014586979), (469, 0.006716662810908424), (86, 0.006727101074324714), (418, 0.007149082091119554), (376, 0.007194465233219994), (108, 0.00936960263384713), (99, 0.010120397640599145), (98, 0.013856760329670377)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orVrjK7MlQTw",
        "outputId": "e9a7cb81-14c0-4aa6-910b-479994bf3cab"
      },
      "source": [
        "num_del_layer_wise"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 8, 8, 17, 17, 33, 33, 33, 67, 67, 67, 67, 67]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f56fu6Kv9lbD"
      },
      "source": [
        "layer=[1,2,4,5,7,8,9,11,12,13,15,16,17]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6836o_8UpiRL",
        "outputId": "e2871560-37dd-42bd-858e-6cb6035b8af0"
      },
      "source": [
        "new_model=model\n",
        "for i in range(1,len(num_del_layer_wise)):\n",
        "   surgeon = Surgeon(new_model)\n",
        "   all_sorted_chanels_of_layer_i=[]#getting the channels which need to be deleted\n",
        "   for ch in weights_dic_sort[i]:\n",
        "     all_sorted_chanels_of_layer_i.append(ch[0])\n",
        "   chanels=[]\n",
        "   for k in range(num_del_layer_wise[i]):\n",
        "     chanels.append(all_sorted_chanels_of_layer_i[k])\n",
        "   surgeon.add_job('delete_channels', new_model.layers[layer[i]], channels=chanels)#deleting the channels at each layer\n",
        "  #  all_sorted_chanels_of_layer_i.clear()\n",
        "  #  chanels.clear()\n",
        "   new_model = surgeon.operate()#fine tuning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deleting 8/64 channels from layer: block1_conv2\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Deleting 8/128 channels from layer: block2_conv1\n",
            "Deleting 17/128 channels from layer: block2_conv2\n",
            "Deleting 17/256 channels from layer: block3_conv1\n",
            "Deleting 33/256 channels from layer: block3_conv2\n",
            "Deleting 33/256 channels from layer: block3_conv3\n",
            "Deleting 33/512 channels from layer: block4_conv1\n",
            "Deleting 67/512 channels from layer: block4_conv2\n",
            "Deleting 67/512 channels from layer: block4_conv3\n",
            "Deleting 67/512 channels from layer: block5_conv1\n",
            "Deleting 67/512 channels from layer: block5_conv2\n",
            "Deleting 67/512 channels from layer: block5_conv3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q20DHGLsjiyq",
        "outputId": "c5e6c9c9-bdf8-45a6-c05f-7ffc8aa7a670"
      },
      "source": [
        "new_model.compile(loss = 'categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])#recompiling the model\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 56)      32312     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 120)     60600     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 111)     119991    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 239)       239000    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 223)       479896    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 223)       447784    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 479)       961832    \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 445)       1918840   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 445)       1782670   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 445)       1782670   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 445)       1782670   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 445)       1782670   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              89317376  \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 121,588,415\n",
            "Trainable params: 121,588,415\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J47Ji6J5r_9P"
      },
      "source": [
        "evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9ywKsuMsBxQ"
      },
      "source": [
        "# new_model.evaluate(test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsyGF_q29ANc"
      },
      "source": [
        "total_time=0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSWW5Fyhqm66",
        "outputId": "7954a3ff-3256-4857-b231-d9de80af23ae"
      },
      "source": [
        "pred_m = []\n",
        "\n",
        "for filename in os.listdir(path):\n",
        "    label = filename.split('_')[0]\n",
        "    file_path = path + \"/\" + filename\n",
        "    x=time.time()\n",
        "    image=tf.keras.preprocessing.image.load_img(file_path, target_size=(224, 224))  # reading image (Folder path and image name )\n",
        "      \n",
        "    image=np.array(image)\n",
        "    image=image.reshape((1,image.shape[0],image.shape[1],image.shape[2]))\n",
        "    image=preprocess_input(image)\n",
        "\n",
        "    op1=new_model.predict(image)\n",
        "    y=time.time()\n",
        "    total_time = total_time + (y-x)\n",
        "    label1=decode_predictions(op1,top=1)\n",
        "    pred_m.append([label, label1[0][0][0]])\n",
        "\n",
        "count = 0\n",
        "for i in range(len(pred_m)):\n",
        "  if pred_m[i][0] == pred_m[i][1] :\n",
        "    count = count + 1\n",
        "\n",
        "print(\"####### FOR RATE : \", r)\n",
        "print('Model Flops : ', modelFlops(new_model))\n",
        "print('Total : ', len(pred_m), ', Correct : ', count, ', Accuracy : ', (100*count/len(pred_m)))\n",
        "print('Time Taken for prediction : ', (total_time/len(pred_m)) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "40960/35363 [==================================] - 0s 0us/step\n",
            "####### FOR RATE :  0.13\n",
            "Model Flops :  24866417876\n",
            "Total :  84 , Correct :  75 , Accuracy :  89.28571428571429\n",
            "Time Taken for prediction :  0.10284691481363206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UEkRZagzm6Z"
      },
      "source": [
        "saving New model after pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quTt6GKOw5BN"
      },
      "source": [
        "new_model.save(\"new_vgg4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9FmLUvLzrXH"
      },
      "source": [
        "Checking the model size after pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIT5jF--xJ6u",
        "outputId": "982e1b75-9319-40f3-dc72-a3f108bb6748"
      },
      "source": [
        "import os\n",
        "import math\n",
        "# Get file size in bytes for a given model\n",
        "print(\"Model size after pruning=>\",(os.stat('/content/new_vgg4').st_size)/math.pow(2,20),\" Mega Bytes\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model size after pruning=> 463.90422439575195  Mega Bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxJbVGMQTrMi"
      },
      "source": [
        "Parameters Reading(Calculating all the parameters for all the different rates)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m9XecNPrLWy"
      },
      "source": [
        "rates_m=[0]\n",
        "params_m=[138357544]\n",
        "model_size_m=[527.8]\n",
        "accuracy_m=[98.8]\n",
        "flops_m=[30932349056]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVnpeyssTvSS",
        "outputId": "1da47dbd-e9ca-490e-c6f7-7946a6ec9642"
      },
      "source": [
        "rates=[0.01,0.02,0.03,0.04,0.05,0.06,0.07]#different values of rates\n",
        "k=0\n",
        "for r in rates:\n",
        "  #counting number of channels to delete layerwise\n",
        "  rates_m.append(r)\n",
        "  print(\"######################################################################################################################################################################\")\n",
        "  num_del_layer_wise=[0]*13\n",
        "  total_time=0.0\n",
        "  for i in range(len(conv_layer_weights)):\n",
        "    weight=conv_layer_weights[i]\n",
        "    #weights_dic={}\n",
        "    num_filters=len(weight[0][0][0])\n",
        "    if i!=0:\n",
        "      num_del_layer_wise[i]=round(num_filters*r)\n",
        "  print(\"Number of channels to delete layerwise: \",num_del_layer_wise)\n",
        "  #initialising new model for pruning\n",
        "  new_model=tf.keras.applications.vgg16.VGG16(weights='imagenet',include_top=True)\n",
        "  new_model.summary()\n",
        "\n",
        "  #pruning the model\n",
        "  for i in range(1,len(num_del_layer_wise)):\n",
        "    surgeon = Surgeon(new_model)\n",
        "    all_sorted_chanels_of_layer_i=[]\n",
        "    for ch in weights_dic_sort[i]:\n",
        "      all_sorted_chanels_of_layer_i.append(ch[0])\n",
        "    chanels=[]\n",
        "    for k in range(num_del_layer_wise[i]):\n",
        "      chanels.append(all_sorted_chanels_of_layer_i[k])\n",
        "    surgeon.add_job('delete_channels', new_model.layers[layer[i]], channels=chanels)\n",
        "    #  all_sorted_chanels_of_layer_i.clear()\n",
        "    #  chanels.clear()\n",
        "    new_model = surgeon.operate()\n",
        "\n",
        "  new_model.compile(loss = 'categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
        "  new_model.summary()\n",
        "  #calculating parameters\n",
        "  pred_m = []\n",
        "\n",
        "  for filename in os.listdir(path):\n",
        "      label = filename.split('_')[0]\n",
        "      file_path = path + \"/\" + filename\n",
        "      x=time.time()\n",
        "      image=tf.keras.preprocessing.image.load_img(file_path, target_size=(224, 224))  # reading image (Folder path and image name )\n",
        "        \n",
        "      image=np.array(image)\n",
        "      image=image.reshape((1,image.shape[0],image.shape[1],image.shape[2]))\n",
        "      image=preprocess_input(image)\n",
        "\n",
        "      op1=new_model.predict(image)\n",
        "      y=time.time()\n",
        "      total_time = total_time + (y-x)\n",
        "      label1=decode_predictions(op1,top=1)\n",
        "      pred_m.append([label, label1[0][0][0]])\n",
        "\n",
        "  count = 0\n",
        "  for i in range(len(pred_m)):\n",
        "    if pred_m[i][0] == pred_m[i][1] :\n",
        "      count = count + 1\n",
        "\n",
        "  print(\"####### FOR RATE : \", r)\n",
        "  print('Model Flops : ', modelFlops(new_model))\n",
        "  flops_m.append(modelFlops(new_model))\n",
        "  print('Total : ', len(pred_m), ', Correct : ', count, ', Accuracy : ', (100*count/len(pred_m)))\n",
        "  accuracy_m.append((100*count/len(pred_m)))\n",
        "  print('Time Taken for prediction : ', (total_time/len(pred_m)) )\n",
        "  print(\"Number of parameter after pruning\",new_model.count_params())\n",
        "  params_m.append(new_model.count_params())\n",
        "  new_model.save((\"vgg16_m_\"+str(k)))\n",
        "  frm = \"/content/\" + \"vgg16_m_\" + str(k)\n",
        "  print(\"Model size after pruning=>\",(os.stat(frm).st_size)/math.pow(2,20),\" Mega Bytes\")\n",
        "  model_size_m.append((os.stat(frm).st_size)/math.pow(2,20))\n",
        "  k+=1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "######################################################################################################################################################################\n",
            "Number of channels to delete layerwise:  [0, 1, 1, 1, 1, 3, 3, 3, 5, 5, 5, 5, 5]\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Deleting 1/64 channels from layer: block1_conv2\n",
            "Deleting 1/128 channels from layer: block2_conv1\n",
            "Deleting 1/128 channels from layer: block2_conv2\n",
            "Deleting 1/256 channels from layer: block3_conv1\n",
            "Deleting 3/256 channels from layer: block3_conv2\n",
            "Deleting 3/256 channels from layer: block3_conv3\n",
            "Deleting 3/512 channels from layer: block4_conv1\n",
            "Deleting 5/512 channels from layer: block4_conv2\n",
            "Deleting 5/512 channels from layer: block4_conv3\n",
            "Deleting 5/512 channels from layer: block5_conv1\n",
            "Deleting 5/512 channels from layer: block5_conv2\n",
            "Deleting 5/512 channels from layer: block5_conv3\n",
            "Model: \"model_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 63)      36351     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 127)     72136     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 127)     145288    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 255)       291720    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 253)       580888    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 253)       576334    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 509)       1159502   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 507)       2323074   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 507)       2313948   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 507)       2313948   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 507)       2313948   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 507)       2313948   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              101761024 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 137,082,213\n",
            "Trainable params: 137,082,213\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "####### FOR RATE :  0.01\n",
            "Model Flops :  30390582674\n",
            "Total :  84 , Correct :  80 , Accuracy :  95.23809523809524\n",
            "Time Taken for prediction :  0.030627083210718064\n",
            "Number of parameter after pruning 137082213\n",
            "Model size after pruning=> 523.0066719055176  Mega Bytes\n",
            "######################################################################################################################################################################\n",
            "Number of channels to delete layerwise:  [0, 1, 1, 3, 3, 5, 5, 5, 10, 10, 10, 10, 10]\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Deleting 1/64 channels from layer: block1_conv2\n",
            "Deleting 1/128 channels from layer: block2_conv1\n",
            "Deleting 3/128 channels from layer: block2_conv2\n",
            "Deleting 3/256 channels from layer: block3_conv1\n",
            "Deleting 5/256 channels from layer: block3_conv2\n",
            "Deleting 5/256 channels from layer: block3_conv3\n",
            "Deleting 5/512 channels from layer: block4_conv1\n",
            "Deleting 10/512 channels from layer: block4_conv2\n",
            "Deleting 10/512 channels from layer: block4_conv3\n",
            "Deleting 10/512 channels from layer: block5_conv1\n",
            "Deleting 10/512 channels from layer: block5_conv2\n",
            "Deleting 10/512 channels from layer: block5_conv3\n",
            "Model: \"model_36\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 63)      36351     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 127)     72136     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 125)     143000    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 253)       284878    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 251)       571778    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 251)       567260    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 507)       1145820   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 502)       2291128   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 502)       2268538   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 502)       2268538   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 502)       2268538   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 502)       2268538   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              100757504 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 135,824,111\n",
            "Trainable params: 135,824,111\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "####### FOR RATE :  0.02\n",
            "Model Flops :  29978173943\n",
            "Total :  84 , Correct :  81 , Accuracy :  96.42857142857143\n",
            "Time Taken for prediction :  0.030463096641358874\n",
            "Number of parameter after pruning 135824111\n",
            "Model size after pruning=> 518.2075271606445  Mega Bytes\n",
            "######################################################################################################################################################################\n",
            "Number of channels to delete layerwise:  [0, 2, 2, 4, 4, 8, 8, 8, 15, 15, 15, 15, 15]\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Deleting 2/64 channels from layer: block1_conv2\n",
            "Deleting 2/128 channels from layer: block2_conv1\n",
            "Deleting 4/128 channels from layer: block2_conv2\n",
            "Deleting 4/256 channels from layer: block3_conv1\n",
            "Deleting 8/256 channels from layer: block3_conv2\n",
            "Deleting 8/256 channels from layer: block3_conv3\n",
            "Deleting 8/512 channels from layer: block4_conv1\n",
            "Deleting 15/512 channels from layer: block4_conv2\n",
            "Deleting 15/512 channels from layer: block4_conv3\n",
            "Deleting 15/512 channels from layer: block5_conv1\n",
            "Deleting 15/512 channels from layer: block5_conv2\n",
            "Deleting 15/512 channels from layer: block5_conv3\n",
            "Model: \"model_48\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 62)      35774     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 126)     70434     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 124)     140740    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 252)       281484    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 248)       562712    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 248)       553784    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 504)       1125432   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 497)       2254889   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 497)       2223578   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 497)       2223578   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 497)       2223578   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 497)       2223578   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              99753984  \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 134,553,649\n",
            "Trainable params: 134,553,649\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "####### FOR RATE :  0.03\n",
            "Model Flops :  29444253833\n",
            "Total :  84 , Correct :  80 , Accuracy :  95.23809523809524\n",
            "Time Taken for prediction :  0.03578626541864304\n",
            "Number of parameter after pruning 134553649\n",
            "Model size after pruning=> 513.3612442016602  Mega Bytes\n",
            "######################################################################################################################################################################\n",
            "Number of channels to delete layerwise:  [0, 3, 3, 5, 5, 10, 10, 10, 20, 20, 20, 20, 20]\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Deleting 3/64 channels from layer: block1_conv2\n",
            "Deleting 3/128 channels from layer: block2_conv1\n",
            "Deleting 5/128 channels from layer: block2_conv2\n",
            "Deleting 5/256 channels from layer: block3_conv1\n",
            "Deleting 10/256 channels from layer: block3_conv2\n",
            "Deleting 10/256 channels from layer: block3_conv3\n",
            "Deleting 10/512 channels from layer: block4_conv1\n",
            "Deleting 20/512 channels from layer: block4_conv2\n",
            "Deleting 20/512 channels from layer: block4_conv3\n",
            "Deleting 20/512 channels from layer: block5_conv1\n",
            "Deleting 20/512 channels from layer: block5_conv2\n",
            "Deleting 20/512 channels from layer: block5_conv3\n",
            "Model: \"model_60\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 61)      35197     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 125)     68750     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 123)     138498    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 251)       278108    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 246)       555960    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 246)       544890    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 502)       1111930   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 492)       2223348   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 492)       2179068   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 492)       2179068   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 492)       2179068   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 492)       2179068   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              98750464  \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 133,303,521\n",
            "Trainable params: 133,303,521\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "####### FOR RATE :  0.04\n",
            "Model Flops :  28973985902\n",
            "Total :  84 , Correct :  80 , Accuracy :  95.23809523809524\n",
            "Time Taken for prediction :  0.03831685724712554\n",
            "Number of parameter after pruning 133303521\n",
            "Model size after pruning=> 508.5925178527832  Mega Bytes\n",
            "######################################################################################################################################################################\n",
            "Number of channels to delete layerwise:  [0, 3, 3, 6, 6, 13, 13, 13, 26, 26, 26, 26, 26]\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Deleting 3/64 channels from layer: block1_conv2\n",
            "Deleting 3/128 channels from layer: block2_conv1\n",
            "Deleting 6/128 channels from layer: block2_conv2\n",
            "Deleting 6/256 channels from layer: block3_conv1\n",
            "Deleting 13/256 channels from layer: block3_conv2\n",
            "Deleting 13/256 channels from layer: block3_conv3\n",
            "Deleting 13/512 channels from layer: block4_conv1\n",
            "Deleting 26/512 channels from layer: block4_conv2\n",
            "Deleting 26/512 channels from layer: block4_conv3\n",
            "Deleting 26/512 channels from layer: block5_conv1\n",
            "Deleting 26/512 channels from layer: block5_conv2\n",
            "Deleting 26/512 channels from layer: block5_conv3\n",
            "Model: \"model_72\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 61)      35197     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 125)     68750     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 122)     137372    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 250)       274750    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 243)       546993    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 243)       531684    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 499)       1091812   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 486)       2183112   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 486)       2126250   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 486)       2126250   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 486)       2126250   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 486)       2126250   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              97546240  \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 131,801,014\n",
            "Trainable params: 131,801,014\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "####### FOR RATE :  0.05\n",
            "Model Flops :  28543729797\n",
            "Total :  84 , Correct :  83 , Accuracy :  98.80952380952381\n",
            "Time Taken for prediction :  0.039915005366007485\n",
            "Number of parameter after pruning 131801014\n",
            "Model size after pruning=> 502.8610649108887  Mega Bytes\n",
            "######################################################################################################################################################################\n",
            "Number of channels to delete layerwise:  [0, 4, 4, 8, 8, 15, 15, 15, 31, 31, 31, 31, 31]\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Deleting 4/64 channels from layer: block1_conv2\n",
            "Deleting 4/128 channels from layer: block2_conv1\n",
            "Deleting 8/128 channels from layer: block2_conv2\n",
            "Deleting 8/256 channels from layer: block3_conv1\n",
            "Deleting 15/256 channels from layer: block3_conv2\n",
            "Deleting 15/256 channels from layer: block3_conv3\n",
            "Deleting 15/512 channels from layer: block4_conv1\n",
            "Deleting 31/512 channels from layer: block4_conv2\n",
            "Deleting 31/512 channels from layer: block4_conv3\n",
            "Deleting 31/512 channels from layer: block5_conv1\n",
            "Deleting 31/512 channels from layer: block5_conv2\n",
            "Deleting 31/512 channels from layer: block5_conv3\n",
            "Model: \"model_84\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 60)      34620     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 124)     67084     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 120)     134040    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 248)       268088    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 241)       538153    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 241)       522970    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 497)       1078490   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 481)       2151994   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 481)       2082730   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 481)       2082730   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 481)       2082730   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 481)       2082730   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              96542720  \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 130,549,183\n",
            "Trainable params: 130,549,183\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "####### FOR RATE :  0.06\n",
            "Model Flops :  28017684184\n",
            "Total :  84 , Correct :  82 , Accuracy :  97.61904761904762\n",
            "Time Taken for prediction :  0.0467839553242638\n",
            "Number of parameter after pruning 130549183\n",
            "Model size after pruning=> 498.0858497619629  Mega Bytes\n",
            "######################################################################################################################################################################\n",
            "Number of channels to delete layerwise:  [0, 4, 4, 9, 9, 18, 18, 18, 36, 36, 36, 36, 36]\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Deleting 4/64 channels from layer: block1_conv2\n",
            "Deleting 4/128 channels from layer: block2_conv1\n",
            "Deleting 9/128 channels from layer: block2_conv2\n",
            "Deleting 9/256 channels from layer: block3_conv1\n",
            "Deleting 18/256 channels from layer: block3_conv2\n",
            "Deleting 18/256 channels from layer: block3_conv3\n",
            "Deleting 18/512 channels from layer: block4_conv1\n",
            "Deleting 36/512 channels from layer: block4_conv2\n",
            "Deleting 36/512 channels from layer: block4_conv3\n",
            "Deleting 36/512 channels from layer: block5_conv1\n",
            "Deleting 36/512 channels from layer: block5_conv2\n",
            "Deleting 36/512 channels from layer: block5_conv3\n",
            "Model: \"model_96\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 60)      34620     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 124)     67084     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 119)     132923    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 247)       264784    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 238)       529312    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 238)       510034    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 494)       1058642   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 476)       2116772   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 476)       2039660   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 476)       2039660   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 476)       2039660   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 476)       2039660   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              95539200  \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 129,292,115\n",
            "Trainable params: 129,292,115\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "####### FOR RATE :  0.07\n",
            "Model Flops :  27625907196\n",
            "Total :  84 , Correct :  80 , Accuracy :  95.23809523809524\n",
            "Time Taken for prediction :  0.048262576262156166\n",
            "Number of parameter after pruning 129292115\n",
            "Model size after pruning=> 493.2906913757324  Mega Bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg0y4yWcudWO",
        "outputId": "25875add-c593-46b4-a31c-fd9b2e799339"
      },
      "source": [
        "print(rates_m)\n",
        "print(accuracy_m)\n",
        "print(params_m)\n",
        "print(model_size_m)\n",
        "print(flops_m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07]\n",
            "[98.8, 95.23809523809524, 96.42857142857143, 95.23809523809524, 95.23809523809524, 98.80952380952381, 97.61904761904762, 95.23809523809524]\n",
            "[138357544, 137082213, 135824111, 134553649, 133303521, 131801014, 130549183, 129292115]\n",
            "[527.8, 523.0066719055176, 518.2075271606445, 513.3612442016602, 508.5925178527832, 502.8610649108887, 498.0858497619629, 493.2906913757324]\n",
            "[30932349056, 30390582674, 29978173943, 29444253833, 28973985902, 28543729797, 28017684184, 27625907196]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "WQPjSt8RLcdV",
        "outputId": "06e82b50-bffe-4fed-f126-2b570654d29a"
      },
      "source": [
        "fig,a =  plt.subplots(2,2)\n",
        "a[0][0].plot(rates_m,params_m)\n",
        "a[0][0].set_title('Rate Vs. Parameters')\n",
        "a[0][1].plot(rates_m,model_size_m)\n",
        "a[0][1].set_title('Rate Vs. mode_size')\n",
        "a[1][0].plot(rates_m,accuracy_m)\n",
        "a[1][0].set_title('Rate Vs. Accuracy')\n",
        "a[1][1].plot(rates_m,flops_m)\n",
        "a[1][1].set_title('Rate Vs. flops')\n",
        "fig.tight_layout()\n",
        "fig.set_size_inches(15, 10)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MnfDwv4PqtGM",
        "outputId": "c4b75afd-ba7c-41f5-c5c9-b759e3f3de62"
      },
      "source": [
        "rates=[0.08,0.09,0.10,0.12,0.14,0.16]#different values of rates\n",
        "k=7\n",
        "for r in rates:\n",
        "  #counting number of channels to delete layerwise\n",
        "  rates_m.append(r)\n",
        "  print(\"######################################################################################################################################################################\")\n",
        "  num_del_layer_wise=[0]*13\n",
        "  total_time=0.0\n",
        "  for i in range(len(conv_layer_weights)):\n",
        "    weight=conv_layer_weights[i]\n",
        "    #weights_dic={}\n",
        "    num_filters=len(weight[0][0][0])\n",
        "    if i!=0:\n",
        "      num_del_layer_wise[i]=round(num_filters*r)\n",
        "  print(\"Number of channels to delete layerwise: \",num_del_layer_wise)\n",
        "  #initialising new model for pruning\n",
        "  new_model=tf.keras.applications.vgg16.VGG16(weights='imagenet',include_top=True)\n",
        "  new_model.summary()\n",
        "\n",
        "  #pruning the model\n",
        "  for i in range(1,len(num_del_layer_wise)):\n",
        "    surgeon = Surgeon(new_model)\n",
        "    all_sorted_chanels_of_layer_i=[]\n",
        "    for ch in weights_dic_sort[i]:\n",
        "      all_sorted_chanels_of_layer_i.append(ch[0])\n",
        "    chanels=[]\n",
        "    for k in range(num_del_layer_wise[i]):\n",
        "      chanels.append(all_sorted_chanels_of_layer_i[k])\n",
        "    surgeon.add_job('delete_channels', new_model.layers[layer[i]], channels=chanels)\n",
        "    #  all_sorted_chanels_of_layer_i.clear()\n",
        "    #  chanels.clear()\n",
        "    new_model = surgeon.operate()\n",
        "\n",
        "  new_model.compile(loss = 'categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
        "  new_model.summary()\n",
        "  #calculating parameters\n",
        "  pred_m = []\n",
        "\n",
        "  for filename in os.listdir(path):\n",
        "      label = filename.split('_')[0]\n",
        "      file_path = path + \"/\" + filename\n",
        "      x=time.time()\n",
        "      image=tf.keras.preprocessing.image.load_img(file_path, target_size=(224, 224))  # reading image (Folder path and image name )\n",
        "        \n",
        "      image=np.array(image)\n",
        "      image=image.reshape((1,image.shape[0],image.shape[1],image.shape[2]))\n",
        "      image=preprocess_input(image)\n",
        "\n",
        "      op1=new_model.predict(image)\n",
        "      y=time.time()\n",
        "      total_time = total_time + (y-x)\n",
        "      label1=decode_predictions(op1,top=1)\n",
        "      pred_m.append([label, label1[0][0][0]])\n",
        "\n",
        "  count = 0\n",
        "  for i in range(len(pred_m)):\n",
        "    if pred_m[i][0] == pred_m[i][1] :\n",
        "      count = count + 1\n",
        "\n",
        "  print(\"####### FOR RATE : \", r)\n",
        "  print('Model Flops : ', modelFlops(new_model))\n",
        "  flops_m.append(modelFlops(new_model))\n",
        "  print('Total : ', len(pred_m), ', Correct : ', count, ', Accuracy : ', (100*count/len(pred_m)))\n",
        "  accuracy_m.append((100*count/len(pred_m)))\n",
        "  print('Time Taken for prediction : ', (total_time/len(pred_m)) )\n",
        "  print(\"Number of parameter after pruning\",new_model.count_params())\n",
        "  params_m.append(new_model.count_params())\n",
        "  new_model.save((\"vgg16_m_\"+str(k)))\n",
        "  frm = \"/content/\" + \"vgg16_m_\" + str(k)\n",
        "  print(\"Model size after pruning=>\",(os.stat(frm).st_size)/math.pow(2,20),\" Mega Bytes\")\n",
        "  model_size_m.append((os.stat(frm).st_size)/math.pow(2,20))\n",
        "  k+=1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "######################################################################################################################################################################\n",
            "Number of channels to delete layerwise:  [0, 5, 5, 10, 10, 20, 20, 20, 41, 41, 41, 41, 41]\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Deleting 5/64 channels from layer: block1_conv2\n",
            "Deleting 5/128 channels from layer: block2_conv1\n",
            "Deleting 10/128 channels from layer: block2_conv2\n",
            "Deleting 10/256 channels from layer: block3_conv1\n",
            "Deleting 20/256 channels from layer: block3_conv2\n",
            "Deleting 20/256 channels from layer: block3_conv3\n",
            "Deleting 20/512 channels from layer: block4_conv1\n",
            "Deleting 41/512 channels from layer: block4_conv2\n",
            "Deleting 41/512 channels from layer: block4_conv3\n",
            "Deleting 41/512 channels from layer: block5_conv1\n",
            "Deleting 41/512 channels from layer: block5_conv2\n",
            "Deleting 41/512 channels from layer: block5_conv3\n",
            "Model: \"model_108\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 59)      34043     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 123)     65436     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 118)     130744    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 246)       261498    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 236)       522740    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 236)       501500    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 492)       1045500   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 471)       2086059   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 471)       1997040   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 471)       1997040   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 471)       1997040   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 471)       1997040   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              94535680  \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 128,051,464\n",
            "Trainable params: 128,051,464\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "####### FOR RATE :  0.08\n",
            "Model Flops :  27169123281\n",
            "Total :  84 , Correct :  81 , Accuracy :  96.42857142857143\n",
            "Time Taken for prediction :  0.05270366157804217\n",
            "Number of parameter after pruning 128051464\n",
            "Model size after pruning=> 488.5581245422363  Mega Bytes\n",
            "######################################################################################################################################################################\n",
            "Number of channels to delete layerwise:  [0, 6, 6, 12, 12, 23, 23, 23, 46, 46, 46, 46, 46]\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Deleting 6/64 channels from layer: block1_conv2\n",
            "Deleting 6/128 channels from layer: block2_conv1\n",
            "Deleting 12/128 channels from layer: block2_conv2\n",
            "Deleting 12/256 channels from layer: block3_conv1\n",
            "Deleting 23/256 channels from layer: block3_conv2\n",
            "Deleting 23/256 channels from layer: block3_conv3\n",
            "Deleting 23/512 channels from layer: block4_conv1\n",
            "Deleting 46/512 channels from layer: block4_conv2\n",
            "Deleting 46/512 channels from layer: block4_conv3\n",
            "Deleting 46/512 channels from layer: block5_conv1\n",
            "Deleting 46/512 channels from layer: block5_conv2\n",
            "Deleting 46/512 channels from layer: block5_conv3\n",
            "Model: \"model_120\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 58)      33466     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 122)     63806     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 116)     127484    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 244)       254980    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 233)       511901    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 233)       488834    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 489)       1025922   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 466)       2051332   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 466)       1954870   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 466)       1954870   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 466)       1954870   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 466)       1954870   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              93532160  \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 126,789,469\n",
            "Trainable params: 126,789,469\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "####### FOR RATE :  0.09\n",
            "Model Flops :  26597615857\n",
            "Total :  84 , Correct :  80 , Accuracy :  95.23809523809524\n",
            "Time Taken for prediction :  0.055652045068286714\n",
            "Number of parameter after pruning 126789469\n",
            "Model size after pruning=> 483.74222564697266  Mega Bytes\n",
            "######################################################################################################################################################################\n",
            "Number of channels to delete layerwise:  [0, 6, 6, 13, 13, 26, 26, 26, 51, 51, 51, 51, 51]\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Deleting 6/64 channels from layer: block1_conv2\n",
            "Deleting 6/128 channels from layer: block2_conv1\n",
            "Deleting 13/128 channels from layer: block2_conv2\n",
            "Deleting 13/256 channels from layer: block3_conv1\n",
            "Deleting 26/256 channels from layer: block3_conv2\n",
            "Deleting 26/256 channels from layer: block3_conv3\n",
            "Deleting 26/512 channels from layer: block4_conv1\n",
            "Deleting 51/512 channels from layer: block4_conv2\n",
            "Deleting 51/512 channels from layer: block4_conv3\n",
            "Deleting 51/512 channels from layer: block5_conv1\n",
            "Deleting 51/512 channels from layer: block5_conv2\n",
            "Deleting 51/512 channels from layer: block5_conv3\n",
            "Model: \"model_132\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 58)      33466     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 122)     63806     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 115)     126385    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 243)       251748    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 230)       503240    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 230)       476330    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 486)       1006506   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 461)       2016875   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 461)       1913150   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 461)       1913150   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 461)       1913150   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 461)       1913150   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              92528640  \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 125,539,700\n",
            "Trainable params: 125,539,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "####### FOR RATE :  0.1\n",
            "Model Flops :  26216161797\n",
            "Total :  84 , Correct :  82 , Accuracy :  97.61904761904762\n",
            "Time Taken for prediction :  0.053722199939546134\n",
            "Number of parameter after pruning 125539700\n",
            "Model size after pruning=> 478.9748725891113  Mega Bytes\n",
            "######################################################################################################################################################################\n",
            "Number of channels to delete layerwise:  [0, 8, 8, 15, 15, 31, 31, 31, 61, 61, 61, 61, 61]\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Deleting 8/64 channels from layer: block1_conv2\n",
            "Deleting 8/128 channels from layer: block2_conv1\n",
            "Deleting 15/128 channels from layer: block2_conv2\n",
            "Deleting 15/256 channels from layer: block3_conv1\n",
            "Deleting 31/256 channels from layer: block3_conv2\n",
            "Deleting 31/256 channels from layer: block3_conv3\n",
            "Deleting 31/512 channels from layer: block4_conv1\n",
            "Deleting 61/512 channels from layer: block4_conv2\n",
            "Deleting 61/512 channels from layer: block4_conv3\n",
            "Deleting 61/512 channels from layer: block5_conv1\n",
            "Deleting 61/512 channels from layer: block5_conv2\n",
            "Deleting 61/512 channels from layer: block5_conv3\n",
            "Model: \"model_144\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 56)      32312     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 120)     60600     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 113)     122153    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 241)       245338    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 225)       488250    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 225)       455850    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 481)       974506    \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 451)       1952830   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 451)       1831060   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 451)       1831060   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 451)       1831060   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 451)       1831060   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              90521600  \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 123,057,783\n",
            "Trainable params: 123,057,783\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "####### FOR RATE :  0.12\n",
            "Model Flops :  25271639292\n",
            "Total :  84 , Correct :  79 , Accuracy :  94.04761904761905\n",
            "Time Taken for prediction :  0.06088508310772124\n",
            "Number of parameter after pruning 123057783\n",
            "Model size after pruning=> 469.5073890686035  Mega Bytes\n",
            "######################################################################################################################################################################\n",
            "Number of channels to delete layerwise:  [0, 9, 9, 18, 18, 36, 36, 36, 72, 72, 72, 72, 72]\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_13 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Deleting 9/64 channels from layer: block1_conv2\n",
            "Deleting 9/128 channels from layer: block2_conv1\n",
            "Deleting 18/128 channels from layer: block2_conv2\n",
            "Deleting 18/256 channels from layer: block3_conv1\n",
            "Deleting 36/256 channels from layer: block3_conv2\n",
            "Deleting 36/256 channels from layer: block3_conv3\n",
            "Deleting 36/512 channels from layer: block4_conv1\n",
            "Deleting 72/512 channels from layer: block4_conv2\n",
            "Deleting 72/512 channels from layer: block4_conv3\n",
            "Deleting 72/512 channels from layer: block5_conv1\n",
            "Deleting 72/512 channels from layer: block5_conv2\n",
            "Deleting 72/512 channels from layer: block5_conv3\n",
            "Model: \"model_156\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_13 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 55)      31735     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 119)     59024     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 110)     117920    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 238)       235858    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 220)       471460    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 220)       435820    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 476)       942956    \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 440)       1885400   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 440)       1742840   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 440)       1742840   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 440)       1742840   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 440)       1742840   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              88313856  \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 120,345,493\n",
            "Trainable params: 120,345,493\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "####### FOR RATE :  0.14\n",
            "Model Flops :  24376252022\n",
            "Total :  84 , Correct :  64 , Accuracy :  76.19047619047619\n",
            "Time Taken for prediction :  0.06361757005964007\n",
            "Number of parameter after pruning 120345493\n",
            "Model size after pruning=> 459.1611213684082  Mega Bytes\n",
            "######################################################################################################################################################################\n",
            "Number of channels to delete layerwise:  [0, 10, 10, 20, 20, 41, 41, 41, 82, 82, 82, 82, 82]\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_14 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Deleting 10/64 channels from layer: block1_conv2\n",
            "Deleting 10/128 channels from layer: block2_conv1\n",
            "Deleting 20/128 channels from layer: block2_conv2\n",
            "Deleting 20/256 channels from layer: block3_conv1\n",
            "Deleting 41/256 channels from layer: block3_conv2\n",
            "Deleting 41/256 channels from layer: block3_conv3\n",
            "Deleting 41/512 channels from layer: block4_conv1\n",
            "Deleting 82/512 channels from layer: block4_conv2\n",
            "Deleting 82/512 channels from layer: block4_conv3\n",
            "Deleting 82/512 channels from layer: block5_conv1\n",
            "Deleting 82/512 channels from layer: block5_conv2\n",
            "Deleting 82/512 channels from layer: block5_conv3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kerassurgeon/_utils/tensor_dict.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'ref'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_output\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bottomed out at a model input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kerassurgeon/_utils/tensor_dict.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: <Reference wrapping <tf.Tensor 'predictions_181/Softmax:0' shape=(?, 1000) dtype=float32>>",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kerassurgeon/_utils/tensor_dict.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'ref'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_output\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bottomed out at a model input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kerassurgeon/_utils/tensor_dict.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: <Reference wrapping <tf.Tensor 'fc2_181/Relu:0' shape=(?, 4096) dtype=float32>>",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kerassurgeon/_utils/tensor_dict.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'ref'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_output\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bottomed out at a model input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kerassurgeon/_utils/tensor_dict.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: <Reference wrapping <tf.Tensor 'fc1_181/Relu:0' shape=(?, 4096) dtype=float32>>",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[21070,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node fc1_182/kernel/Initializer/random_uniform/RandomUniform}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-c46e0b5a708b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m#  all_sorted_chanels_of_layer_i.clear()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m#  chanels.clear()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msurgeon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36moperate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0moutput_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mnew_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rebuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_graph\u001b[0;34m(self, graph_inputs, output_nodes, graph_input_masks)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;31m# Call the recursive _rebuild_rec method to rebuild the submodel up to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;31m# each output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_rebuild_rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_nodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;31m# Call the recursive _rebuild_rec method to rebuild the submodel up to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;31m# each output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_rebuild_rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_nodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 245\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 245\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 245\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 245\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                     \u001b[0mnew_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_delete_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;31m# Record that this node has been rebuild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2151\u001b[0m     \u001b[0;31m# Optionally load weight values specified at layer instantiation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_initial_weights'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1341\u001b[0m                          'provided weight shape ' + str(w.shape))\n\u001b[1;32m   1342\u001b[0m       \u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1343\u001b[0;31m     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   3257\u001b[0m           \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3258\u001b[0m           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3259\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    484\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    908\u001b[0m       \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m       \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[21070,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node fc1_182/kernel/Initializer/random_uniform/RandomUniform (defined at /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py:1748) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nOriginal stack trace for 'fc1_182/kernel/Initializer/random_uniform/RandomUniform':\n  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 845, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 451, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 434, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-37-c46e0b5a708b>\", line 32, in <module>\n    new_model = surgeon.operate()\n  File \"/usr/local/lib/python3.7/dist-packages/kerassurgeon/surgeon.py\", line 166, in operate\n    new_outputs, _ = self._rebuild_graph(self.model.inputs, output_nodes)\n  File \"/usr/local/lib/python3.7/dist-packages/kerassurgeon/surgeon.py\", line 278, in _rebuild_graph\n    outputs, output_masks = zip(*[_rebuild_rec(n) for n in output_nodes])\n  File \"/usr/local/lib/python3.7/dist-packages/kerassurgeon/surgeon.py\", line 278, in <listcomp>\n    outputs, output_masks = zip(*[_rebuild_rec(n) for n in output_nodes])\n  File \"/usr/local/lib/python3.7/dist-packages/kerassurgeon/surgeon.py\", line 245, in _rebuild_rec\n    *[_rebuild_rec(n) for n in inbound_nodes])\n  File \"/usr/local/lib/python3.7/dist-packages/kerassurgeon/surgeon.py\", line 245, in <listcomp>\n    *[_rebuild_rec(n) for n in inbound_nodes])\n  File \"/usr/local/lib/python3.7/dist-packages/kerassurgeon/surgeon.py\", line 245, in _rebuild_rec\n    *[_rebuild_rec(n) for n in inbound_nodes])\n  File \"/usr/local/lib/python3.7/dist-packages/kerassurgeon/surgeon.py\", line 245, in <listcomp>\n    *[_rebuild_rec(n) for n in inbound_nodes])\n  File \"/usr/local/lib/python3.7/dist-packages/kerassurgeon/surgeon.py\", line 269, in _rebuild_rec\n    output = new_layer(utils.single_element(list(inputs)))\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/engine/base_layer.py\", line 824, in __call__\n    self._maybe_build(inputs)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/engine/base_layer.py\", line 2146, in _maybe_build\n    self.build(input_shapes)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/layers/core.py\", line 1021, in build\n    trainable=True)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/engine/base_layer.py\", line 529, in add_weight\n    aggregation=aggregation)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/tracking/base.py\", line 712, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/engine/base_layer_utils.py\", line 139, in make_variable\n    shape=variable_shape if variable_shape else None)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/variables.py\", line 258, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/variables.py\", line 219, in _variable_v1_call\n    shape=shape)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/variables.py\", line 197, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/variable_scope.py\", line 2503, in default_variable_creator\n    shape=shape)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/variables.py\", line 262, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py\", line 1406, in __init__\n    distribute_strategy=distribute_strategy)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py\", line 1537, in _init_from_args\n    initial_value() if init_from_fn else initial_value,\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/engine/base_layer_utils.py\", line 119, in <lambda>\n    init_val = lambda: initializer(shape, dtype=dtype)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/init_ops.py\", line 533, in __call__\n    shape, -limit, limit, dtype, seed=self.seed)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/random_ops.py\", line 245, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/gen_random_ops.py\", line 822, in random_uniform\n    name=name)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3Ms5abrinbe"
      },
      "source": [
        "Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkrzX8Q0irJw"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjwkFrmwOttV",
        "outputId": "7bea7949-4e2f-4a3e-b41d-4a5fa510582e"
      },
      "source": [
        "rates_m.pop()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt4jfjnmiwmL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc680687-6428-4761-f4d5-ed0927a65218"
      },
      "source": [
        "print(rates_m)\n",
        "print(accuracy_m)\n",
        "print(params_m)\n",
        "print(model_size_m)\n",
        "print(flops_m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.12, 0.14]\n",
            "[98.8, 95.23809523809524, 96.42857142857143, 95.23809523809524, 95.23809523809524, 98.80952380952381, 97.61904761904762, 95.23809523809524, 96.42857142857143, 95.23809523809524, 97.61904761904762, 94.04761904761905, 76.19047619047619]\n",
            "[138357544, 137082213, 135824111, 134553649, 133303521, 131801014, 130549183, 129292115, 128051464, 126789469, 125539700, 123057783, 120345493]\n",
            "[527.8, 523.0066719055176, 518.2075271606445, 513.3612442016602, 508.5925178527832, 502.8610649108887, 498.0858497619629, 493.2906913757324, 488.5581245422363, 483.74222564697266, 478.9748725891113, 469.5073890686035, 459.1611213684082]\n",
            "[30932349056, 30390582674, 29978173943, 29444253833, 28973985902, 28543729797, 28017684184, 27625907196, 27169123281, 26597615857, 26216161797, 25271639292, 24376252022]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "TfP5VQPLl8Re",
        "outputId": "85a44f72-864e-43ea-9376-a8e458abf214"
      },
      "source": [
        "fig,a =  plt.subplots(2,2)\n",
        "a[0][0].plot(rates_m,params_m)\n",
        "a[0][0].set_title('Rate Vs. Parameters')\n",
        "a[0][1].plot(rates_m,model_size_m)\n",
        "a[0][1].set_title('Rate Vs. mode_size')\n",
        "a[1][0].plot(rates_m,accuracy_m)\n",
        "a[1][0].set_title('Rate Vs. Accuracy')\n",
        "a[1][1].plot(rates_m,flops_m)\n",
        "a[1][1].set_title('Rate Vs. flops')\n",
        "fig.set_size_inches(15, 10)\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiP0_-qMBldN"
      },
      "source": [
        "# Whole Model Pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Im2IQdzBosh",
        "outputId": "b4597256-e06b-40f5-a878-309ff6c2ec22"
      },
      "source": [
        "weights_dic_sort={}\n",
        "import numpy as np\n",
        "for i in range(len(conv_layer_weights)):#iterating over all conv layer\n",
        "  weight=conv_layer_weights[i]#getting weight tensor\n",
        "  #weights_dic={}\n",
        "  num_filters=len(weight[0][0][0])#getting number of channels\n",
        "  # if i!=0:\n",
        "  #    num_del_layer_wise[i]=round(num_filters*r)\n",
        "  print(num_filters)\n",
        "\n",
        "  for j in range(num_filters):#iterating over each channel and calculate L2-Norm for that and stored it and a dictionary as key=(layer_index,channel_index) and value as L2-Norm\n",
        "    arr=np.square(weight[0][0][0][j])\n",
        "    w_s=np.sum(arr)\n",
        "    w_s=w_s/9\n",
        "    filt=i+1,j #'filt_{}'.format(j)\n",
        "    weights_dic_sort[filt]=w_s\n",
        "\n",
        "weights_dic_sort_item=sorted(weights_dic_sort.items(),key=lambda kv: kv[1])#sort the L2-Norm for getting most redundant channels\n",
        "print(\"L2 norm of all conv_layer is\\n\",weights_dic_sort_item)\n",
        "print(\"Length of weights_dic_sort_item is :\",len(weights_dic_sort_item))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "64\n",
            "64\n",
            "128\n",
            "128\n",
            "256\n",
            "256\n",
            "256\n",
            "512\n",
            "512\n",
            "512\n",
            "512\n",
            "512\n",
            "L2 norm of all conv_layer is\n",
            " [((4, 43), 6.286170618194673e-05), ((4, 69), 0.00035632564686238766), ((4, 123), 0.00039671956458025507), ((6, 149), 0.0010584016434020465), ((4, 0), 0.0010868039809995228), ((6, 255), 0.0012041685274905628), ((4, 49), 0.0012226545562346776), ((6, 37), 0.0013269330892297956), ((2, 24), 0.0013315817341208458), ((6, 44), 0.001364568869272868), ((6, 174), 0.0014009279095464284), ((6, 171), 0.0014320312895708615), ((11, 504), 0.001495065995388561), ((4, 27), 0.0015026376479201848), ((6, 232), 0.0015380571906765301), ((7, 140), 0.0015460838460259968), ((6, 54), 0.0015563347066442172), ((6, 243), 0.001574746540023221), ((6, 233), 0.0016129448389013608), ((6, 82), 0.001632794737815857), ((7, 228), 0.0016429902364810307), ((6, 123), 0.0016612890693876478), ((11, 58), 0.0016776197072532442), ((6, 110), 0.0016919286507699224), ((4, 89), 0.0017015053373244074), ((9, 351), 0.0017058576146761577), ((9, 362), 0.0017132658718360795), ((9, 40), 0.0017393678426742554), ((4, 77), 0.0017421299384699927), ((6, 181), 0.0017443678031365077), ((6, 58), 0.0017674167950948079), ((7, 94), 0.00176919624209404), ((6, 64), 0.0017708726227283478), ((6, 47), 0.0017728327463070552), ((6, 202), 0.0017736943231688605), ((9, 333), 0.001776026768816842), ((6, 61), 0.0017958119925525454), ((6, 186), 0.0018041210456026925), ((6, 28), 0.0018067384759585063), ((9, 388), 0.001815246625079049), ((6, 102), 0.0018289267188972896), ((9, 364), 0.0018311476127968894), ((7, 204), 0.0018428551654020946), ((6, 165), 0.0018477559917502934), ((6, 131), 0.0018559988174173567), ((9, 329), 0.001860664122634464), ((9, 54), 0.0018607071704334682), ((7, 170), 0.001868479781680637), ((9, 137), 0.0018730353977945116), ((9, 358), 0.0018781957527001698), ((4, 1), 0.0018933763106664021), ((4, 92), 0.0019025757080978816), ((7, 239), 0.0019028644180960124), ((6, 57), 0.0019033261471324498), ((9, 295), 0.001907395405901803), ((7, 106), 0.0019102456669012706), ((9, 471), 0.001912237869368659), ((9, 186), 0.0019194742457734214), ((9, 50), 0.0019315005176597172), ((9, 328), 0.0019397878398497899), ((9, 38), 0.0019444732202423944), ((6, 68), 0.0019459322922759587), ((9, 176), 0.0019497674786382252), ((4, 121), 0.0019509740587737826), ((10, 195), 0.00195110941098796), ((9, 131), 0.0019547444664769703), ((10, 377), 0.001956076050798098), ((7, 82), 0.001963922960890664), ((10, 396), 0.0019658178918891484), ((10, 379), 0.0019658305164840487), ((4, 115), 0.0019715995424323613), ((9, 217), 0.0019755750480625364), ((9, 481), 0.0019816371301809945), ((6, 152), 0.001984912488195631), ((9, 164), 0.001985198507706324), ((6, 48), 0.0019914362993505266), ((4, 124), 0.0020089964899751875), ((9, 76), 0.002019029524591234), ((9, 215), 0.002019073193271955), ((6, 74), 0.002020677551627159), ((6, 121), 0.002025346996055709), ((9, 286), 0.0020332872453663084), ((9, 335), 0.0020385686722066668), ((9, 422), 0.002039034747415119), ((6, 96), 0.0020403851651483113), ((9, 419), 0.002041070204642084), ((9, 8), 0.0020451901687516105), ((6, 67), 0.002053012036614948), ((9, 255), 0.002053417679336336), ((9, 207), 0.0020602885633707047), ((9, 318), 0.0020622573792934418), ((3, 14), 0.002062475722697046), ((6, 137), 0.0020634300178951686), ((9, 26), 0.0020634372615151936), ((9, 377), 0.0020652485804425347), ((9, 261), 0.0020692462308539283), ((10, 13), 0.0020744560493363273), ((9, 459), 0.0020848603712187875), ((6, 8), 0.002085437791215049), ((7, 29), 0.0020881998870107862), ((9, 21), 0.002088433959417873), ((10, 505), 0.0020898357033729553), ((6, 13), 0.0020933347857660716), ((9, 80), 0.0020958251423305934), ((7, 177), 0.002098497831159168), ((9, 253), 0.0020994188057051767), ((9, 247), 0.0020998037523693508), ((9, 284), 0.0021011419594287872), ((9, 432), 0.002102724173002773), ((10, 459), 0.002105549391773012), ((7, 245), 0.0021059539996915394), ((10, 461), 0.0021079882151550716), ((9, 274), 0.002109040402703815), ((4, 53), 0.0021160872032245), ((9, 225), 0.002117020388444265), ((9, 154), 0.0021217955897251763), ((7, 146), 0.0021218742347425884), ((9, 218), 0.002126069739460945), ((6, 235), 0.002126876471771134), ((9, 98), 0.002129638981488016), ((9, 371), 0.0021356013086107043), ((9, 396), 0.00213735302289327), ((6, 139), 0.002138286828994751), ((6, 158), 0.0021395335594813028), ((7, 27), 0.0021400530305173662), ((7, 104), 0.002143318247463968), ((4, 100), 0.002143578396903144), ((6, 136), 0.0021471031424072054), ((6, 128), 0.002147700016697248), ((9, 382), 0.002148021219505204), ((9, 159), 0.0021520577785041598), ((9, 460), 0.0021538386742273965), ((10, 380), 0.0021600487331549325), ((9, 455), 0.00216097053554323), ((9, 509), 0.002161579206585884), ((9, 360), 0.002164230371514956), ((10, 448), 0.0021643986304601035), ((9, 262), 0.002167454610268275), ((9, 15), 0.002167648325363795), ((9, 118), 0.0021698292758729723), ((10, 71), 0.0021702837612893847), ((6, 134), 0.0021742015249199336), ((7, 16), 0.0021767140262656743), ((6, 180), 0.002179047299755944), ((9, 273), 0.002179393751753701), ((9, 392), 0.002180003457599216), ((9, 339), 0.002185101724333233), ((9, 27), 0.0021901076866520774), ((10, 456), 0.0021908440523677403), ((7, 217), 0.0021916193266709647), ((9, 420), 0.002194685654507743), ((6, 125), 0.002197892508573002), ((9, 10), 0.002202913992934757), ((9, 506), 0.0022060113648573556), ((10, 168), 0.0022070014642344583), ((10, 312), 0.002207063138484955), ((9, 457), 0.002207753765914175), ((10, 469), 0.0022096816036436292), ((10, 470), 0.00220972527232435), ((10, 138), 0.0022108852863311768), ((9, 488), 0.002212568289703793), ((9, 469), 0.002212924054927296), ((9, 415), 0.0022164032691054875), ((9, 239), 0.002217846612135569), ((7, 215), 0.0022183451801538467), ((9, 504), 0.002222747024562624), ((9, 331), 0.002223944498433007), ((10, 36), 0.0022255869375334848), ((7, 39), 0.0022267351547876992), ((13, 207), 0.0022288945813973746), ((6, 135), 0.002232565234104792), ((10, 361), 0.002243529591295454), ((9, 370), 0.0022477242681715223), ((9, 219), 0.00224940354625384), ((4, 74), 0.0022504275871647727), ((9, 324), 0.002252645583616363), ((9, 122), 0.002252744303809272), ((7, 237), 0.002253439277410507), ((9, 168), 0.002258252145515548), ((10, 93), 0.0022591733270221287), ((7, 248), 0.002260584384202957), ((9, 96), 0.002265102126532131), ((9, 110), 0.0022659864690568713), ((10, 231), 0.002267608212100135), ((6, 190), 0.0022700909111234876), ((7, 59), 0.0022706397705607945), ((6, 52), 0.0022713562680615317), ((6, 120), 0.002274107187986374), ((6, 49), 0.0022785055140654245), ((10, 463), 0.0022785827103588316), ((9, 109), 0.0022787368959850734), ((9, 363), 0.0022796615958213806), ((9, 198), 0.0022812996887498433), ((10, 75), 0.0022878112892309823), ((6, 167), 0.0022896192967891693), ((9, 4), 0.002295874473121431), ((7, 20), 0.002302577512131797), ((9, 272), 0.00230319384071562), ((9, 202), 0.0023034819298320347), ((10, 129), 0.0023070377194219166), ((9, 297), 0.002312194142076704), ((7, 126), 0.002312391996383667), ((10, 286), 0.002312764525413513), ((9, 46), 0.002313197279969851), ((11, 129), 0.0023144661552376216), ((6, 122), 0.0023158354063828788), ((9, 205), 0.0023166899465852315), ((7, 32), 0.002320619093047248), ((5, 95), 0.0023215264081954956), ((9, 181), 0.0023232288658618927), ((9, 355), 0.0023232725345426137), ((9, 151), 0.0023257722043328816), ((9, 104), 0.002327976334426138), ((6, 175), 0.0023309505648083156), ((9, 9), 0.0023311397267712485), ((9, 497), 0.0023320685658189985), ((9, 16), 0.0023327573306030696), ((10, 293), 0.002337460923526022), ((10, 142), 0.002344834721750683), ((9, 293), 0.00234504747721884), ((10, 391), 0.00234517434404956), ((10, 424), 0.0023460379905170864), ((10, 157), 0.0023464767469300162), ((9, 304), 0.002347134053707123), ((10, 185), 0.0023493129346105787), ((6, 92), 0.0023533637738890117), ((10, 340), 0.00235495881901847), ((10, 31), 0.0023550687150822747), ((4, 39), 0.0023574369649092355), ((9, 252), 0.0023599227683411706), ((7, 31), 0.002361299677027596), ((9, 495), 0.0023615211248397827), ((9, 294), 0.0023641888466146258), ((9, 246), 0.0023642703890800476), ((10, 336), 0.0023644835584693486), ((7, 9), 0.0023709628731012344), ((9, 383), 0.0023711402383115557), ((9, 271), 0.0023723464045259687), ((10, 381), 0.0023758121662669713), ((6, 117), 0.002375996775097317), ((9, 140), 0.0023806972636116874), ((6, 108), 0.002383655144108666), ((6, 42), 0.002384385714928309), ((9, 498), 0.002385732200410631), ((9, 41), 0.002385903149843216), ((10, 511), 0.002386631030175421), ((10, 334), 0.002390924013323254), ((7, 87), 0.002392331138253212), ((9, 309), 0.0023928704775042003), ((9, 158), 0.0023943668024407495), ((10, 408), 0.0023963136805428397), ((6, 188), 0.0023987723721398246), ((10, 465), 0.002399350619978375), ((7, 191), 0.0024006159769164193), ((9, 290), 0.0024044900718662473), ((10, 170), 0.0024048234853479597), ((6, 38), 0.0024050559020704692), ((6, 71), 0.002406444400548935), ((9, 144), 0.002408642735746172), ((9, 156), 0.0024099089205265045), ((9, 92), 0.002410066003600756), ((9, 353), 0.0024133328762319353), ((11, 0), 0.0024159749348958335), ((9, 359), 0.0024168617609474394), ((9, 108), 0.002417331354485618), ((4, 67), 0.0024186575578318704), ((9, 167), 0.0024189170863893297), ((10, 19), 0.0024193504618273843), ((9, 307), 0.0024202830261654323), ((7, 241), 0.002420529309246275), ((10, 211), 0.002420615404844284), ((10, 480), 0.0024211961362097), ((9, 316), 0.002421830263402727), ((9, 171), 0.0024236668315198687), ((10, 467), 0.0024259740279780496), ((9, 395), 0.0024283925692240396), ((7, 223), 0.0024288917581240335), ((6, 39), 0.0024297309832440484), ((6, 147), 0.0024314808348814645), ((9, 99), 0.0024315081536769867), ((7, 88), 0.0024328266994820703), ((10, 152), 0.002433050630821122), ((9, 180), 0.0024334206763241026), ((9, 356), 0.002433442407184177), ((9, 283), 0.0024340798457463584), ((10, 326), 0.002434194708863894), ((9, 33), 0.002436423053344091), ((9, 73), 0.0024374164640903473), ((9, 340), 0.0024385121133592394), ((9, 406), 0.0024408851232793597), ((6, 173), 0.002441536635160446), ((10, 311), 0.0024418067187070847), ((10, 119), 0.0024426269034544625), ((10, 236), 0.002442852490478092), ((9, 275), 0.002443229158719381), ((12, 196), 0.002443715516063902), ((9, 31), 0.0024449266493320465), ((10, 484), 0.00244501709110207), ((10, 400), 0.0024451236757967207), ((9, 242), 0.002447116706106398), ((10, 387), 0.0024487759090132183), ((9, 121), 0.0024494013438622155), ((9, 462), 0.002452218077248997), ((7, 187), 0.002452400823434194), ((6, 185), 0.0024539190861913892), ((10, 246), 0.0024567010502020517), ((9, 64), 0.00245769363310602), ((7, 89), 0.0024581530855761636), ((9, 263), 0.002461166638467047), ((10, 473), 0.0024619479146268633), ((10, 328), 0.0024640833338101706), ((7, 176), 0.002464414056804445), ((7, 124), 0.00246563491721948), ((6, 209), 0.002467576207386123), ((9, 49), 0.002467603319221073), ((9, 150), 0.0024683301647504172), ((10, 128), 0.002468554510010613), ((10, 172), 0.0024694750706354776), ((7, 49), 0.002469681203365326), ((10, 148), 0.002469942801528507), ((10, 70), 0.0024713476498921714), ((9, 57), 0.002471750188204977), ((9, 494), 0.0024724346068170336), ((6, 237), 0.0024742173651854196), ((9, 129), 0.0024760483453671136), ((5, 64), 0.0024797488003969193), ((9, 231), 0.0024849192963706124), ((10, 302), 0.0024855033391051823), ((12, 423), 0.0024861200816101497), ((9, 350), 0.0024861515396171147), ((7, 51), 0.0024862434301111433), ((10, 283), 0.002486909015311135), ((7, 189), 0.002487136258019341), ((10, 439), 0.002487697328130404), ((7, 214), 0.00248917109436459), ((9, 323), 0.0024896996716658273), ((7, 110), 0.002489964167277018), ((7, 12), 0.0024899966600868437), ((9, 221), 0.0024904865357610914), ((10, 274), 0.0024914551112386915), ((9, 510), 0.0024923812597990036), ((10, 301), 0.002493389985627598), ((9, 234), 0.0024942681193351746), ((9, 312), 0.002494693630271488), ((10, 342), 0.0024960761268933616), ((9, 437), 0.0024962926076518167), ((7, 19), 0.0024969354271888733), ((6, 24), 0.002497987614737617), ((11, 2), 0.0024984214040968153), ((9, 160), 0.0024986974895000458), ((10, 441), 0.0024989967544873557), ((9, 62), 0.0025021077858077157), ((4, 118), 0.0025026069747077096), ((7, 63), 0.002502806691659821), ((9, 94), 0.002504918724298477), ((9, 489), 0.0025056679215696123), ((10, 240), 0.002505883988406923), ((9, 182), 0.0025096620536512798), ((9, 315), 0.0025124349113967684), ((9, 464), 0.002512924787071016), ((9, 366), 0.002513206253449122), ((11, 202), 0.0025135758850309583), ((7, 231), 0.0025143704066673913), ((10, 365), 0.0025143737180365455), ((9, 440), 0.002515550288889143), ((10, 275), 0.0025183111429214478), ((10, 378), 0.0025196605258517796), ((6, 16), 0.0025240530570348105), ((11, 484), 0.0025265316168467202), ((9, 480), 0.002528506020704905), ((9, 128), 0.002530693593952391), ((9, 65), 0.002531999929083718), ((6, 242), 0.0025321547355916765), ((10, 401), 0.0025327226354016196), ((10, 460), 0.0025340786410702597), ((9, 439), 0.002534466485182444), ((7, 69), 0.002537274112304052), ((9, 161), 0.0025380317949586445), ((9, 116), 0.0025405180123117235), ((9, 306), 0.0025410817729102243), ((10, 18), 0.002543416495124499), ((6, 100), 0.002544156379169888), ((9, 265), 0.0025458348294099173), ((7, 109), 0.0025478442096047932), ((10, 322), 0.0025507124761740365), ((9, 426), 0.002551715614067184), ((9, 314), 0.0025539259529776042), ((9, 361), 0.0025542800625165305), ((9, 183), 0.0025553537739647757), ((9, 175), 0.0025556273758411407), ((9, 397), 0.002555989349881808), ((9, 201), 0.002556535932752821), ((9, 418), 0.002559783144129647), ((10, 299), 0.0025599367088741725), ((6, 225), 0.0025599396063221824), ((9, 508), 0.0025625398589505088), ((7, 103), 0.00256653337015046), ((9, 429), 0.0025677242212825352), ((10, 222), 0.0025684494111273023), ((10, 291), 0.00256936252117157), ((10, 411), 0.002569904343949424), ((10, 223), 0.0025711076127158273), ((9, 278), 0.0025724160174528756), ((10, 344), 0.0025728419423103333), ((8, 129), 0.002573261244429482), ((6, 9), 0.0025732871145009995), ((7, 50), 0.0025750346895721224), ((12, 157), 0.002576132615407308), ((9, 236), 0.0025765078349245917), ((11, 386), 0.0025782183640533024), ((9, 206), 0.002579269309838613), ((11, 395), 0.0025828925685750116), ((10, 496), 0.002583224740293291), ((7, 197), 0.0025837053027417925), ((9, 134), 0.002586791498793496), ((10, 165), 0.0025874372157785627), ((10, 162), 0.0025887799759705863), ((10, 208), 0.002588808329568969), ((10, 341), 0.0025889575481414795), ((6, 81), 0.0025914147910144594), ((6, 150), 0.0025929568542374503), ((9, 119), 0.0025954002307520974), ((10, 252), 0.0025966916647222307), ((9, 53), 0.0025970240434010825), ((9, 19), 0.0025972887459728452), ((7, 76), 0.0025981461836232077), ((6, 18), 0.0025992641846338906), ((9, 243), 0.0026014598293436896), ((10, 217), 0.0026015895936224195), ((9, 77), 0.002602384322219425), ((10, 39), 0.00260317325592041), ((9, 458), 0.002603634777996275), ((9, 478), 0.002603866159915924), ((9, 254), 0.0026048868894577026), ((13, 452), 0.0026075285342004565), ((10, 213), 0.0026099462476041582), ((9, 34), 0.0026103154652648503), ((11, 503), 0.0026126830942100948), ((10, 230), 0.0026166424569156435), ((9, 482), 0.0026180214352077907), ((8, 218), 0.0026198472413751814), ((10, 370), 0.00262153728140725), ((11, 131), 0.0026228328545888266), ((12, 400), 0.0026248956306113135), ((10, 111), 0.0026262284566958747), ((9, 143), 0.0026271724038653905), ((10, 95), 0.0026285333765877616), ((7, 160), 0.0026315670046541425), ((10, 56), 0.002631815771261851), ((9, 17), 0.0026323613193300036), ((10, 479), 0.0026326804525322383), ((9, 170), 0.002639082363910145), ((9, 69), 0.0026403023964828914), ((10, 69), 0.0026423397163550058), ((7, 212), 0.0026436830974287456), ((11, 84), 0.0026465155598190096), ((9, 178), 0.002646891193257438), ((7, 210), 0.00264809342722098), ((9, 405), 0.0026480998429987165), ((9, 332), 0.0026483960035774442), ((10, 474), 0.002648719275991122), ((13, 37), 0.0026493420203526816), ((9, 14), 0.002649996222721206), ((12, 474), 0.0026502611322535407), ((10, 101), 0.0026520730720625985), ((9, 190), 0.002654322940442297), ((10, 281), 0.0026543454991446603), ((9, 387), 0.0026546836727195317), ((7, 254), 0.0026565268635749817), ((10, 478), 0.0026592982725964654), ((10, 426), 0.0026595722883939743), ((10, 372), 0.00266007168425454), ((10, 393), 0.0026614757047759164), ((9, 184), 0.0026636229207118354), ((10, 417), 0.0026637566172414357), ((10, 433), 0.0026637806246678033), ((11, 316), 0.0026638288464811114), ((10, 205), 0.002664103690120909), ((9, 391), 0.0026642800205283696), ((9, 58), 0.0026655281997389263), ((11, 173), 0.0026658249811993707), ((13, 41), 0.002666804939508438), ((9, 136), 0.0026681388003958594), ((10, 282), 0.0026691845721668666), ((7, 130), 0.00267117139365938), ((10, 255), 0.0026719806094964347), ((10, 4), 0.0026721180313163334), ((9, 336), 0.0026746096296442878), ((6, 198), 0.0026751564194758735), ((5, 78), 0.002677514942155944), ((10, 305), 0.0026778092400895227), ((10, 358), 0.002677985363536411), ((6, 199), 0.0026784584754043156), ((9, 244), 0.002678681785861651), ((10, 492), 0.002680818239847819), ((9, 209), 0.0026810127827856275), ((10, 116), 0.0026820173694027793), ((12, 179), 0.0026824656460020277), ((6, 78), 0.002682615899377399), ((10, 189), 0.0026830602437257767), ((10, 298), 0.002683244231674406), ((7, 38), 0.0026855520490143034), ((10, 481), 0.002686296072271135), ((7, 209), 0.0026863416035970054), ((9, 436), 0.0026867646310064527), ((9, 43), 0.002687183933125602), ((10, 192), 0.0026877648714515897), ((7, 55), 0.0026884774367014566), ((9, 200), 0.002692903909418318), ((10, 304), 0.0026951063838269976), ((12, 308), 0.00269656235145198), ((7, 90), 0.0026975439654456247), ((12, 25), 0.00269957073032856), ((6, 90), 0.002703875924150149), ((9, 20), 0.0027063594510157904), ((9, 222), 0.0027070438696278464), ((10, 251), 0.002708566685517629), ((9, 349), 0.0027087926864624023), ((12, 422), 0.0027114806903733146), ((10, 257), 0.002714732454882728), ((9, 146), 0.0027167312800884247), ((9, 322), 0.002716810339026981), ((4, 108), 0.0027194716450240877), ((9, 197), 0.0027215112414624956), ((12, 387), 0.00272168405354023), ((13, 321), 0.0027226248963011634), ((4, 105), 0.002722690709763103), ((10, 50), 0.0027232240471574995), ((6, 6), 0.002723232325580385), ((10, 453), 0.0027232950346337426), ((13, 482), 0.002723725305663215), ((10, 268), 0.002725844168000751), ((9, 477), 0.0027263924065563413), ((9, 374), 0.0027277006043328177), ((9, 410), 0.0027285096132093007), ((9, 85), 0.002731494191620085), ((12, 132), 0.002734306992755996), ((6, 140), 0.0027345193343030084), ((10, 310), 0.002735253009531233), ((10, 450), 0.002735844916767544), ((9, 35), 0.002736170465747515), ((11, 229), 0.0027365628629922867), ((10, 202), 0.0027367634077866874), ((10, 244), 0.002737419472800361), ((10, 124), 0.0027379499127467475), ((9, 233), 0.002738306505812539), ((10, 279), 0.0027385943879683814), ((9, 424), 0.002739579106370608), ((10, 121), 0.002740210543076197), ((9, 502), 0.0027408674359321594), ((10, 353), 0.002741145590941111), ((9, 248), 0.0027425742397705712), ((6, 234), 0.0027433637943532732), ((12, 197), 0.002745903821455108), ((6, 195), 0.0027477755728695127), ((12, 53), 0.002749066799879074), ((7, 96), 0.0027495837873882717), ((9, 103), 0.0027526033421357474), ((6, 10), 0.002754703164100647), ((4, 2), 0.0027547598712974125), ((8, 142), 0.00275567298134168), ((11, 83), 0.002757257264521387), ((10, 78), 0.0027579770733912787), ((9, 256), 0.002758401549524731), ((9, 84), 0.0027588469286759696), ((10, 508), 0.00275941358672248), ((9, 173), 0.0027596130967140198), ((9, 149), 0.0027601151830620235), ((10, 289), 0.0027602345993121466), ((6, 179), 0.002762275437513987), ((10, 72), 0.0027631082468562657), ((10, 498), 0.002763851649231381), ((10, 294), 0.002765316516160965), ((9, 71), 0.0027662134832806056), ((12, 240), 0.0027662358350223964), ((10, 444), 0.002767447382211685), ((9, 320), 0.002769686074720489), ((10, 254), 0.00277026059726874), ((11, 511), 0.0027739202810658347), ((10, 238), 0.002774248934454388), ((4, 31), 0.0027751103043556213), ((9, 162), 0.0027755842440658146), ((11, 315), 0.002776536676618788), ((11, 193), 0.002777034209834205), ((11, 180), 0.00277802265352673), ((4, 50), 0.0027783337152666515), ((9, 321), 0.002778473206692272), ((9, 368), 0.0027785425384839377), ((9, 42), 0.002780862980418735), ((9, 216), 0.0027812483410040536), ((9, 25), 0.0027818909535805383), ((9, 269), 0.0027824238770537907), ((9, 196), 0.0027849769426716697), ((10, 423), 0.0027852991802824866), ((7, 30), 0.0027861499951945413), ((10, 109), 0.0027863598532146877), ((9, 438), 0.002786563295457098), ((10, 102), 0.0027865891655286155), ((8, 107), 0.0027877361410193974), ((9, 78), 0.002787782293226984), ((11, 63), 0.0027884915471076965), ((12, 258), 0.002791004048453437), ((10, 17), 0.0027919920782248178), ((10, 277), 0.002792482781741354), ((6, 177), 0.0027982687784565818), ((11, 294), 0.0027984916749927732), ((9, 372), 0.0027986055033074487), ((12, 95), 0.0027987522383530936), ((10, 188), 0.0027993698087003496), ((9, 189), 0.0027994405892160204), ((7, 1), 0.0028005720426638923), ((9, 223), 0.0028023657699426017), ((10, 250), 0.0028036344382498), ((6, 226), 0.0028039581245846218), ((9, 91), 0.002804972438348664), ((11, 153), 0.0028067860338422987), ((9, 452), 0.0028068131456772485), ((10, 466), 0.0028096818261676365), ((6, 182), 0.002809781167242262), ((8, 39), 0.002810380318098598), ((12, 177), 0.0028109782271915013), ((12, 24), 0.002812824108534389), ((9, 192), 0.0028129685670137405), ((10, 491), 0.0028138491842481825), ((9, 281), 0.0028155214256710475), ((10, 237), 0.002816284696261088), ((10, 167), 0.002817664709356096), ((13, 350), 0.0028178880198134314), ((9, 193), 0.0028182913859685263), ((9, 400), 0.00281919642455048), ((6, 53), 0.002819347091846996), ((7, 178), 0.0028201349907451207), ((10, 174), 0.002820530285437902), ((11, 290), 0.002821400140722593), ((7, 162), 0.0028224274930026797), ((9, 228), 0.002822563880019718), ((9, 503), 0.0028231321937508052), ((10, 84), 0.0028247361381848655), ((9, 245), 0.0028254236612055036), ((9, 292), 0.0028266463842656878), ((9, 327), 0.0028269092241923013), ((10, 410), 0.0028274872650702796), ((12, 60), 0.0028286948800086975), ((9, 240), 0.0028289974563651616), ((9, 453), 0.0028305831882688734), ((9, 60), 0.002831551970707046), ((11, 213), 0.0028318696551852757), ((9, 138), 0.002833888762527042), ((10, 245), 0.0028369720611307356), ((6, 192), 0.002838074126177364), ((10, 249), 0.0028386952148543466), ((9, 68), 0.0028406737579239737), ((9, 490), 0.0028407772382100425), ((9, 373), 0.0028411073403226007), ((7, 25), 0.002841805418332418), ((10, 290), 0.002841886132955551), ((9, 385), 0.0028424211260345248), ((7, 152), 0.0028431672188970777), ((10, 390), 0.002843259937233395), ((10, 316), 0.0028432936718066535), ((9, 125), 0.002843338582250807), ((9, 484), 0.0028436105284425947), ((11, 333), 0.00284440815448761), ((10, 76), 0.0028448489805062613), ((9, 298), 0.002845363070567449), ((9, 213), 0.0028469405240482753), ((10, 216), 0.0028470419347286224), ((9, 451), 0.002850087152587043), ((10, 64), 0.002851462819510036), ((10, 45), 0.002851735179622968), ((7, 42), 0.0028518343137370217), ((9, 163), 0.002852926237715615), ((9, 81), 0.0028530415147542953), ((11, 409), 0.0028535729895035424), ((9, 475), 0.002854062037335502), ((10, 338), 0.0028562924514214196), ((4, 35), 0.0028570894565847185), ((7, 196), 0.002857547046409713), ((9, 270), 0.0028582877582973903), ((10, 49), 0.002858560946252611), ((9, 301), 0.002859530763493644), ((10, 507), 0.0028602267718977397), ((9, 456), 0.002860764662424723), ((11, 39), 0.0028615910559892654), ((5, 60), 0.002867279367314445), ((9, 32), 0.002868346869945526), ((6, 76), 0.0028697355753845638), ((9, 6), 0.0028717584080166286), ((8, 12), 0.0028720953398280675), ((8, 247), 0.002873118966817856), ((12, 65), 0.0028745300239986843), ((10, 495), 0.002874794312649303), ((12, 77), 0.002875234931707382), ((6, 21), 0.002875676585568322), ((10, 266), 0.0028757045252455603), ((6, 204), 0.0028766306738058725), ((11, 321), 0.0028779922674099603), ((10, 104), 0.0028787189059787327), ((10, 269), 0.0028800538016690146), ((9, 348), 0.002880862603584925), ((10, 212), 0.002881477897365888), ((8, 73), 0.002884649568133884), ((12, 89), 0.002885345783498552), ((10, 258), 0.0028855864786439473), ((9, 326), 0.0028875679191615847), ((8, 81), 0.0028876569122076035), ((10, 89), 0.002888219017121527), ((9, 430), 0.002888797471920649), ((10, 30), 0.0028890280259980094), ((10, 233), 0.002889924579196506), ((11, 189), 0.002891437460978826), ((11, 271), 0.0028920177784230974), ((10, 153), 0.0028928942564460966), ((9, 431), 0.0028934338026576573), ((4, 28), 0.002893896773457527), ((12, 402), 0.002895849032534493), ((11, 464), 0.0028969223300615945), ((9, 0), 0.0028970541639460456), ((9, 95), 0.002897233184840944), ((6, 93), 0.002899339215623008), ((9, 123), 0.0028999226374758613), ((10, 510), 0.0029002527395884195), ((10, 6), 0.0029006896333562005), ((10, 73), 0.0029019578877422544), ((13, 48), 0.0029022093448374006), ((6, 3), 0.002902772691514757), ((7, 221), 0.0029031758507092795), ((11, 300), 0.002904795938067966), ((10, 421), 0.0029061995446681976), ((10, 96), 0.002906468179490831), ((10, 399), 0.002906849814785851), ((10, 139), 0.0029068849980831146), ((9, 496), 0.0029078732348150676), ((10, 415), 0.0029080986148781246), ((10, 329), 0.002908474455277125), ((13, 87), 0.0029124576184484693), ((8, 33), 0.0029138268695937265), ((6, 253), 0.002914323781927427), ((13, 196), 0.0029152159889539084), ((7, 121), 0.0029155976242489284), ((10, 86), 0.002916354686021805), ((12, 162), 0.002917792648077011), ((12, 217), 0.002918697272737821), ((10, 323), 0.0029201184709866843), ((13, 373), 0.0029225084516737196), ((4, 91), 0.002924431943231159), ((9, 266), 0.0029247477650642395), ((12, 139), 0.002925136850939857), ((13, 82), 0.0029282505727476543), ((3, 22), 0.0029284575333197913), ((10, 196), 0.0029289734860261283), ((7, 122), 0.002929969173338678), ((10, 227), 0.002930175099107954), ((10, 501), 0.002931152159969012), ((10, 502), 0.0029321379131740993), ((6, 249), 0.002932763761944241), ((10, 468), 0.0029342702279488244), ((10, 87), 0.002935107176502546), ((6, 238), 0.0029357564118173388), ((10, 99), 0.0029359819988409677), ((9, 434), 0.0029362404925955665), ((9, 204), 0.002936956783135732), ((9, 212), 0.002938211378124025), ((10, 306), 0.00293877845009168), ((13, 457), 0.002938898487223519), ((10, 493), 0.0029395903564161724), ((9, 472), 0.0029396783146593305), ((6, 218), 0.002940600944889916), ((10, 447), 0.002940710633993149), ((6, 144), 0.0029415651741955015), ((11, 138), 0.0029417893124951255), ((12, 386), 0.002943587592906422), ((7, 18), 0.002944001721011268), ((12, 63), 0.00294681079685688), ((10, 330), 0.002947017964389589), ((7, 249), 0.0029492444462246364), ((12, 4), 0.002949249413278368), ((7, 183), 0.0029493404759301078), ((10, 504), 0.002950342579020394), ((11, 412), 0.002950487037499746), ((9, 468), 0.0029512981159819495), ((11, 499), 0.0029527822302447427), ((12, 220), 0.0029543425059980815), ((9, 287), 0.0029575911660989127), ((9, 47), 0.002958483166164822), ((10, 44), 0.002959902501768536), ((9, 446), 0.0029616521464453805), ((4, 68), 0.002963336391581429), ((12, 252), 0.002963673323392868), ((10, 194), 0.0029646634227699703), ((7, 80), 0.0029650754812690946), ((7, 220), 0.002965824471579658), ((11, 81), 0.002969292716847526), ((9, 492), 0.002970222383737564), ((10, 397), 0.00297160798476802), ((9, 185), 0.0029741227626800537), ((11, 312), 0.0029750333891974557), ((9, 299), 0.0029756948351860046), ((7, 244), 0.0029762950208452013), ((9, 311), 0.002976741227838728), ((11, 72), 0.00297677434153027), ((9, 30), 0.0029771429383092457), ((11, 127), 0.002979614254501131), ((11, 279), 0.0029803473088476392), ((12, 3), 0.002980852706564797), ((9, 199), 0.002981116788254844), ((11, 337), 0.00298134113351504), ((12, 136), 0.0029813808699448905), ((12, 158), 0.0029820919864707524), ((11, 458), 0.0029832813888788223), ((9, 155), 0.002986110953821076), ((11, 323), 0.0029875257362922034), ((11, 36), 0.0029895945141712823), ((7, 207), 0.0029907127221425376), ((10, 220), 0.0029916444586382974), ((13, 211), 0.0029918505913681453), ((10, 178), 0.002992386826210552), ((9, 142), 0.002992744661039776), ((10, 384), 0.0029933307733800677), ((7, 15), 0.0029934512244330514), ((9, 179), 0.0029969732794496748), ((7, 125), 0.002997353259060118), ((10, 103), 0.002997943510611852), ((11, 31), 0.0030008951822916665), ((9, 344), 0.0030009299516677856), ((10, 176), 0.0030023521847195095), ((10, 475), 0.003002799219555325), ((11, 133), 0.00300306992398368), ((9, 399), 0.0030036469300587973), ((10, 309), 0.003003722470667627), ((8, 0), 0.003004384537537893), ((12, 222), 0.0030072112050321368), ((13, 223), 0.0030079210797945657), ((12, 304), 0.0030081671559148366), ((6, 63), 0.0030095246103074816), ((7, 172), 0.0030104141268465254), ((10, 307), 0.003011337791879972), ((9, 291), 0.0030164021170801586), ((6, 4), 0.003017623805337482), ((9, 3), 0.003018786923752891), ((11, 259), 0.0030193705525663164), ((10, 386), 0.0030195359140634537), ((7, 112), 0.003019592207339075), ((11, 253), 0.0030197836458683014), ((13, 504), 0.003020031584633721), ((10, 126), 0.0030210291345914206), ((10, 40), 0.003022008885939916), ((6, 1), 0.003023748596509298), ((7, 234), 0.0030247498717572954), ((13, 191), 0.003027321149905523), ((11, 269), 0.0030281876938210595), ((12, 469), 0.0030282247397634718), ((12, 184), 0.003028411625160111), ((10, 455), 0.0030284331490596137), ((9, 325), 0.0030293516400787565), ((13, 348), 0.0030298084020614624), ((11, 151), 0.0030306639770666757), ((10, 327), 0.0030311176346408), ((6, 36), 0.003032358984152476), ((11, 397), 0.003033087899287542), ((13, 414), 0.003033717473347982), ((11, 56), 0.0030354460080464682), ((12, 438), 0.0030367359932925967), ((9, 493), 0.00303739495575428), ((8, 131), 0.00303942503200637), ((11, 431), 0.0030406423740916783), ((6, 250), 0.003040790350900756), ((11, 13), 0.003040966267387072), ((11, 158), 0.003042440033621258), ((10, 173), 0.003042992204427719), ((11, 115), 0.0030444196114937463), ((9, 165), 0.003045101546578937), ((10, 83), 0.0030455518927839068), ((11, 94), 0.003045556445916494), ((10, 48), 0.003045884685383903), ((13, 88), 0.0030468611253632438), ((12, 5), 0.003047192262278663), ((8, 192), 0.003047482834921943), ((6, 201), 0.0030479286279943255), ((12, 458), 0.0030480867458714377), ((9, 414), 0.00304883180393113), ((10, 32), 0.0030501940184169346), ((11, 364), 0.0030509837799602086), ((13, 352), 0.0030532098478741115), ((10, 155), 0.003053225783838166), ((13, 443), 0.0030544932103819316), ((12, 251), 0.0030546308391624028), ((11, 5), 0.003054694583018621), ((12, 398), 0.0030559392438994516), ((7, 164), 0.0030559589051538045), ((12, 91), 0.003057323396205902), ((11, 106), 0.0030578432811631095), ((11, 390), 0.0030593578186300066), ((6, 22), 0.0030601068089405694), ((9, 97), 0.003060254371828503), ((11, 132), 0.003061655494901869), ((7, 208), 0.0030655618757009506), ((10, 383), 0.00306582719915443), ((9, 444), 0.003066804880897204), ((11, 33), 0.0030689934889475503), ((13, 430), 0.0030703465971681806), ((4, 57), 0.0030718553397390577), ((10, 368), 0.003073532548215654), ((9, 172), 0.0030752610829141405), ((13, 104), 0.003076215171151691), ((7, 123), 0.003077001621325811), ((2, 32), 0.003077487357788616), ((11, 121), 0.003078100168042713), ((10, 130), 0.003078622536526786), ((10, 204), 0.0030797533690929413), ((11, 459), 0.003080271598365572), ((11, 340), 0.003080712838305367), ((13, 384), 0.003080737880534596), ((10, 435), 0.0030815433710813522), ((11, 427), 0.0030828010704782275), ((11, 303), 0.0030832719057798386), ((13, 252), 0.0030833615197075736), ((10, 395), 0.0030835308134555817), ((12, 239), 0.0030847138000859153), ((13, 426), 0.0030848061045010886), ((8, 214), 0.0030857231467962265), ((10, 402), 0.0030859149992465973), ((7, 144), 0.003087263968255785), ((7, 225), 0.0030881748017337588), ((9, 249), 0.0030898327628771463), ((9, 403), 0.003092508763074875), ((10, 25), 0.0030936766415834427), ((10, 127), 0.0030939864615599313), ((11, 415), 0.00309504403008355), ((11, 495), 0.0030965858863459695), ((13, 386), 0.003096742762459649), ((8, 106), 0.0030972734093666077), ((9, 341), 0.003098919987678528), ((8, 69), 0.0030989876637856164), ((13, 40), 0.00309898994035191), ((11, 239), 0.0030991832415262857), ((6, 30), 0.0030996248953872258), ((7, 136), 0.003099857105149163), ((10, 488), 0.0030998877353138393), ((12, 405), 0.003100223011440701), ((11, 350), 0.0031002466049459246), ((11, 22), 0.0031003310448593563), ((12, 36), 0.0031005568388435575), ((8, 160), 0.0031011230829689237), ((12, 441), 0.0031018079155021245), ((13, 188), 0.0031024511489603254), ((11, 374), 0.0031027417216036054), ((10, 490), 0.0031052471862898934), ((9, 70), 0.0031052488419744703), ((9, 346), 0.0031055348614851632), ((6, 51), 0.0031059098740418753), ((12, 476), 0.0031060802025927436), ((10, 262), 0.003106290267573463), ((13, 281), 0.003108984480301539), ((8, 190), 0.00310943979356024), ((6, 241), 0.0031110385639799964), ((9, 259), 0.003111075609922409), ((9, 120), 0.0031123438643084634), ((6, 114), 0.0031133186486032275), ((12, 19), 0.0031133265131049687), ((11, 408), 0.0031143085410197577), ((8, 28), 0.003114309161901474), ((12, 67), 0.003114681277010176), ((10, 443), 0.003115259731809298), ((10, 199), 0.003115460690524843), ((12, 160), 0.0031167411555846534), ((10, 509), 0.0031177525719006858), ((10, 457), 0.003118375523222817), ((7, 159), 0.0031188002063168418), ((12, 107), 0.0031188949942588806), ((9, 448), 0.0031196255650785235), ((10, 436), 0.0031216206649939218), ((10, 317), 0.003121970428360833), ((12, 166), 0.0031226368414031137), ((10, 499), 0.003123174938890669), ((11, 224), 0.0031231819755501216), ((8, 150), 0.0031233597546815872), ((11, 355), 0.0031244270503520966), ((7, 118), 0.00312668705979983), ((7, 188), 0.0031268795331319175), ((10, 27), 0.003127182109488381), ((13, 58), 0.0031273787220319114), ((9, 473), 0.0031284085578388637), ((13, 333), 0.0031292198432816398), ((4, 13), 0.0031310729682445526), ((10, 242), 0.003131875561343299), ((11, 61), 0.0031320293330483967), ((12, 336), 0.0031348752478758493), ((8, 182), 0.0031381241149372524), ((13, 306), 0.0031383285919825235), ((10, 91), 0.0031391746468014186), ((9, 369), 0.0031399490932623544), ((11, 103), 0.0031403063072098624), ((12, 44), 0.003141985999213325), ((10, 67), 0.0031446023947662776), ((13, 330), 0.0031452433516581855), ((10, 144), 0.0031469913406504523), ((11, 367), 0.003147121932771471), ((13, 343), 0.003147479560640123), ((10, 363), 0.003148694626159138), ((13, 173), 0.003149663201636738), ((13, 441), 0.0031500005473693213), ((11, 122), 0.003150616255071428), ((12, 66), 0.0031529805726475185), ((9, 208), 0.003153562131855223), ((10, 285), 0.00315419625904825), ((11, 165), 0.003154370519849989), ((7, 194), 0.0031558554619550705), ((10, 10), 0.0031561930146482256), ((10, 29), 0.0031578650491105188), ((7, 238), 0.0031580651799837747), ((12, 121), 0.0031580900152524314), ((11, 174), 0.003158247305287255), ((12, 340), 0.0031587088273631204), ((7, 116), 0.0031596782306830087), ((10, 184), 0.0031602074288659627), ((10, 98), 0.003160347127252155), ((11, 353), 0.0031608357611629698), ((9, 296), 0.0031613146679268945), ((10, 382), 0.0031633141140143075), ((8, 71), 0.0031634829938411713), ((10, 234), 0.0031639461716016135), ((10, 376), 0.0031643671294053397), ((12, 370), 0.003164908538262049), ((10, 7), 0.0031650749345620475), ((9, 29), 0.0031671010785632664), ((11, 400), 0.0031677213393979603), ((12, 349), 0.0031700171530246735), ((10, 357), 0.0031702793720695707), ((9, 476), 0.0031717351327339807), ((11, 226), 0.003173179096645779), ((11, 68), 0.003173448559310701), ((12, 145), 0.003174005283249749), ((3, 9), 0.003174619128306707), ((12, 362), 0.0031750096629063287), ((13, 413), 0.0031754889835913977), ((9, 177), 0.0031758536481195027), ((9, 7), 0.003176053985953331), ((11, 387), 0.0031764027145173815), ((10, 160), 0.0031768567860126495), ((10, 77), 0.0031773286561171212), ((10, 454), 0.003178172434369723), ((9, 226), 0.0031785331666469574), ((9, 260), 0.0031787074274486965), ((10, 141), 0.0031795849402745566), ((11, 429), 0.0031796319203244317), ((11, 356), 0.0031798690971401003), ((10, 68), 0.003180233968628777), ((12, 464), 0.003181121622522672), ((10, 66), 0.003183972090482712), ((10, 348), 0.0031845722761419085), ((10, 430), 0.0031855127049816977), ((11, 281), 0.0031865487496058145), ((13, 354), 0.0031866091820928785), ((6, 29), 0.003186723424328698), ((11, 254), 0.0031871673547559315), ((7, 235), 0.003189708830581771), ((11, 235), 0.0031908216575781503), ((11, 210), 0.0031909381763802636), ((10, 53), 0.0031909445921579995), ((10, 57), 0.003191736423306995), ((11, 341), 0.003193438880973392), ((9, 13), 0.0031935109032524955), ((12, 359), 0.003197403831614388), ((6, 104), 0.00319854107995828), ((10, 295), 0.0031988399310244452), ((12, 213), 0.003199096769094467), ((9, 319), 0.0031992108043697146), ((8, 222), 0.0031993364294370017), ((11, 416), 0.0032005260388056436), ((10, 278), 0.003200874560409122), ((13, 208), 0.0032009726597203147), ((9, 483), 0.003201045509841707), ((10, 156), 0.003202112598551644), ((10, 419), 0.003202815850575765), ((10, 65), 0.0032029240909549925), ((7, 7), 0.00320424594812923), ((12, 269), 0.0032082514630423654), ((12, 459), 0.0032106577936145994), ((9, 227), 0.0032122207598553765), ((12, 337), 0.0032141877131329644), ((9, 23), 0.003215684038069513), ((13, 179), 0.0032166867620415157), ((13, 296), 0.0032172794971201154), ((9, 86), 0.003217879061897596), ((11, 147), 0.0032180030312803057), ((11, 183), 0.003218283255894979), ((13, 147), 0.0032208232829968133), ((12, 279), 0.0032213740050792694), ((10, 146), 0.003222751741607984), ((13, 203), 0.0032241112656063503), ((12, 466), 0.0032248927487267386), ((8, 68), 0.00322521829770671), ((7, 137), 0.0032268009252018398), ((7, 71), 0.0032268501818180084), ((13, 193), 0.003226867980427212), ((7, 253), 0.0032283618218368953), ((13, 467), 0.003228498415814506), ((9, 2), 0.0032301992177963257), ((7, 145), 0.003231054585840967), ((7, 98), 0.003231960866186354), ((10, 346), 0.003233301763733228), ((12, 195), 0.0032333661284711626), ((10, 164), 0.003233764734533098), ((12, 303), 0.00323441190024217), ((13, 400), 0.003234566499789556), ((10, 0), 0.003234848380088806), ((9, 36), 0.00323500567012363), ((12, 271), 0.0032350069118870627), ((11, 257), 0.0032360462678803336), ((13, 489), 0.003236137123571502), ((8, 4), 0.0032369537899891534), ((12, 505), 0.00323802274134424), ((9, 229), 0.0032382185260454812), ((13, 447), 0.0032389511664708457), ((11, 190), 0.0032403158644835153), ((10, 413), 0.0032404797772566476), ((11, 141), 0.0032409640649954477), ((9, 402), 0.0032415826701455647), ((10, 100), 0.0032443799492385653), ((11, 299), 0.0032446355455451542), ((10, 438), 0.0032447075678242576), ((12, 173), 0.0032452895409531063), ((12, 131), 0.0032457028412156636), ((13, 462), 0.003246609949403339), ((13, 154), 0.003246897210677465), ((11, 348), 0.0032472627030478585), ((9, 139), 0.003247887310054567), ((9, 303), 0.003247949191265636), ((11, 220), 0.0032479965852366555), ((9, 416), 0.003248982545402315), ((6, 66), 0.003248991237746345), ((6, 161), 0.003249751196967231), ((13, 394), 0.003249842259618971), ((9, 342), 0.0032510078615612453), ((10, 445), 0.003251066224442588), ((10, 108), 0.0032517568518718085), ((7, 81), 0.00325461911658446), ((12, 187), 0.0032546367082330915), ((11, 107), 0.00325605645775795), ((12, 265), 0.0032577315966288247), ((9, 24), 0.003257900062534544), ((11, 305), 0.0032583054982953602), ((7, 97), 0.0032585528161790636), ((13, 181), 0.0032591064357095295), ((9, 479), 0.0032592061907052994), ((10, 420), 0.0032595578167173597), ((13, 445), 0.0032599280691809123), ((10, 214), 0.003260065077079667), ((6, 142), 0.003260345094733768), ((12, 460), 0.0032607662594980663), ((6, 62), 0.0032621692452165815), ((11, 252), 0.003262425876326031), ((13, 500), 0.003262575094898542), ((10, 60), 0.003263927168316311), ((11, 494), 0.0032651500983370673), ((13, 294), 0.0032653905865218905), ((11, 261), 0.003265769531329473), ((12, 431), 0.0032672014915280873), ((11, 382), 0.0032681512335936227), ((11, 401), 0.0032688391705354056), ((13, 209), 0.003269301106532415), ((10, 187), 0.003269865488012632), ((6, 112), 0.0032715811911556455), ((7, 195), 0.0032717943605449465), ((10, 149), 0.0032718893554475573), ((12, 78), 0.0032725706696510315), ((13, 106), 0.0032731915513674417), ((11, 304), 0.003273194862736596), ((7, 66), 0.0032740719616413116), ((13, 162), 0.003276422205898497), ((10, 177), 0.0032784388297133977), ((12, 68), 0.0032789895517958533), ((12, 502), 0.003279690941174825), ((11, 204), 0.003280598877204789), ((13, 239), 0.0032807497514618766), ((13, 159), 0.003280753476752175), ((13, 183), 0.0032817135668463176), ((13, 272), 0.003282238625817829), ((12, 0), 0.003282304232319196), ((9, 338), 0.003282402124669817), ((11, 26), 0.003284682830174764), ((13, 397), 0.003285137108630604), ((11, 38), 0.0032855975959036085), ((10, 134), 0.0032856373323334586), ((7, 102), 0.0032865338855319554), ((9, 501), 0.003286586039596134), ((13, 49), 0.00328729757004314), ((12, 245), 0.003288837977581554), ((10, 487), 0.0032889188991652597), ((12, 174), 0.0032904139823383754), ((13, 167), 0.0032905369169182247), ((4, 94), 0.003291110404663616), ((13, 227), 0.003291315502590603), ((11, 232), 0.0032916197346316445), ((8, 65), 0.003292271246512731), ((11, 392), 0.0032950308587816027), ((13, 398), 0.0032953015632099575), ((13, 117), 0.0032958537340164185), ((13, 311), 0.003295980600847138), ((10, 389), 0.003296302424536811), ((12, 510), 0.0032963380217552185), ((12, 83), 0.003297878843214777), ((13, 30), 0.0032984125945303175), ((13, 351), 0.003298711445596483), ((12, 427), 0.0032996611876620185), ((12, 1), 0.0033023307720820108), ((12, 433), 0.0033032078709867266), ((6, 196), 0.0033035650849342346), ((11, 449), 0.003304346568054623), ((12, 406), 0.003306333596507708), ((10, 74), 0.0033072976188527215), ((13, 496), 0.003308995937307676), ((10, 414), 0.0033092726435926226), ((11, 144), 0.0033100288775232104), ((9, 141), 0.0033101367039812934), ((6, 154), 0.0033111735764476988), ((7, 73), 0.003313534375694063), ((13, 260), 0.0033138630290826163), ((11, 30), 0.0033141947868797514), ((11, 455), 0.003314429687129127), ((11, 347), 0.0033152256574895647), ((8, 53), 0.003315804733170403), ((13, 180), 0.0033159098691410488), ((12, 355), 0.003317004276646508), ((13, 261), 0.0033173056112395394), ((11, 74), 0.003317818666497866), ((13, 249), 0.003317839569515652), ((7, 129), 0.003317943670683437), ((10, 362), 0.0033180034822887844), ((8, 208), 0.0033191990935140187), ((9, 5), 0.003320150077342987), ((11, 482), 0.003320760817991363), ((7, 24), 0.0033208096606863868), ((12, 170), 0.0033210795372724533), ((11, 134), 0.003321383148431778), ((13, 449), 0.003321384597155783), ((9, 126), 0.0033220892979039084), ((10, 209), 0.003322130690018336), ((12, 148), 0.0033236040423313775), ((11, 282), 0.003323666130503019), ((8, 248), 0.003323667993148168), ((6, 148), 0.0033239656024509007), ((5, 75), 0.003324723078144921), ((10, 416), 0.0033259447664022446), ((13, 67), 0.00332635206480821), ((9, 317), 0.0033264776898754966), ((9, 487), 0.0033271275460720062), ((9, 280), 0.003328940520683924), ((13, 453), 0.0033291218181451163), ((12, 307), 0.003329857976900207), ((13, 283), 0.003330560194121467), ((9, 214), 0.0033314997951189675), ((12, 290), 0.003331889294915729), ((10, 140), 0.003334615793493059), ((13, 12), 0.003334636075629128), ((13, 486), 0.0033350514454974067), ((12, 383), 0.0033367290678951475), ((9, 276), 0.0033368213723103204), ((12, 499), 0.003337383684184816), ((12, 146), 0.003339055304725965), ((9, 379), 0.003339078484310044), ((9, 55), 0.003339398445354568), ((7, 41), 0.003340332872337765), ((12, 294), 0.003340906567043728), ((11, 136), 0.003341137535042233), ((8, 195), 0.003341597608394093), ((11, 25), 0.0033420438153876197), ((11, 436), 0.0033426942924658456), ((11, 311), 0.0033434948159588706), ((7, 167), 0.0033436897728178236), ((3, 36), 0.0033445627325110966), ((12, 385), 0.0033450155622429317), ((10, 224), 0.0033450259102715384), ((10, 347), 0.003347190717856089), ((10, 106), 0.0033492748108175066), ((11, 90), 0.0033498385714160073), ((10, 352), 0.0033498460219966043), ((9, 88), 0.0033502199997504554), ((10, 113), 0.0033513415190908643), ((13, 396), 0.0033518384314245647), ((7, 120), 0.0033520011024342645), ((11, 98), 0.003352152183651924), ((11, 120), 0.003352772237526046), ((12, 352), 0.0033541803972588647), ((12, 339), 0.0033563710749149323), ((13, 498), 0.0033566742721531126), ((9, 235), 0.0033589237266116673), ((9, 300), 0.003360062837600708), ((10, 427), 0.003360336439477073), ((10, 271), 0.0033609308302402496), ((9, 463), 0.0033612919764386285), ((10, 486), 0.0033619668748643664), ((11, 185), 0.003362826175159878), ((12, 109), 0.003363303633199798), ((12, 93), 0.003363880432314343), ((8, 254), 0.0033640203376611075), ((12, 393), 0.0033642659998602336), ((11, 450), 0.0033646534300512737), ((11, 28), 0.0033648808797200522), ((9, 267), 0.0033649251692824894), ((9, 174), 0.003367112949490547), ((10, 2), 0.00336755584511492), ((6, 229), 0.003368818097644382), ((7, 148), 0.003369006638725599), ((7, 213), 0.003369806334376335), ((13, 14), 0.003370252541369862), ((8, 111), 0.003371145162317488), ((9, 378), 0.0033725036515129935), ((13, 390), 0.0033749395774470437), ((10, 351), 0.0033751146660910714), ((13, 492), 0.0033753783338599736), ((5, 17), 0.0033768187794420454), ((10, 345), 0.003377538381351365), ((13, 364), 0.0033793687406513426), ((13, 497), 0.003379587291015519), ((10, 37), 0.0033826749357912275), ((7, 3), 0.0033827821413675943), ((11, 43), 0.00338288437989023), ((12, 490), 0.003383249044418335), ((10, 270), 0.0033833011984825134), ((6, 240), 0.0033834634555710685), ((12, 209), 0.003383468215664228), ((7, 2), 0.0033838628894752925), ((9, 111), 0.0033842788802252877), ((11, 437), 0.0033855351308981576), ((7, 22), 0.0033861102743281257), ((7, 226), 0.0033884644508361816), ((9, 423), 0.0033897004193729824), ((6, 83), 0.00339114334848192), ((12, 492), 0.0033917518125640023), ((12, 384), 0.0033923188845316568), ((12, 75), 0.003392338959707154), ((8, 118), 0.003392768402894338), ((13, 65), 0.0033940602507856158), ((13, 45), 0.003394265141752031), ((11, 139), 0.0033944712744818795), ((12, 435), 0.003396136893166436), ((6, 163), 0.00339683269460996), ((12, 416), 0.003398550053437551), ((11, 97), 0.0033986754715442657), ((10, 11), 0.003399079458581077), ((11, 218), 0.0033996146586206225), ((9, 365), 0.003400451193253199), ((12, 353), 0.003400468991862403), ((12, 364), 0.0034008237222830453), ((13, 337), 0.0034010952545536887), ((13, 421), 0.0034039647628863654), ((13, 145), 0.0034041336427132287), ((8, 210), 0.003404218082626661), ((13, 1), 0.0034045285234848657), ((11, 471), 0.003404890497525533), ((13, 57), 0.003405816439125273), ((6, 20), 0.00340744915107886), ((6, 178), 0.00340754311117861), ((13, 429), 0.0034089446481731203), ((10, 405), 0.003409887353579203), ((12, 312), 0.00341028802924686), ((13, 121), 0.003410411791668998), ((9, 210), 0.00341056018239922), ((12, 452), 0.003410689118835661), ((10, 145), 0.0034110411587688657), ((12, 473), 0.0034115962270233366), ((13, 256), 0.0034120927254358926), ((9, 417), 0.003412123355600569), ((10, 394), 0.003412681735224194), ((11, 417), 0.0034131335301531684), ((6, 215), 0.003413760413726171), ((12, 96), 0.0034142322838306427), ((9, 354), 0.0034168532325161826), ((10, 88), 0.0034194567965136636), ((6, 141), 0.0034200683650043276), ((11, 214), 0.0034214320282141366), ((8, 3), 0.0034217143224345315), ((11, 493), 0.003422273943821589), ((11, 260), 0.0034230233480532966), ((11, 465), 0.003423376836710506), ((11, 135), 0.003423428783814112), ((10, 284), 0.0034238037963708243), ((13, 416), 0.003424357622861862), ((10, 431), 0.0034248634345001644), ((10, 163), 0.0034262179914447996), ((12, 194), 0.0034263022243976593), ((11, 45), 0.003428641292783949), ((10, 9), 0.0034291257874833215), ((13, 353), 0.0034310931546820533), ((11, 288), 0.003431534187661277), ((5, 112), 0.0034320385505755744), ((12, 214), 0.00343208946287632), ((12, 453), 0.0034322082582447263), ((13, 190), 0.0034322626888751984), ((7, 131), 0.0034345549841721854), ((6, 85), 0.0034357313480642107), ((11, 18), 0.0034373102502690423), ((11, 456), 0.0034383158716890547), ((9, 264), 0.003438803263836437), ((5, 50), 0.0034390433381001153), ((7, 134), 0.0034399823182159), ((12, 133), 0.003440137952566147), ((8, 225), 0.0034404022412167657), ((5, 30), 0.0034409972528616586), ((9, 305), 0.0034411483340793187), ((7, 92), 0.0034413283897770774), ((6, 159), 0.0034415374199549356), ((4, 62), 0.003441674013932546), ((13, 344), 0.003443304035398695), ((7, 193), 0.003443727476729287), ((12, 164), 0.0034441834108697045), ((13, 494), 0.0034443578786320156), ((7, 200), 0.00344468177192741), ((13, 465), 0.0034447800781991747), ((13, 135), 0.0034455015427536434), ((12, 328), 0.003446578151649899), ((2, 40), 0.0034466187159220376), ((12, 255), 0.003446983794371287), ((13, 38), 0.00344955465859837), ((13, 155), 0.003449890348646376), ((6, 248), 0.00345028109020657), ((13, 478), 0.003450633337100347), ((6, 217), 0.003450653205315272), ((13, 92), 0.003450947089327706), ((11, 178), 0.0034509613696071836), ((11, 505), 0.003451144943634669), ((11, 32), 0.0034522225873337854), ((8, 235), 0.0034534970505370032), ((12, 127), 0.0034537031832668516), ((11, 255), 0.0034538552992873723), ((13, 310), 0.0034543886366817686), ((12, 101), 0.003459181015690168), ((11, 265), 0.003459632396697998), ((13, 287), 0.003459751605987549), ((11, 44), 0.003460093918773863), ((11, 243), 0.0034609265211555692), ((12, 305), 0.003460977019535171), ((11, 402), 0.0034612512422932517), ((11, 326), 0.0034620436943239635), ((12, 421), 0.0034631221658653682), ((11, 453), 0.0034633506503370074), ((8, 62), 0.003463905718591478), ((13, 24), 0.0034649715655379826), ((10, 229), 0.0034663451628552545), ((11, 283), 0.003467569127678871), ((6, 106), 0.0034689054720931584), ((11, 262), 0.0034696852995289695), ((11, 331), 0.00347083889775806), ((13, 362), 0.0034710117098357943), ((9, 289), 0.0034710499975416395), ((4, 40), 0.003471442394786411), ((13, 158), 0.003472055825922224), ((6, 164), 0.003472527282105552), ((10, 203), 0.0034732710984018114), ((12, 225), 0.003474030229780409), ((11, 492), 0.0034749193323983085), ((7, 192), 0.003475792706012726), ((13, 7), 0.0034761238429281446), ((7, 179), 0.0034762099385261536), ((6, 105), 0.003476808468500773), ((11, 85), 0.0034774442513783774), ((10, 354), 0.003477868934472402), ((11, 276), 0.0034779256416691672), ((11, 470), 0.003478251811530855), ((13, 170), 0.00347885861992836), ((11, 60), 0.003481308619181315), ((10, 247), 0.003481394714779324), ((10, 110), 0.003482204344537523), ((7, 52), 0.0034830342564317915), ((11, 345), 0.0034837664829360116), ((12, 205), 0.0034844448996914756), ((10, 300), 0.003484484222200182), ((12, 21), 0.0034870869583553737), ((9, 345), 0.0034875464108255175), ((13, 483), 0.0034887914856274924), ((12, 330), 0.0034889140062861973), ((10, 58), 0.003490462899208069), ((9, 404), 0.0034907253252135385), ((12, 485), 0.003490793208281199), ((11, 170), 0.0034912005066871643), ((10, 432), 0.003493193123075697), ((13, 237), 0.003493222097555796), ((8, 188), 0.0034935797254244485), ((13, 19), 0.0034937324623266854), ((11, 506), 0.0034942395157284206), ((12, 395), 0.00349441087908215), ((7, 37), 0.003494551198350059), ((9, 390), 0.003494648055897819), ((7, 251), 0.0034956340160634783), ((13, 417), 0.00349660755859481), ((9, 93), 0.003499569578303231), ((10, 94), 0.0035014160805278355), ((13, 50), 0.0035022530290815565), ((12, 46), 0.003502640045351452), ((11, 330), 0.003504995670583513), ((6, 127), 0.0035052585105101266), ((10, 398), 0.0035052593383524152), ((10, 1), 0.0035057556298043993), ((7, 77), 0.003506893085108863), ((13, 174), 0.00350756405128373), ((11, 302), 0.0035084312160809836), ((13, 292), 0.003509008222156101), ((12, 496), 0.003509050856033961), ((13, 73), 0.0035093161794874403), ((13, 270), 0.0035093617108133105), ((13, 393), 0.0035094693303108215), ((7, 95), 0.0035096771187252468), ((11, 75), 0.003509850965605842), ((10, 264), 0.0035101034575038487), ((11, 378), 0.003510576155450609), ((9, 44), 0.0035109023253122964), ((13, 70), 0.0035114379392729867), ((4, 84), 0.0035119429230690002), ((12, 99), 0.0035123477379480996), ((13, 510), 0.0035137306484911176), ((9, 357), 0.0035158180528216893), ((4, 95), 0.003516371879312727), ((9, 470), 0.0035171707471211753), ((13, 123), 0.003517244839006), ((13, 304), 0.00351827343304952), ((9, 375), 0.00351842161681917), ((10, 55), 0.0035184799797005123), ((13, 340), 0.0035188905894756317), ((13, 115), 0.003519957264264425), ((11, 231), 0.0035216067400243548), ((8, 48), 0.003521705667177836), ((11, 110), 0.003522002034717136), ((5, 72), 0.003523206545246972), ((12, 429), 0.0035240650177001953), ((9, 112), 0.003528746465841929), ((11, 273), 0.0035298321810033587), ((13, 4), 0.0035304812093575797), ((6, 95), 0.003532655123207304), ((10, 193), 0.0035330408977137674), ((10, 92), 0.003533661365509033), ((12, 319), 0.0035340446564886305), ((10, 273), 0.003536905679437849), ((13, 182), 0.0035369466576311323), ((9, 102), 0.00353717886739307), ((13, 20), 0.0035373494029045105), ((9, 166), 0.0035374541249540118), ((6, 69), 0.0035374905500147077), ((13, 322), 0.003538578748703003), ((8, 94), 0.0035389777686860827), ((13, 406), 0.00353989087873035), ((11, 142), 0.003540250990125868), ((11, 55), 0.0035422026283211177), ((13, 464), 0.003542903396818373), ((9, 407), 0.003543094214465883), ((10, 5), 0.0035439406832059226), ((11, 301), 0.0035452350146240657), ((4, 60), 0.003545422520902422), ((12, 298), 0.003545740826262368), ((9, 101), 0.0035457656615310246), ((12, 58), 0.0035462818211979335), ((13, 229), 0.0035468190908432007), ((13, 479), 0.0035476175447305045), ((12, 480), 0.0035494930214352077), ((12, 288), 0.0035501056247287327), ((11, 433), 0.0035504471096727583), ((13, 163), 0.003550569216410319), ((11, 366), 0.003550862272580465), ((13, 111), 0.003551760067542394), ((13, 80), 0.003552079200744629), ((9, 230), 0.003553430653280682), ((9, 408), 0.003554588390721215), ((6, 247), 0.003554830120669471), ((6, 228), 0.003554946846432156), ((10, 462), 0.0035550097624460855), ((12, 49), 0.0035564088159137303), ((10, 337), 0.0035564746293756696), ((12, 11), 0.0035576195352607304), ((10, 175), 0.0035586580634117126), ((7, 61), 0.003560514913664924), ((12, 22), 0.0035614946650134195), ((13, 389), 0.0035617686808109283), ((8, 228), 0.003562284012635549), ((11, 485), 0.00356433168053627), ((13, 357), 0.0035645696851942274), ((11, 476), 0.003565290735827552), ((12, 356), 0.003565352823999193), ((11, 286), 0.003565810206863615), ((12, 285), 0.003566552781396442), ((13, 177), 0.003569209741221534), ((4, 51), 0.0035694175296359593), ((13, 36), 0.003569499072101381), ((13, 71), 0.003570839762687683), ((10, 207), 0.0035718832578923968), ((13, 247), 0.0035731949739985997), ((12, 273), 0.0035748353434933555), ((13, 125), 0.0035754901667435965), ((12, 94), 0.0035755683978398642), ((10, 135), 0.0035759595533212027), ((9, 288), 0.003575963278611501), ((13, 410), 0.003576500134335624), ((11, 179), 0.003576671911610497), ((13, 75), 0.0035766934355099997), ((12, 198), 0.003578110287586848), ((13, 502), 0.0035786570774184335), ((9, 330), 0.0035796004037062326), ((11, 435), 0.0035797680417696633), ((13, 52), 0.003579984108606974), ((12, 223), 0.003580673701233334), ((12, 249), 0.0035812610553370584), ((11, 206), 0.00358158184422387), ((8, 242), 0.003582336422469881), ((13, 289), 0.0035824349357022178), ((9, 465), 0.003583167162206438), ((13, 408), 0.0035836369627051884), ((8, 127), 0.0035839656160937417), ((11, 475), 0.0035847926305400003), ((13, 59), 0.003584961924288008), ((13, 411), 0.0035853791568014356), ((5, 21), 0.0035866561035315194), ((13, 112), 0.0035875261657767827), ((12, 140), 0.0035881217983033922), ((9, 37), 0.0035885940823290083), ((7, 67), 0.003588708738485972), ((8, 36), 0.003588793178399404), ((11, 446), 0.0035889152851369646), ((12, 114), 0.0035902783274650574), ((6, 124), 0.0035908098022143045), ((4, 90), 0.003591783344745636), ((13, 284), 0.0035928181476063198), ((7, 218), 0.003593818181090885), ((13, 278), 0.0035939630534913805), ((13, 146), 0.003596445752514733), ((8, 114), 0.003600127167171902), ((12, 203), 0.0036004305713706547), ((9, 51), 0.003603782918718126), ((10, 61), 0.0036039513846238456), ((11, 237), 0.0036044038004345363), ((13, 204), 0.003604763083987766), ((10, 369), 0.003605029649204678), ((10, 115), 0.003606403867403666), ((12, 117), 0.0036072019073698255), ((12, 143), 0.003608201113012102), ((13, 491), 0.0036085997190740374), ((11, 73), 0.0036099511716100904), ((11, 12), 0.00361109690533744), ((13, 234), 0.0036116792923874324), ((12, 224), 0.0036118866668807138), ((13, 189), 0.0036122906539175245), ((6, 113), 0.00361311642660035), ((11, 381), 0.0036139090855916343), ((13, 355), 0.0036139562726020813), ((13, 401), 0.0036143126587073007), ((9, 435), 0.003614644209543864), ((10, 241), 0.0036147994299729667), ((10, 359), 0.0036153768499692283), ((12, 87), 0.0036156272722615134), ((12, 396), 0.003616123149792353), ((13, 484), 0.0036162791980637442), ((9, 250), 0.0036172974440786573), ((11, 339), 0.003619687838686837), ((11, 468), 0.0036201493607627023), ((11, 463), 0.003620290093951755), ((12, 200), 0.0036202996141380733), ((6, 208), 0.0036209324995676675), ((12, 486), 0.003621550897757212), ((13, 403), 0.0036225029163890416), ((13, 21), 0.003622728917333815), ((13, 415), 0.0036240236626731027), ((13, 382), 0.0036243312060832977), ((11, 186), 0.003626336240106159), ((10, 494), 0.0036264417899979483), ((12, 369), 0.0036266855895519257), ((10, 210), 0.00362688841091262), ((12, 363), 0.003627434786823061), ((13, 152), 0.0036297067999839783), ((12, 14), 0.003629886441760593), ((13, 31), 0.0036313417885038587), ((13, 232), 0.0036314986646175385), ((2, 29), 0.0036323455472787223), ((6, 170), 0.003633201950126224), ((13, 263), 0.0036334308485190072), ((6, 251), 0.0036342673831515843), ((13, 128), 0.0036344842778311837), ((10, 228), 0.0036348849534988403), ((8, 193), 0.0036353940765062966), ((11, 317), 0.003636066284444597), ((5, 49), 0.0036363336775037977), ((13, 46), 0.003636496348513497), ((13, 221), 0.0036371234390470716), ((13, 228), 0.0036377588080035318), ((13, 127), 0.0036378084785408443), ((13, 157), 0.0036378328998883567), ((10, 497), 0.003638337469763226), ((13, 295), 0.0036383618911107383), ((11, 150), 0.003639643390973409), ((7, 153), 0.0036402245362599692), ((11, 51), 0.00364077091217041), ((10, 485), 0.0036409770449002585), ((13, 236), 0.0036414658857716452), ((11, 411), 0.0036416364212830863), ((13, 468), 0.003641681124766668), ((11, 422), 0.003642374442683326), ((12, 228), 0.0036434481541315713), ((11, 116), 0.0036441427138116625), ((6, 176), 0.0036449184020360312), ((9, 384), 0.0036452652679549325), ((13, 25), 0.003646497925122579), ((12, 367), 0.0036469722787539163), ((6, 166), 0.0036471825506952074), ((10, 288), 0.0036474785043133628), ((7, 216), 0.0036487244069576263), ((13, 144), 0.0036489367485046387), ((11, 201), 0.003649387922551897), ((13, 285), 0.003649891664584478), ((6, 223), 0.003650063027938207), ((12, 358), 0.0036503742966387006), ((7, 227), 0.00365108417140113), ((7, 143), 0.0036519914865493774), ((10, 412), 0.0036531943413946363), ((9, 449), 0.003653396334913042), ((12, 212), 0.0036534153752856785), ((12, 379), 0.0036539865864647757), ((13, 458), 0.003655204342471229), ((13, 150), 0.003655391020907296), ((10, 335), 0.0036559460891617667), ((13, 302), 0.0036567780706617567), ((13, 420), 0.003659651925166448), ((8, 249), 0.003661110583278868), ((11, 479), 0.003661825011173884), ((12, 35), 0.0036620344552728864), ((13, 315), 0.003662318405177858), ((13, 242), 0.0036628726455900404), ((7, 138), 0.003663848257727093), ((11, 454), 0.0036644256777233547), ((9, 220), 0.003665209644370609), ((11, 37), 0.0036658019655280644), ((10, 464), 0.0036666111813651193), ((11, 112), 0.003666691482067108), ((11, 54), 0.0036667022440168592), ((7, 6), 0.0036685835156175825), ((13, 480), 0.0036691303054491677), ((7, 44), 0.003672105156713062), ((6, 35), 0.003673847350809309), ((10, 248), 0.0036744545731279585), ((10, 117), 0.0036744938956366647), ((13, 324), 0.0036750779383712346), ((10, 136), 0.0036754384636878967), ((13, 9), 0.003675764633549584), ((11, 306), 0.0036768660777144963), ((9, 398), 0.0036788342727555167), ((9, 132), 0.0036793177326520285), ((6, 221), 0.0036799030171500314), ((7, 40), 0.003680044578181373), ((13, 18), 0.0036802002125316197), ((13, 212), 0.003680647247367435), ((11, 490), 0.0036806795332166883), ((11, 293), 0.003682052923573388), ((12, 313), 0.0036826754609743753), ((9, 343), 0.0036844064791997275), ((13, 113), 0.0036849139465226066), ((13, 0), 0.0036850281887584263), ((10, 125), 0.00368566686908404), ((12, 507), 0.0036857256458865274), ((13, 100), 0.0036859561999638877), ((2, 55), 0.0036865133378240797), ((13, 215), 0.0036871408422787986), ((12, 123), 0.00368903163406584), ((12, 329), 0.0036900705761379665), ((11, 373), 0.0036901748842663234), ((9, 409), 0.0036904141306877136), ((12, 138), 0.003690857854154375), ((10, 428), 0.003691753993431727), ((13, 161), 0.0036928214960628087), ((13, 387), 0.003692838880750868), ((12, 215), 0.00369340181350708), ((11, 225), 0.0036943480372428894), ((11, 191), 0.0036958654721577964), ((13, 303), 0.0036977028681172263), ((10, 131), 0.003697836564646827), ((12, 411), 0.00369811968670951), ((11, 130), 0.003699522465467453), ((12, 153), 0.0036995605462127263), ((13, 3), 0.0036997770269711814), ((12, 360), 0.0037000030279159546), ((13, 276), 0.0037000630464818743), ((10, 374), 0.003700601557890574), ((11, 164), 0.0037010047170850965), ((11, 342), 0.003701412015491062), ((11, 338), 0.003703046590089798), ((10, 169), 0.0037038574616114297), ((13, 379), 0.003704206811057197), ((8, 49), 0.0037045669224527148), ((9, 115), 0.0037047341465950012), ((11, 217), 0.003707064522637261), ((5, 73), 0.0037084552976820204), ((10, 482), 0.003710562984148661), ((11, 87), 0.003710992220375273), ((12, 181), 0.0037118072311083474), ((10, 150), 0.003712825063202116), ((8, 52), 0.0037138722836971283), ((12, 230), 0.003713946375581953), ((6, 213), 0.0037144141064749826), ((9, 313), 0.0037147444155481127), ((12, 283), 0.003715001874499851), ((13, 380), 0.003715026709768507), ((13, 129), 0.0037150676879617902), ((10, 319), 0.0037162635061475965), ((11, 172), 0.0037164679831928676), ((7, 163), 0.0037189647555351257), ((13, 165), 0.0037195243769221837), ((7, 13), 0.0037202350795269012), ((12, 9), 0.0037202445997132193), ((12, 69), 0.00372111052274704), ((12, 90), 0.0037213671538564893), ((13, 176), 0.0037218170861403146), ((10, 154), 0.003724269154998991), ((10, 225), 0.003724281986554464), ((12, 134), 0.003725348247422112), ((10, 407), 0.0037261943022410073), ((13, 243), 0.0037273441751797995), ((8, 206), 0.003727688557571835), ((12, 124), 0.0037280345956484475), ((13, 142), 0.00372878834605217), ((8, 10), 0.0037296112212869856), ((11, 23), 0.0037297668556372323), ((4, 10), 0.003731243312358856), ((11, 238), 0.0037316733764277566), ((12, 85), 0.003731822801960839), ((6, 230), 0.003732498735189438), ((10, 219), 0.0037329792976379395), ((7, 99), 0.00373379099700186), ((10, 180), 0.0037342078155941432), ((13, 297), 0.0037349677748150295), ((13, 264), 0.003735007925166024), ((10, 458), 0.0037359388338194955), ((4, 106), 0.0037384749286704594), ((12, 147), 0.003739145894845327), ((13, 84), 0.0037398330039448207), ((7, 252), 0.003741225020753013), ((8, 237), 0.0037423090802298654), ((13, 434), 0.003742673330836826), ((10, 33), 0.0037443811694780984), ((13, 254), 0.0037447594934039647), ((11, 369), 0.0037448787026935155), ((9, 1), 0.0037450575166278416), ((13, 96), 0.003746533973349465), ((13, 238), 0.003747774495018853), ((13, 105), 0.003748832477463616), ((13, 197), 0.003749459981918335), ((11, 406), 0.0037498242325252956), ((11, 278), 0.0037515146864785087), ((12, 126), 0.003752507683303621), ((7, 168), 0.003752610749668545), ((12, 451), 0.003752717541323768), ((9, 454), 0.003753090484274758), ((10, 179), 0.0037531757520304788), ((10, 143), 0.0037538218829366895), ((13, 299), 0.0037543049289120566), ((10, 182), 0.003754453112681707), ((12, 403), 0.003755248255199856), ((8, 217), 0.0037558356093035806), ((7, 151), 0.00375643703672621), ((12, 284), 0.0037569511267873975), ((12, 426), 0.003757133666012022), ((11, 451), 0.003757236732376946), ((10, 171), 0.0037573998173077903), ((9, 450), 0.0037597931093639797), ((13, 69), 0.0037602616680992972), ((6, 210), 0.0037615771094957986), ((11, 501), 0.0037618474000030095), ((9, 106), 0.0037620034482744005), ((13, 241), 0.0037620796097649466), ((6, 23), 0.0037644741435845694), ((12, 27), 0.003765015552441279), ((11, 171), 0.0037651595969994864), ((11, 15), 0.0037655006680223676), ((12, 221), 0.003767503632439507), ((11, 27), 0.0037676642338434854), ((13, 224), 0.0037678579489390054), ((11, 69), 0.003767913414372338), ((13, 250), 0.003768722630209393), ((13, 103), 0.0037688244548108843), ((10, 201), 0.0037689494589964547), ((12, 447), 0.003769061631626553), ((13, 425), 0.0037696522970994315), ((9, 302), 0.0037718332476086086), ((13, 291), 0.0037720460030767652), ((10, 114), 0.0037733622723155552), ((13, 94), 0.003773369722896152), ((5, 65), 0.00377378405796157), ((10, 122), 0.003775521285004086), ((12, 199), 0.0037757601175043318), ((11, 234), 0.0037763938307762146), ((12, 204), 0.0037776190373632642), ((10, 20), 0.0037785019311639997), ((11, 487), 0.0037804386681980556), ((9, 499), 0.003780694885386361), ((11, 155), 0.003780937443176905), ((6, 222), 0.0037815190023846095), ((13, 370), 0.0037830140855577257), ((13, 114), 0.003783383303218418), ((9, 195), 0.0037834925784005057), ((13, 85), 0.0037836978832880654), ((7, 4), 0.003783770733409458), ((13, 463), 0.0037846689422925315), ((13, 23), 0.0037864852282736036), ((10, 34), 0.003789562318060133), ((12, 274), 0.003789835506015354), ((6, 220), 0.0037909352944956887), ((12, 116), 0.0037914042671521506), ((13, 422), 0.0037917171915372214), ((10, 333), 0.003793545895152622), ((3, 21), 0.0037939676807986367), ((12, 247), 0.003794011970361074), ((10, 133), 0.003794801731904348), ((13, 138), 0.0037975824541515773), ((7, 17), 0.003797913591066996), ((11, 357), 0.003798831668164995), ((9, 427), 0.003798914866314994), ((11, 425), 0.003799326303932402), ((13, 13), 0.0037997249099943372), ((11, 319), 0.0038000792264938354), ((10, 392), 0.0038012833231025273), ((6, 111), 0.0038017473287052577), ((10, 503), 0.0038026058011584813), ((11, 320), 0.0038034493724505105), ((12, 467), 0.003804357929362191), ((12, 29), 0.0038047764036390516), ((6, 98), 0.003804971774419149), ((4, 52), 0.003805966013007694), ((11, 168), 0.003805985467301475), ((10, 123), 0.0038066663675838048), ((6, 89), 0.003806736734178331), ((9, 194), 0.0038070455193519592), ((10, 261), 0.003808880845705668), ((12, 144), 0.0038094561960962084), ((12, 2), 0.0038108999530474343), ((13, 442), 0.003811176452371809), ((8, 155), 0.003811375548442205), ((13, 404), 0.0038139426873789895), ((13, 437), 0.003814135988553365), ((13, 42), 0.0038151037361886767), ((12, 487), 0.003816102941830953), ((8, 238), 0.0038162701659732396), ((13, 338), 0.0038169316119617885), ((12, 404), 0.003818696571720971), ((7, 119), 0.0038188041912184823), ((13, 95), 0.0038196874989403617), ((10, 452), 0.0038200608558124965), ((12, 440), 0.0038201709588368735), ((13, 432), 0.00382076534960005), ((11, 152), 0.0038212359779410893), ((11, 10), 0.0038213510480191973), ((8, 40), 0.0038221507436699336), ((11, 430), 0.0038230249451266397), ((12, 206), 0.0038232310778564876), ((12, 444), 0.0038234715660413108), ((8, 178), 0.0038237435122330985), ((13, 349), 0.0038255121972825793), ((10, 403), 0.0038257700701554618), ((13, 8), 0.003826265533765157), ((8, 57), 0.003828502363628811), ((8, 43), 0.0038290839228365156), ((11, 297), 0.0038292474216885036), ((13, 60), 0.0038305570681889853), ((10, 21), 0.003832627087831497), ((11, 207), 0.0038332839806874595), ((13, 456), 0.0038344450294971466), ((8, 115), 0.0038345265719625684), ((13, 153), 0.0038345716893672943), ((13, 342), 0.003834664821624756), ((11, 318), 0.003834926419787937), ((13, 5), 0.0038351035780376857), ((13, 499), 0.003835678514507082), ((11, 77), 0.003837388422754076), ((13, 122), 0.0038380432460043165), ((11, 307), 0.003839184840520223), ((7, 202), 0.0038392055365774366), ((13, 255), 0.0038404266039530435), ((12, 494), 0.0038411476545863682), ((13, 269), 0.003841432432333628), ((12, 389), 0.00384156819846895), ((7, 181), 0.003841860426796807), ((9, 380), 0.0038423314690589905), ((13, 334), 0.0038427329725689357), ((12, 120), 0.0038427975442674425), ((13, 300), 0.0038432321614689296), ((12, 420), 0.003843854698869917), ((8, 159), 0.0038440583480728995), ((12, 341), 0.0038465865784221226), ((6, 168), 0.0038470116754372916), ((12, 202), 0.003847324185901218), ((12, 442), 0.0038475187288390267), ((8, 24), 0.003847944653696484), ((11, 101), 0.0038480108810795676), ((10, 166), 0.003848675224516127), ((3, 38), 0.003848741865820355), ((11, 361), 0.0038491677906778124), ((12, 119), 0.0038497373461723328), ((13, 116), 0.003851150472958883), ((9, 491), 0.0038534079988797507), ((11, 216), 0.003853792945543925), ((13, 83), 0.003854850927988688), ((11, 245), 0.003855696568886439), ((12, 508), 0.0038556986384921605), ((11, 325), 0.003856481777297126), ((13, 371), 0.0038574693931473624), ((13, 314), 0.0038577214711242253), ((7, 79), 0.0038602716392940944), ((13, 32), 0.0038608391251828936), ((5, 107), 0.0038619115948677063), ((13, 366), 0.003863039943906996), ((13, 377), 0.003863133490085602), ((6, 146), 0.0038647825519243875), ((13, 166), 0.0038667461938328212), ((12, 257), 0.003867334789699978), ((13, 273), 0.0038680562542544473), ((11, 95), 0.003868160976303948), ((8, 70), 0.00386839649743504), ((10, 297), 0.003869537678029802), ((11, 105), 0.0038706308437718284), ((11, 200), 0.0038707243899504342), ((10, 232), 0.003870996336142222), ((13, 118), 0.0038717505004670885), ((11, 113), 0.003873166110780504), ((12, 449), 0.0038756123847431606), ((11, 508), 0.003875910821888182), ((13, 2), 0.003876452230744892), ((13, 444), 0.003876891401078966), ((13, 63), 0.0038771985305680167), ((11, 328), 0.0038774762716558245), ((12, 80), 0.0038775851329167685), ((8, 86), 0.003877737455897861), ((11, 267), 0.0038779866364267138), ((8, 252), 0.0038801303340329062), ((12, 141), 0.0038806580834918553), ((10, 52), 0.0038806754681799146), ((13, 11), 0.003880766530831655), ((10, 429), 0.00388103144036399), ((13, 240), 0.0038815082775221933), ((7, 240), 0.003885750969250997), ((12, 229), 0.003886053131686317), ((13, 424), 0.003887366917398241), ((11, 478), 0.003888496922122108), ((6, 212), 0.003888801568084293), ((12, 208), 0.003889476259549459), ((11, 92), 0.0038902171783977086), ((13, 274), 0.00389075775941213), ((11, 148), 0.003890758587254418), ((10, 80), 0.003890859997934765), ((11, 393), 0.003892049193382263), ((12, 412), 0.003892146878772312), ((12, 428), 0.003892207311259376), ((13, 143), 0.003894591083129247), ((11, 457), 0.003894661863644918), ((5, 36), 0.003895588219165802), ((13, 210), 0.0038959508140881858), ((12, 504), 0.0038963937097125584), ((4, 87), 0.0038974032633834416), ((10, 343), 0.0038978498842981127), ((10, 388), 0.0038983337581157684), ((10, 198), 0.003898339139090644), ((8, 56), 0.0038985717627737257), ((6, 118), 0.0038996305730607775), ((13, 395), 0.0039003309276368883), ((9, 187), 0.003903364141782125), ((12, 10), 0.0039035239153438145), ((10, 8), 0.0039036555422676932), ((13, 136), 0.003904709385501014), ((13, 206), 0.003907358480824364), ((13, 186), 0.003907512459490035), ((13, 391), 0.003907519910070632), ((13, 280), 0.003909728593296475), ((12, 250), 0.003910507592889998), ((12, 394), 0.003910635908444722), ((10, 159), 0.003913223743438721), ((11, 228), 0.003913297421402401), ((5, 71), 0.003914903435442183), ((11, 198), 0.003915586819251378), ((9, 39), 0.003915964315334956), ((11, 96), 0.003916090147362815), ((12, 59), 0.003916114568710327), ((11, 391), 0.003916414247618781), ((6, 65), 0.00391651193300883), ((6, 169), 0.003916516900062561), ((12, 382), 0.003919084038999345), ((11, 159), 0.0039202020400100285), ((11, 310), 0.00392088500989808), ((13, 214), 0.003920993043316735), ((10, 440), 0.003921926021575928), ((10, 409), 0.003922405342260997), ((13, 471), 0.003923123909367455), ((13, 383), 0.003925875243213441), ((12, 263), 0.0039271095560656655), ((11, 473), 0.003927482499016656), ((10, 256), 0.00392909554971589), ((8, 104), 0.00393020941151513), ((13, 51), 0.003930650237533782), ((11, 287), 0.003930882861216863), ((11, 188), 0.003931114657057656), ((13, 235), 0.00393139984872606), ((13, 359), 0.003931705322530534), ((11, 47), 0.003931802180078294), ((7, 115), 0.003932046393553416), ((11, 100), 0.003932634989420573), ((12, 260), 0.003933460762103398), ((10, 265), 0.003934066328737471), ((12, 190), 0.0039342790842056274), ((11, 403), 0.003934854020675023), ((13, 318), 0.003935563895437453), ((12, 172), 0.0039359645711051095), ((11, 52), 0.00393631723192003), ((11, 428), 0.003936988612016042), ((2, 2), 0.003937005168861813), ((11, 7), 0.003937573068671756), ((2, 17), 0.003938651747173733), ((13, 66), 0.003939359552330441), ((10, 200), 0.0039399369723267024), ((8, 92), 0.00394520577457216), ((13, 368), 0.003945397833983104), ((13, 501), 0.003946055554681354), ((7, 255), 0.003947959591945012), ((13, 323), 0.0039485957887437605), ((11, 71), 0.003949366095993254), ((9, 376), 0.003949413696924846), ((4, 119), 0.003950178209278319), ((11, 263), 0.003950181520647473), ((12, 188), 0.003950194766124089), ((8, 47), 0.003954332735803392), ((11, 414), 0.003955172167883979), ((11, 491), 0.003958543141682942), ((9, 474), 0.003959173957506816), ((13, 26), 0.003959241012732188), ((9, 428), 0.00396117443839709), ((13, 248), 0.003961389677392112), ((10, 315), 0.003962325553099315), ((13, 495), 0.003964051604270935), ((9, 507), 0.0039642614622910815), ((9, 45), 0.003964641855822669), ((8, 88), 0.003966172536214192), ((8, 243), 0.00396922810210122), ((5, 2), 0.003969822906785541), ((7, 91), 0.003969993442296982), ((7, 247), 0.003970110581980811), ((7, 211), 0.003971731497181786), ((10, 24), 0.0039723896318011815), ((11, 67), 0.003974981606006622), ((13, 505), 0.003975977500279744), ((13, 392), 0.003976842181550132), ((13, 226), 0.003977215538422267), ((6, 5), 0.003977611660957336), ((13, 216), 0.003977997021542655), ((11, 181), 0.003979129923714532), ((6, 43), 0.003980251650015513), ((13, 76), 0.003980483031935162), ((13, 91), 0.003981089012490379), ((7, 180), 0.003981992602348328), ((10, 437), 0.003982972767617967), ((13, 140), 0.0039831896622975664), ((13, 97), 0.003984309732913971), ((13, 72), 0.003984667774703767), ((6, 207), 0.003984830445713467), ((12, 167), 0.003985005120436351), ((10, 267), 0.003985029541783863), ((9, 224), 0.003986394239796532), ((8, 45), 0.003987729549407959), ((12, 72), 0.003988301588429345), ((10, 239), 0.003988304485877355), ((13, 435), 0.003989023466904958), ((13, 374), 0.003989189035362667), ((13, 124), 0.0039900251560741), ((12, 254), 0.003990090141693751), ((9, 485), 0.003991175029012892), ((10, 112), 0.003991875797510147), ((12, 270), 0.0039918828341696), ((12, 192), 0.003992419275972579), ((8, 126), 0.003993307964669334), ((11, 448), 0.003993525687191222), ((4, 63), 0.00399373471736908), ((13, 293), 0.003994200792577531), ((6, 73), 0.003997752649916543), ((13, 279), 0.00400064554479387), ((10, 418), 0.004001522229777442), ((10, 197), 0.0040015975634257), ((13, 363), 0.00400289065308041), ((10, 449), 0.004002950257725186), ((11, 497), 0.004004124965932634), ((8, 17), 0.004005311677853267), ((10, 375), 0.004005703661176894), ((11, 274), 0.004006121721532609), ((8, 224), 0.004008397459983826), ((13, 56), 0.0040090373820728725), ((12, 81), 0.0040090787741873), ((13, 506), 0.004010985294977824), ((7, 0), 0.004011123544640011), ((13, 265), 0.004012345853779051), ((13, 298), 0.0040145280460516615), ((12, 151), 0.004015119539366828), ((9, 421), 0.004015237092971802), ((6, 12), 0.004017188317245907), ((13, 61), 0.0040197715991073186), ((9, 148), 0.0040202149086528355), ((7, 84), 0.004021612306435903), ((11, 327), 0.004023720406823688), ((10, 367), 0.00402555118004481), ((9, 442), 0.004025688601864709), ((10, 325), 0.004026220904456245), ((11, 154), 0.004026273058520423), ((13, 222), 0.004026952717039321), ((12, 235), 0.004027698602941301), ((13, 231), 0.004028140670723385), ((9, 211), 0.004030692080656688), ((13, 164), 0.004030713190635045), ((10, 303), 0.004034794039196438), ((11, 19), 0.004034886757532756), ((12, 84), 0.004034994790951411), ((12, 207), 0.004035196784469817), ((13, 102), 0.004036098304722045), ((11, 114), 0.004036323063903385), ((12, 488), 0.004037209682994419), ((12, 113), 0.00403736862871382), ((13, 141), 0.004038507739702861), ((6, 19), 0.004039528469244639), ((10, 451), 0.004040220545397865), ((13, 6), 0.004041520257790883), ((11, 48), 0.004044632944795821), ((12, 324), 0.0040453751054075025), ((9, 191), 0.004045893748601277), ((13, 317), 0.004046262138419681), ((13, 473), 0.004046501384841071), ((11, 223), 0.004046928137540817), ((13, 151), 0.004047228230370415), ((12, 128), 0.004048593756225374), ((9, 74), 0.004049488653739293), ((9, 347), 0.004050912956396739), ((13, 369), 0.004052773945861393), ((12, 468), 0.00405295193195343), ((11, 230), 0.004052990426619847), ((13, 313), 0.004053102599249946), ((5, 34), 0.004053108394145966), ((12, 300), 0.004053187039163377), ((8, 20), 0.004054765734407637), ((4, 120), 0.004055451187822554), ((10, 489), 0.004056364297866821), ((13, 367), 0.004057036091883977), ((7, 203), 0.004057466983795166), ((12, 371), 0.004057504236698151), ((11, 146), 0.004058320489194658), ((12, 150), 0.00405912846326828), ((8, 202), 0.004060126013225979), ((11, 399), 0.004060607817437913), ((11, 461), 0.00406083216269811), ((13, 320), 0.004062594638930427), ((12, 432), 0.004062911288605796), ((13, 185), 0.004062973376777437), ((12, 388), 0.004064151396354039), ((10, 12), 0.0040651899245050215), ((13, 81), 0.004066978063848283), ((8, 21), 0.00406822810570399), ((13, 77), 0.0040683017836676705), ((10, 82), 0.0040704744557539625), ((11, 372), 0.004071266286902958), ((5, 98), 0.004072237345907424), ((8, 42), 0.004072394635942247), ((11, 182), 0.004073816041151683), ((12, 86), 0.004074176980389489), ((13, 202), 0.004075022207366096), ((13, 282), 0.004075460549857881), ((13, 335), 0.004075942354069816), ((12, 125), 0.004076748258537716), ((11, 385), 0.004077231718434228), ((11, 211), 0.004078232579761081), ((8, 59), 0.004078698654969533), ((7, 158), 0.004079370862907833), ((12, 489), 0.0040794677204555934), ((7, 54), 0.004080880847242143), ((10, 23), 0.004081129613849852), ((13, 385), 0.004081413977675968), ((12, 511), 0.004082897884978188), ((13, 308), 0.004084739006227917), ((13, 455), 0.004085507657792833), ((11, 137), 0.004085746076371934), ((10, 308), 0.004086034993330638), ((13, 205), 0.0040862419539027745), ((9, 282), 0.004086524662044313), ((13, 470), 0.004087420801321666), ((11, 46), 0.004087960554493798), ((13, 475), 0.004090276857217153), ((13, 133), 0.00409042669667138), ((12, 193), 0.004090531004799737), ((7, 62), 0.004090667598777347), ((11, 14), 0.004092024432288276), ((8, 196), 0.00409235805273056), ((11, 440), 0.004093477295504676), ((12, 256), 0.004096801496214337), ((12, 391), 0.004102299196852578), ((10, 366), 0.004102957331471973), ((11, 285), 0.00410739208261172), ((12, 246), 0.004108353207508723), ((13, 131), 0.004108969950013691), ((12, 439), 0.004110021723641289), ((12, 40), 0.004111808207299974), ((13, 110), 0.00411712709400389), ((10, 276), 0.0041172347135014), ((12, 76), 0.004117557571993934), ((13, 446), 0.00411825171775288), ((11, 486), 0.00411856836742825), ((13, 201), 0.0041214823722839355), ((12, 503), 0.00412211815516154), ((13, 405), 0.004122558567259047), ((13, 89), 0.0041239216095871395), ((12, 142), 0.004124173687564002), ((11, 163), 0.00412506361802419), ((6, 205), 0.004126477572653029), ((6, 151), 0.004126831889152527), ((13, 332), 0.004129133290714688), ((8, 145), 0.004131716986497243), ((13, 485), 0.004132354838980569), ((12, 275), 0.004132657415337033), ((13, 62), 0.004132792353630066), ((12, 51), 0.004133719950914383), ((12, 165), 0.004134109864632289), ((6, 33), 0.004134572214550442), ((6, 7), 0.004135904212792714), ((13, 436), 0.004137864543331994), ((13, 511), 0.004139666342073017), ((13, 409), 0.004141088161203597), ((9, 48), 0.004143110579914517), ((7, 93), 0.004143845703866746), ((13, 375), 0.004144139587879181), ((13, 472), 0.004144800206025441), ((9, 411), 0.004146282871564229), ((13, 451), 0.004147482415040334), ((8, 223), 0.00414760990275277), ((11, 64), 0.004147701793246799), ((11, 447), 0.004148033758004506), ((10, 235), 0.004149109952979618), ((7, 114), 0.004149916271368663), ((13, 267), 0.004150469270017412), ((11, 398), 0.004151434534125858), ((11, 50), 0.004154351436429554), ((8, 172), 0.004155315458774567), ((2, 38), 0.004155619276894463), ((13, 372), 0.004156012501981523), ((9, 67), 0.004156307213836246), ((11, 329), 0.00415763548678822), ((12, 306), 0.004157693849669563), ((12, 419), 0.004158577571312587), ((8, 137), 0.004158876422378752), ((13, 130), 0.004159240259064568), ((11, 352), 0.0041595275203386945), ((11, 102), 0.004159613202015559), ((11, 379), 0.0041606177886327105), ((9, 188), 0.004161307381259071), ((12, 8), 0.004164717677566741), ((12, 407), 0.004164731336964501), ((7, 11), 0.004164865447415246), ((12, 347), 0.004165861755609512), ((7, 224), 0.0041663216220008), ((11, 266), 0.004167199962668949), ((12, 18), 0.004169337451457977), ((13, 132), 0.004170501397715675), ((9, 367), 0.0041706230905320905), ((12, 32), 0.004171388016806709), ((8, 76), 0.004171458383401235), ((13, 286), 0.004173424922757679), ((13, 220), 0.004174036698208915), ((11, 462), 0.004174614118205177), ((12, 436), 0.004175059497356415), ((13, 466), 0.004175117446316613), ((10, 260), 0.004175189882516861), ((11, 434), 0.004175451894601186), ((12, 176), 0.004177018172211117), ((13, 345), 0.004178555475340949), ((13, 347), 0.004183093706766765), ((10, 472), 0.004184284971819984), ((13, 34), 0.0041849058535363935), ((13, 28), 0.004185003125005298), ((13, 507), 0.004186633560392592), ((8, 135), 0.004186747802628411), ((10, 191), 0.004187639388773177), ((9, 135), 0.00418920980559455), ((11, 360), 0.004189305007457733), ((12, 33), 0.004189875390794542), ((13, 454), 0.004191896981663174), ((11, 268), 0.004192610581715901), ((10, 26), 0.004193596127960417), ((6, 25), 0.004193995147943497), ((7, 135), 0.004194094489018123), ((11, 62), 0.004197405030330022), ((13, 78), 0.0041990263594521415), ((13, 245), 0.0042006754212909276), ((11, 480), 0.004203940845198101), ((11, 426), 0.004204463627603319), ((12, 7), 0.004204582009050582), ((8, 132), 0.004206050601270463), ((13, 230), 0.00420696743660503), ((4, 112), 0.004207006345192592), ((13, 388), 0.004208284119764964), ((13, 200), 0.004209109892447789), ((11, 380), 0.0042100730869505144), ((11, 314), 0.004210689001613193), ((10, 313), 0.004211067325539059), ((12, 354), 0.004213767333163155), ((13, 54), 0.004214605523480309), ((12, 310), 0.004217327468925052), ((12, 325), 0.0042180998457802665), ((8, 219), 0.004218334125147926), ((13, 358), 0.00421857088804245), ((11, 343), 0.004219171073701646), ((11, 477), 0.0042205022441016305), ((12, 100), 0.004221851627031962), ((10, 385), 0.004222240712907579), ((6, 126), 0.004222777982552846), ((12, 302), 0.004223117397891151), ((11, 421), 0.00422421470284462), ((11, 502), 0.00422514933678839), ((11, 65), 0.004226531419489119), ((11, 249), 0.004227579053905275), ((12, 372), 0.004229290203915702), ((11, 222), 0.004229540212286843), ((13, 101), 0.004231492678324382), ((9, 466), 0.00423178697625796), ((13, 171), 0.004231847822666168), ((13, 195), 0.004232162402735816), ((12, 318), 0.004233150432507197), ((11, 358), 0.004234920773241255), ((13, 271), 0.0042360226313273115), ((7, 33), 0.004236546655495961), ((7, 72), 0.00423948797914717), ((12, 248), 0.004243554754389657), ((11, 469), 0.004243602355321248), ((6, 75), 0.004244804382324219), ((12, 15), 0.00424488302734163), ((12, 374), 0.004245176911354065), ((11, 472), 0.004246097885900074), ((10, 15), 0.004246154593096839), ((10, 38), 0.0042474062906371225), ((10, 46), 0.004248129824797313), ((5, 46), 0.004248280078172684), ((7, 150), 0.0042489998870425755), ((12, 152), 0.004252289732297261), ((12, 280), 0.004254848592811161), ((8, 55), 0.004255038996537526), ((13, 331), 0.004258547392156389), ((12, 320), 0.004259189797772301), ((13, 319), 0.004259895119402144), ((12, 73), 0.00425992285211881), ((12, 47), 0.00426002550456259), ((13, 22), 0.004261967622571521), ((13, 336), 0.004263624548912048), ((13, 481), 0.00426575168967247), ((13, 148), 0.004266132083204057), ((12, 61), 0.004267901182174683), ((11, 99), 0.004273238281408946), ((8, 37), 0.004273956848515404), ((12, 282), 0.004275466005007426), ((6, 97), 0.004278574138879776), ((9, 145), 0.004279062979751163), ((7, 184), 0.004279822938972049), ((13, 328), 0.004280906170606613), ((12, 346), 0.004281130101945665), ((9, 500), 0.004282260106669532), ((5, 124), 0.004284231199158562), ((13, 327), 0.004284482035371993), ((12, 12), 0.004285274280442132), ((12, 455), 0.004286095499992371), ((12, 316), 0.0042862676911883885), ((13, 339), 0.004286752806769477), ((11, 375), 0.0042868513200018145), ((11, 35), 0.004287129475010766), ((12, 231), 0.004287969734933641), ((11, 264), 0.004289627489116456), ((13, 509), 0.004292653252681096), ((13, 184), 0.004292709545956718), ((10, 477), 0.004294340809186299), ((7, 74), 0.004294564326604207), ((13, 119), 0.004294678568840027), ((7, 246), 0.00429511277212037), ((11, 119), 0.004295368989308675), ((12, 482), 0.004296086314651702), ((11, 298), 0.004296268853876326), ((5, 79), 0.00429753131336636), ((11, 160), 0.004301735096507602), ((12, 129), 0.0043021726111571), ((6, 216), 0.004304512921306822), ((9, 157), 0.004304576251241896), ((13, 346), 0.004306527475516002), ((13, 27), 0.00431075899137391), ((8, 120), 0.004311001549164454), ((9, 153), 0.00431108930044704), ((10, 81), 0.004311202300919427), ((9, 66), 0.004313129517767165), ((6, 31), 0.004313484662108951), ((13, 93), 0.00431409478187561), ((12, 71), 0.004314192467265659), ((11, 410), 0.004315369658999973), ((7, 8), 0.004315512461794747), ((12, 448), 0.004316040211253696), ((12, 343), 0.004316139552328322), ((8, 14), 0.004316349824269612), ((10, 85), 0.0043175241185559165), ((13, 305), 0.0043187542921966976), ((11, 247), 0.00432043108675215), ((13, 325), 0.0043208421104484135), ((8, 174), 0.0043232859008842045), ((10, 321), 0.00432358475195037), ((8, 148), 0.004323929962184694), ((13, 266), 0.004325174623065525), ((13, 217), 0.004325373305214776), ((12, 315), 0.004327746729056041), ((12, 159), 0.0043282947606510585), ((11, 6), 0.004328945444689857), ((12, 201), 0.004329231878121694), ((11, 140), 0.004329533212714725), ((13, 47), 0.004333341287242042), ((7, 142), 0.0043341463638676535), ((13, 244), 0.004337136116292741), ((11, 419), 0.004337907251384523), ((13, 15), 0.004338633682992723), ((13, 419), 0.004340664794047673), ((8, 96), 0.004342522472143173), ((13, 39), 0.004345554444524977), ((7, 23), 0.004346256868706809), ((6, 197), 0.00434627052810457), ((8, 87), 0.0043470097912682425), ((12, 479), 0.004348798344532649), ((10, 181), 0.004351229717334111), ((12, 115), 0.004352076186074151), ((12, 368), 0.00435283738705847), ((13, 134), 0.004353387488259209), ((11, 295), 0.004354288594590293), ((9, 59), 0.004355439709292518), ((8, 158), 0.004355500141779582), ((12, 509), 0.004357259306642745), ((8, 205), 0.004357956349849701), ((12, 185), 0.004359222120708889), ((5, 93), 0.004361085179779265), ((11, 289), 0.0043624138666523826), ((7, 219), 0.0043632810314496355), ((12, 97), 0.004369499782721202), ((10, 483), 0.0043698979748619925), ((10, 151), 0.0043701376352045275), ((5, 57), 0.004370540380477905), ((9, 279), 0.00437201311190923), ((12, 477), 0.004373279710610707), ((8, 184), 0.004373468458652496), ((11, 322), 0.004373903075853984), ((13, 253), 0.004374749958515167), ((8, 173), 0.004376318719651964), ((8, 255), 0.004376532302962409), ((13, 137), 0.0043782248265213436), ((12, 463), 0.004378239727682537), ((13, 90), 0.004379242244693968), ((8, 35), 0.004379422300391727), ((8, 170), 0.004380433509747188), ((8, 165), 0.004383191466331482), ((13, 312), 0.0043841708037588335), ((2, 50), 0.004385071496168773), ((8, 227), 0.004385601315233443), ((12, 293), 0.004385870777898365), ((12, 350), 0.00438625779416826), ((13, 79), 0.004386407633622487), ((11, 363), 0.004387225541803572), ((5, 43), 0.004391750113831626), ((4, 38), 0.004391779916154014), ((8, 64), 0.004391921891106499), ((9, 486), 0.004395882288614909), ((12, 399), 0.004396513104438782), ((5, 119), 0.004397136469682057), ((12, 457), 0.004400020672215356), ((11, 126), 0.0044017744561036425), ((12, 311), 0.004402678045961592), ((11, 176), 0.00440356218152576), ((13, 399), 0.004404309723112319), ((10, 105), 0.00440530851483345), ((11, 187), 0.004405909114413791), ((10, 161), 0.004408312754498588), ((9, 268), 0.00440833427839809), ((11, 423), 0.004408528821335899), ((8, 78), 0.00441173298491372), ((6, 46), 0.004413393636544545), ((4, 22), 0.004414374629656474), ((7, 58), 0.0044151461786694), ((13, 35), 0.004415171013938056), ((7, 53), 0.004416289014948739), ((8, 99), 0.004416509220997493), ((10, 226), 0.004417213300863902), ((13, 493), 0.004419448888964123), ((12, 484), 0.004420570615265105), ((6, 194), 0.004421113265885247), ((6, 27), 0.00442280371983846), ((6, 236), 0.004424820343653361), ((13, 213), 0.004429350296656291), ((6, 246), 0.004431721236970689), ((10, 22), 0.004431777944167455), ((7, 68), 0.0044324008954895865), ((6, 101), 0.004432431111733119), ((13, 450), 0.004432640141910977), ((5, 9), 0.004432763904333115), ((7, 26), 0.004433000667227639), ((13, 258), 0.004435920466979344), ((10, 97), 0.004437100556161668), ((13, 356), 0.004438023600313399), ((13, 378), 0.00443810804022683), ((12, 57), 0.004440115557776557), ((10, 272), 0.004440894143448936), ((11, 365), 0.004440938433011373), ((5, 106), 0.0044417646196153425), ((12, 106), 0.004441894590854645), ((6, 72), 0.004444058570596907), ((12, 39), 0.004444482839769787), ((6, 0), 0.004445477906200621), ((5, 120), 0.0044469452566570705), ((11, 291), 0.004447896447446611), ((11, 109), 0.004451322058836619), ((9, 113), 0.004451339443524678), ((11, 175), 0.00445183159576522), ((12, 430), 0.00445210768116845), ((12, 417), 0.004453136689133114), ((13, 68), 0.004453601936499278), ((10, 79), 0.004455334196488063), ((5, 15), 0.004455399596028858), ((11, 86), 0.00445597411857711), ((6, 211), 0.00445624440908432), ((12, 361), 0.00445634416408009), ((11, 169), 0.004457169936762916), ((11, 161), 0.004458583891391754), ((8, 82), 0.004458949383762147), ((9, 310), 0.004459181593524085), ((6, 94), 0.0044593314329783125), ((11, 460), 0.004462977250417073), ((6, 56), 0.004463738451401393), ((12, 155), 0.004464554289976756), ((9, 334), 0.0044661156005329555), ((12, 456), 0.004468169063329697), ((12, 333), 0.004469258917702569), ((13, 402), 0.004469773835606045), ((12, 415), 0.004473292993174659), ((9, 100), 0.00447591890891393), ((11, 166), 0.004476447072294023), ((13, 307), 0.004479116035832299), ((12, 309), 0.004480662859148449), ((11, 407), 0.004483995338280995), ((13, 423), 0.004487332370546129), ((11, 404), 0.004488692929347356), ((7, 45), 0.0044896366695563), ((11, 212), 0.004490182631545597), ((10, 296), 0.004490541501177682), ((11, 394), 0.00449088422788514), ((8, 151), 0.004496324807405472), ((13, 225), 0.004498218910561668), ((12, 149), 0.004498552117082808), ((5, 74), 0.004498692022429572), ((11, 362), 0.00449901239739524), ((9, 152), 0.004499414728747474), ((13, 460), 0.004501518276002672), ((8, 83), 0.004501991801791721), ((5, 89), 0.004503947165277269), ((8, 58), 0.004504000561104881), ((5, 22), 0.0045060333278444074), ((12, 327), 0.004506397578451369), ((11, 162), 0.00450650230050087), ((6, 26), 0.004506971273157332), ((5, 32), 0.0045079295006063246), ((11, 128), 0.004508776797188653), ((5, 111), 0.004509455627865261), ((11, 405), 0.00451209478908115), ((8, 199), 0.004513310061560737), ((13, 156), 0.004513685488038593), ((13, 64), 0.004513830774360233), ((9, 238), 0.004514096097813712), ((9, 401), 0.004519795378049214), ((12, 253), 0.004521483762396706), ((9, 412), 0.004523497488763597), ((7, 48), 0.004523923827542199), ((7, 10), 0.004523969358868069), ((11, 292), 0.004524374173747169), ((11, 221), 0.004525677611430486), ((8, 110), 0.004526638322406345), ((8, 169), 0.00452700008948644), ((12, 287), 0.004527643322944641), ((6, 187), 0.004527885880735185), ((10, 320), 0.004527905748950111), ((12, 6), 0.004531905468967225), ((2, 6), 0.004532900121476915), ((11, 89), 0.00453331031733089), ((7, 205), 0.004533403449588352), ((11, 149), 0.004535213112831116), ((7, 198), 0.004535648971796036), ((13, 503), 0.004536306692494286), ((8, 209), 0.00453731334871716), ((2, 52), 0.004538122150633071), ((7, 132), 0.004538439628150728), ((13, 160), 0.004540929363833534), ((12, 219), 0.00454154693418079), ((7, 169), 0.004542236526807149), ((12, 108), 0.004544915838374032), ((11, 474), 0.004545501536793179), ((12, 446), 0.004547467662228478), ((13, 187), 0.004548366698953841), ((11, 368), 0.0045490918887986075), ((11, 49), 0.0045492276549339294), ((13, 407), 0.004549764924579197), ((11, 240), 0.004550073709752824), ((7, 56), 0.004552231480677922), ((13, 326), 0.0045529864728450775), ((12, 178), 0.004553110235267215), ((13, 360), 0.004562666846646203), ((11, 335), 0.004563561744160122), ((11, 3), 0.004563593202167087), ((10, 314), 0.004564014159970813), ((12, 130), 0.004564746386475033), ((13, 139), 0.004564782811535729), ((11, 383), 0.004565332912736469), ((9, 75), 0.0045662617517842185), ((10, 259), 0.00456777670317226), ((12, 295), 0.0045679716600312125), ((12, 381), 0.004568020502726237), ((8, 77), 0.004572825713290108), ((12, 233), 0.004575060473548042), ((11, 483), 0.00457836604780621), ((9, 12), 0.004579451349046495), ((12, 332), 0.004581313166353438), ((8, 103), 0.004581715497705672), ((8, 112), 0.00458187030421363), ((6, 227), 0.004587145315276252), ((12, 277), 0.004591224922074212), ((13, 439), 0.004591998126771715), ((12, 103), 0.00459326555331548), ((13, 74), 0.0045955607460604776), ((8, 250), 0.004596882810195287), ((13, 246), 0.004597065349419911), ((8, 13), 0.004598303387562434), ((10, 500), 0.004600154028998481), ((12, 20), 0.004601985216140747), ((11, 29), 0.00460343642367257), ((5, 70), 0.004605261815918816), ((12, 301), 0.004605374402470059), ((8, 133), 0.004605397995975282), ((9, 133), 0.004605761832661099), ((12, 501), 0.0046113042367829215), ((10, 107), 0.004613695873154534), ((9, 72), 0.00461598320139779), ((9, 505), 0.004619133141305711), ((7, 156), 0.004620182017485301), ((12, 375), 0.004620340135362413), ((11, 145), 0.004620439476437039), ((9, 447), 0.004623129963874817), ((6, 70), 0.004625346097681258), ((11, 354), 0.004625894957118564), ((12, 357), 0.004626129236486223), ((8, 31), 0.004626616421673033), ((12, 377), 0.004626646637916565), ((13, 257), 0.004627221160464817), ((10, 183), 0.004629937724934684), ((10, 215), 0.004631535046630436), ((10, 28), 0.004633814096450806), ((12, 278), 0.004634117914570702), ((11, 376), 0.004635773599147797), ((6, 109), 0.004636067897081375), ((10, 446), 0.004637934681442048), ((11, 509), 0.004638094868924882), ((13, 194), 0.0046389297478728825), ((11, 1), 0.004640759693251716), ((12, 79), 0.00464179159866439), ((10, 471), 0.004643130633566115), ((11, 452), 0.004643195619185765), ((11, 270), 0.004643835127353668), ((12, 261), 0.004647028528981739), ((13, 120), 0.00464973971247673), ((10, 14), 0.0046500278015931444), ((12, 276), 0.00465023559000757), ((7, 36), 0.00465588519970576), ((10, 206), 0.004656987057791816), ((13, 476), 0.0046581120954619516), ((7, 175), 0.0046594709985786015), ((10, 422), 0.0046597739888562095), ((13, 55), 0.0046604300538698835), ((10, 90), 0.004660922206110424), ((13, 474), 0.004662415633598964), ((12, 454), 0.004662685924106174), ((11, 111), 0.0046638080643283), ((13, 44), 0.004667735762066311), ((13, 309), 0.004668461365832223), ((8, 200), 0.00466860251294242), ((6, 203), 0.004669654700491164), ((2, 44), 0.004670798364612792), ((8, 179), 0.004675084518061744), ((13, 251), 0.004677607367436091), ((12, 314), 0.004680139323075612), ((12, 182), 0.0046856846246454455), ((12, 17), 0.004690408292743895), ((12, 292), 0.004690568066305584), ((12, 408), 0.00469129698144065), ((11, 284), 0.004692398839526706), ((12, 210), 0.004693235374159283), ((6, 129), 0.004693426191806793), ((10, 355), 0.00469731373919381), ((6, 55), 0.004702678985065884), ((7, 34), 0.004702986942397224), ((11, 34), 0.004703872319724824), ((13, 277), 0.004703914953602685), ((9, 258), 0.004705095870627297), ((6, 224), 0.0047071754104561275), ((12, 365), 0.004710197448730469), ((10, 190), 0.004711762484576967), ((8, 121), 0.004711905287371742), ((7, 222), 0.00471210562520557), ((11, 118), 0.004721049633291032), ((8, 226), 0.00472224172618654), ((11, 420), 0.004723025692833794), ((5, 4), 0.004724647435877059), ((11, 123), 0.004724899099932777), ((7, 182), 0.004725152005751927), ((9, 107), 0.004732863770590888), ((12, 243), 0.004736218601465225), ((12, 118), 0.00473928948243459), ((13, 440), 0.004739452567365434), ((10, 186), 0.0047408656941519845), ((8, 51), 0.004746139463451173), ((7, 139), 0.004746855133109623), ((13, 329), 0.004746990071402656), ((11, 53), 0.004749630060460832), ((13, 412), 0.004749647031227748), ((12, 163), 0.004751177297698127), ((8, 185), 0.0047588033808602225), ((13, 288), 0.004759734289513694), ((12, 281), 0.004762142068809933), ((9, 308), 0.004763265864716636), ((3, 23), 0.004763361480500963), ((13, 198), 0.004767492827441957), ((12, 437), 0.004769930409060584), ((9, 393), 0.004770556257830726), ((10, 54), 0.00477104095949067), ((10, 51), 0.004772935062646866), ((11, 17), 0.004773873421880934), ((12, 180), 0.00477440282702446), ((6, 103), 0.0047747902572155), ((13, 438), 0.004776064720418718), ((11, 79), 0.00477642234828737), ((11, 272), 0.004776480297247569), ((6, 80), 0.004782325277725856), ((13, 428), 0.004783567869000965), ((7, 113), 0.00478403518597285), ((8, 244), 0.004784434205955929), ((6, 87), 0.004785880446434021), ((13, 33), 0.004787349038653904), ((12, 50), 0.004788827978902393), ((10, 263), 0.004791713423199124), ((9, 251), 0.004794526431295607), ((8, 144), 0.004795326126946343), ((8, 156), 0.004798141204648548), ((9, 79), 0.004800272484620412), ((8, 241), 0.004801313910219405), ((11, 196), 0.004805569847424825), ((9, 394), 0.0048085591859287685), ((11, 498), 0.004811298929982715), ((11, 184), 0.004814074271255069), ((10, 35), 0.004814171128802829), ((11, 195), 0.004816734128528171), ((4, 98), 0.004818047914240096), ((11, 9), 0.0048208894828955335), ((10, 120), 0.004821533130274879), ((5, 28), 0.004822793106238048), ((10, 287), 0.004823135419024361), ((12, 13), 0.00482397692071067), ((11, 108), 0.004825147075785531), ((12, 491), 0.004826400842931535), ((13, 149), 0.0048279377321402235), ((10, 16), 0.004828099575307634), ((12, 236), 0.004829770988888211), ((6, 138), 0.004832205673058827), ((12, 41), 0.004836480650636885), ((9, 11), 0.004848969479401906), ((6, 79), 0.004850110246075524), ((12, 154), 0.0048509397440486485), ((6, 59), 0.004851034118069543), ((8, 176), 0.00485405284497473), ((11, 277), 0.004854220896959305), ((10, 404), 0.0048551228311326765), ((6, 77), 0.00485523458984163), ((6, 99), 0.004856524368127187), ((12, 272), 0.004857692867517471), ((6, 172), 0.004857970194684135), ((13, 16), 0.004858276496330897), ((13, 508), 0.004861415260367923), ((9, 232), 0.004864227440622117), ((11, 156), 0.004866417911317613), ((13, 218), 0.004866453508536021), ((6, 231), 0.004868578165769577), ((7, 75), 0.0048714859618080985), ((8, 67), 0.00487337095869912), ((12, 443), 0.004875714166296853), ((12, 156), 0.004877170754803551), ((6, 60), 0.0048787399298614925), ((8, 134), 0.004881518168581856), ((10, 406), 0.004884350630972121), ((10, 434), 0.004887073404259152), ((13, 365), 0.00488777831196785), ((12, 462), 0.004888121038675308), ((10, 332), 0.004888866096735001), ((5, 62), 0.004890090061558617), ((10, 476), 0.0048939792646302115), ((7, 60), 0.0048950980934831835), ((10, 221), 0.004896344410048591), ((12, 168), 0.0048985179099771715), ((13, 126), 0.0049018243120776284), ((13, 178), 0.004904843038982815), ((13, 172), 0.004909256680144204), ((8, 201), 0.004910060101085239), ((11, 215), 0.004911589953634474), ((12, 289), 0.004913341253995895), ((13, 461), 0.004916595915953319), ((6, 45), 0.004917514406972461), ((12, 483), 0.004920695390966203), ((8, 102), 0.004920711119969686), ((8, 109), 0.004921812978055742), ((7, 165), 0.0049225592778788674), ((13, 107), 0.0049258458117643995), ((12, 326), 0.004926760577493244), ((2, 13), 0.004926790793736775), ((12, 475), 0.004927533782190747), ((12, 331), 0.004936380104886161), ((6, 40), 0.004940481235583623), ((12, 38), 0.00494404426879353), ((10, 506), 0.004944519036346012), ((12, 34), 0.0049466755655076765), ((5, 94), 0.004952731231848399), ((9, 63), 0.004955701529979706), ((11, 197), 0.004957160188092126), ((11, 258), 0.004957844813664754), ((13, 275), 0.004958008312516742), ((11, 432), 0.004960787793000539), ((8, 119), 0.004964152144061195), ((10, 118), 0.004967247446378072), ((9, 461), 0.004967309948470857), ((4, 11), 0.004967331058449215), ((11, 351), 0.00497231673863199), ((12, 334), 0.004972950451903873), ((13, 10), 0.0049732766217655605), ((13, 487), 0.004974279966619279), ((11, 388), 0.004975431495242649), ((11, 24), 0.004983653210931354), ((12, 317), 0.004984674768315421), ((10, 59), 0.004987367739280065), ((11, 441), 0.004987724953227573), ((8, 105), 0.004988000624709659), ((9, 147), 0.004990128179391225), ((4, 81), 0.004992264840337966), ((13, 459), 0.004993422577778499), ((12, 373), 0.00499870917863316), ((11, 445), 0.005001131445169449), ((4, 93), 0.005001530879073673), ((11, 384), 0.0050059350000487435), ((8, 1), 0.00500745822985967), ((8, 29), 0.005008331603474087), ((13, 301), 0.005009575850433773), ((9, 18), 0.005009593235121833), ((9, 90), 0.005010474887159135), ((13, 168), 0.005012287033928765), ((8, 246), 0.005013309005233977), ((8, 194), 0.005014981660577986), ((11, 78), 0.0050151464011934065), ((11, 192), 0.005016887353526222), ((12, 414), 0.005018077790737152), ((3, 8), 0.005021059678660499), ((12, 472), 0.0050221797492769026), ((9, 443), 0.005026102893882328), ((12, 493), 0.005027691937155194), ((12, 64), 0.005027899311648475), ((11, 296), 0.005033504631784227), ((12, 299), 0.005036413669586182), ((13, 219), 0.0050370461410946315), ((5, 37), 0.005037219574054082), ((9, 277), 0.005037782920731438), ((7, 233), 0.005039192736148834), ((12, 390), 0.005040814479192098), ((7, 105), 0.005041379481554031), ((8, 212), 0.00504517803589503), ((8, 230), 0.005047745174831814), ((7, 47), 0.005048672358194987), ((11, 143), 0.0050500598218705915), ((12, 54), 0.005050526311000188), ((3, 48), 0.005050931953721576), ((6, 206), 0.005052161299520069), ((9, 56), 0.005052507751517826), ((12, 342), 0.005053079790539212), ((2, 9), 0.0050536783205138314), ((9, 105), 0.005055644445949131), ((12, 183), 0.0050575948423809474), ((12, 434), 0.005058211584885915), ((7, 155), 0.005058799766831928), ((10, 147), 0.005058891657325957), ((13, 53), 0.005060501396656036), ((12, 366), 0.005061914109521442), ((6, 116), 0.0050635747611522675), ((12, 322), 0.005063796622885598), ((12, 470), 0.005064291258653005), ((12, 175), 0.005064358727799522), ((6, 34), 0.005066595143742031), ((8, 117), 0.005067424641715156), ((8, 108), 0.005068025241295497), ((8, 253), 0.005068884127669864), ((8, 191), 0.00507005179921786), ((13, 175), 0.00507775280210707), ((6, 189), 0.005078501171535916), ((6, 107), 0.00507913985186153), ((12, 471), 0.00508731934759352), ((5, 84), 0.005095194611284468), ((11, 500), 0.005096654925081465), ((12, 122), 0.005099607838524712), ((12, 268), 0.005099790791670482), ((7, 35), 0.005100092126263512), ((8, 113), 0.0051021286182933384), ((12, 267), 0.0051109496917989515), ((8, 211), 0.005111217498779297), ((9, 114), 0.005111842933628295), ((11, 41), 0.005116734239790175), ((13, 361), 0.005117626653777229), ((13, 268), 0.005119493438137902), ((8, 90), 0.00512081053521898), ((12, 30), 0.0051210688220130075), ((12, 450), 0.005127073162131839), ((10, 371), 0.005128108378913667), ((12, 401), 0.00513119250535965), ((13, 477), 0.005133146213160621), ((8, 167), 0.005135801103379991), ((12, 161), 0.005136352446344163), ((11, 8), 0.005140802098645104), ((13, 199), 0.00514711191256841), ((10, 253), 0.005149014708068635), ((7, 149), 0.005150376094712151), ((9, 83), 0.005150584297047721), ((11, 93), 0.005153396477301915), ((5, 80), 0.005153469741344452), ((10, 331), 0.005154963168832991), ((6, 119), 0.005155845648712582), ((11, 481), 0.005158858994642894), ((12, 291), 0.005162429064512253), ((11, 233), 0.005165279739432865), ((8, 149), 0.005165395637353261), ((8, 72), 0.005165420886543062), ((11, 91), 0.005166076123714447), ((12, 48), 0.005170647468831804), ((8, 251), 0.005173464202218586), ((10, 360), 0.005175396800041199), ((9, 381), 0.0051766580177678), ((10, 137), 0.005179169277350108), ((6, 160), 0.005180091079738405), ((12, 418), 0.005181391206052568), ((8, 97), 0.005190042985810174), ((6, 183), 0.005195582078562843), ((8, 6), 0.005200963881280687), ((5, 29), 0.00520399378405677), ((10, 318), 0.005204949114057753), ((12, 266), 0.005208826313416163), ((11, 507), 0.005212797886795468), ((11, 199), 0.005219000081221263), ((8, 2), 0.0052210431959893965), ((11, 236), 0.005227901041507721), ((12, 286), 0.005230279432402717), ((7, 85), 0.005238003200954861), ((9, 237), 0.0052387093504269915), ((8, 50), 0.005244409872425927), ((6, 239), 0.005248800747924381), ((12, 424), 0.005249564018514421), ((6, 214), 0.005250411315096749), ((9, 169), 0.005254554251829783), ((13, 341), 0.005256029880709118), ((5, 69), 0.005258566803402371), ((12, 242), 0.005260868204964532), ((2, 11), 0.005262661311361525), ((12, 45), 0.0052685605155097116), ((13, 262), 0.005268673929903243), ((11, 443), 0.005268829150332345), ((5, 27), 0.005272045731544495), ((12, 378), 0.005272469586796231), ((9, 87), 0.005274071461624569), ((9, 203), 0.005274126927057902), ((12, 297), 0.005277300046549903), ((11, 377), 0.005284688125054042), ((6, 91), 0.0052879320250617135), ((2, 56), 0.005291312105125851), ((2, 36), 0.005295662416352166), ((8, 32), 0.005297729952467812), ((8, 16), 0.005302106754647361), ((8, 34), 0.005302686658170488), ((12, 31), 0.005307348238097297), ((7, 243), 0.00530977381600274), ((8, 27), 0.005310735768742031), ((8, 240), 0.005316122538513607), ((12, 232), 0.0053166358007325065), ((12, 481), 0.005317217773861355), ((10, 373), 0.005329854786396027), ((12, 323), 0.005336126105652915), ((8, 15), 0.005337936182816823), ((11, 280), 0.005344260897901323), ((12, 171), 0.0053459422455893624), ((6, 153), 0.005346356166733636), ((11, 66), 0.0053474936220381), ((5, 12), 0.005348155068026649), ((11, 20), 0.005349304113123152), ((11, 413), 0.005350216395325131), ((8, 41), 0.005356850723425548), ((7, 101), 0.005359354118506114), ((13, 233), 0.005361689461602105), ((8, 215), 0.005366177194648319), ((7, 186), 0.005368482735421922), ((3, 39), 0.005370148354106479), ((9, 337), 0.005373280909326341), ((8, 91), 0.005374826076957915), ((12, 380), 0.005375782648722331), ((11, 177), 0.005377386179235246), ((7, 28), 0.005378120475345188), ((12, 348), 0.00538164046075609), ((11, 82), 0.0053820353415277265), ((7, 127), 0.005382237748967277), ((12, 506), 0.005386529697312249), ((6, 132), 0.005386914230055279), ((6, 88), 0.005397597948710124), ((12, 28), 0.005398380673593945), ((13, 448), 0.0054038166999816895), ((12, 296), 0.005407537851068709), ((11, 336), 0.005408090021875169), ((7, 21), 0.005410133136643304), ((8, 183), 0.005416816307438744), ((12, 244), 0.0054191528922981685), ((8, 130), 0.005425685809718238), ((11, 124), 0.005429033603933122), ((5, 47), 0.005436537166436513), ((5, 114), 0.005446561922629674), ((7, 5), 0.005450502451923158), ((7, 232), 0.005452391588025623), ((8, 204), 0.0054542215334044564), ((6, 200), 0.00546057853433821), ((7, 242), 0.005461230046219296), ((7, 65), 0.00546244697438346), ((13, 43), 0.005465499228901333), ((6, 155), 0.005468141701486375), ((5, 41), 0.005472573969099257), ((6, 244), 0.005481630149814818), ((5, 20), 0.005482681923442417), ((12, 186), 0.005486106706990136), ((8, 168), 0.005488277309470707), ((11, 242), 0.005492268337143792), ((8, 207), 0.005495025879806942), ((10, 63), 0.005495650900734795), ((9, 28), 0.005502066678471035), ((7, 111), 0.005503403643767039), ((11, 418), 0.005506130556265513), ((8, 164), 0.005506484872765011), ((13, 431), 0.005517454197009404), ((7, 64), 0.005519138028224309), ((6, 41), 0.005527606854836146), ((9, 82), 0.005544716699255837), ((5, 53), 0.005548548367288377), ((8, 175), 0.0055537935760286115), ((11, 80), 0.005556405418448978), ((7, 154), 0.005559109151363373), ((10, 3), 0.005559336807992723), ((11, 227), 0.0055598968433009256), ((13, 169), 0.005568228662014008), ((4, 34), 0.005574347658289803), ((7, 185), 0.005574362973372142), ((11, 244), 0.005574707355764177), ((8, 116), 0.005576604770289527), ((4, 126), 0.005577056772179074), ((13, 488), 0.0055819472504986655), ((9, 61), 0.0055860694911744856), ((9, 389), 0.0055870624879995985), ((8, 221), 0.0055893270505799186), ((10, 62), 0.005589865148067474), ((8, 101), 0.00559401594930225), ((11, 313), 0.005599555042054918), ((6, 115), 0.005610644817352295), ((5, 118), 0.005615047282642788), ((11, 275), 0.005618754360410903), ((11, 104), 0.005621262308624055), ((11, 167), 0.005627146197689904), ((8, 30), 0.005629223253991868), ((5, 44), 0.00563104616271125), ((11, 349), 0.005634249912367927), ((12, 335), 0.005642822219265832), ((5, 90), 0.0056493692100048065), ((12, 227), 0.0056517790589067675), ((7, 206), 0.005652155313226912), ((4, 101), 0.005652652432521184), ((8, 157), 0.005652866429752774), ((5, 88), 0.0056547121041350895), ((8, 180), 0.005658996187978321), ((11, 42), 0.005659845140245225), ((3, 43), 0.005662387443913354), ((8, 181), 0.005667513029442893), ((9, 124), 0.005668082584937413), ((5, 122), 0.0056709494027826525), ((11, 467), 0.005674388259649277), ((7, 83), 0.005676876339647505), ((8, 234), 0.005685968945423762), ((12, 500), 0.005691550672054291), ((13, 192), 0.005693622761302524), ((10, 43), 0.005695446497864193), ((12, 237), 0.005698957377009922), ((13, 259), 0.005700683842102687), ((12, 102), 0.00570570429166158), ((8, 80), 0.005705706775188446), ((12, 216), 0.005707699391576979), ((12, 495), 0.0057101208302709795), ((8, 163), 0.005710418025652568), ((13, 316), 0.005711618810892105), ((4, 113), 0.005714198781384362), ((12, 218), 0.00571587226457066), ((12, 445), 0.0057223935921986895), ((8, 44), 0.00572379802664121), ((8, 23), 0.0057243841389815016), ((6, 245), 0.00572800553507275), ((8, 146), 0.005729398793644375), ((9, 285), 0.00573268946674135), ((8, 147), 0.005733725511365467), ((5, 26), 0.005735753724972407), ((2, 1), 0.005736995488405228), ((11, 241), 0.005738248427708943), ((12, 345), 0.005739048537280824), ((5, 110), 0.005739205827315648), ((11, 424), 0.0057469399438964), ((11, 442), 0.00574968589676751), ((12, 55), 0.005753825108210246), ((7, 70), 0.005763904501994451), ((9, 413), 0.005766746484571033), ((9, 130), 0.005775316721863217), ((8, 100), 0.00578141709168752), ((8, 75), 0.005795131127039592), ((8, 124), 0.0057982707189189065), ((13, 490), 0.005798441668351491), ((13, 290), 0.0058000874188211225), ((10, 442), 0.0058101146585411495), ((8, 74), 0.005820670475562413), ((7, 161), 0.005821052110857434), ((8, 161), 0.005825757152504391), ((12, 169), 0.005826196322838466), ((4, 6), 0.005832726342810525), ((10, 42), 0.005834713992145326), ((11, 371), 0.005843585977951686), ((6, 219), 0.00584384302298228), ((2, 22), 0.005856642292605506), ((11, 510), 0.005856869535313712), ((8, 186), 0.005863869355784522), ((8, 189), 0.005867790016863082), ((8, 7), 0.0058718712793456185), ((11, 438), 0.005872874624199337), ((6, 11), 0.005873601883649826), ((12, 70), 0.005875448385874431), ((8, 122), 0.005878000623650021), ((5, 121), 0.005886887510617574), ((7, 133), 0.005887248863776525), ((6, 86), 0.00588835734460089), ((12, 264), 0.005895338952541351), ((10, 349), 0.005896990083985859), ((12, 111), 0.005901653319597244), ((6, 32), 0.005905667940775554), ((13, 29), 0.005918218029869927), ((8, 123), 0.005922539366616143), ((13, 109), 0.005925844113032023), ((12, 88), 0.0059264227747917175), ((11, 489), 0.005928396350807614), ((8, 128), 0.005932917197545369), ((6, 145), 0.005950109826193916), ((10, 356), 0.00595134910609987), ((12, 26), 0.005960322088665432), ((8, 166), 0.005962201290660434), ((12, 105), 0.005977775487634871), ((11, 256), 0.0059891318281491595), ((5, 83), 0.005989522569709354), ((5, 97), 0.005997213224569957), ((12, 238), 0.006001063105132844), ((11, 346), 0.00600310539205869), ((5, 91), 0.006005088488260905), ((12, 52), 0.006007842305633757), ((12, 137), 0.006008329076899422), ((11, 439), 0.006010774109098647), ((13, 17), 0.0060113101369804805), ((8, 197), 0.006013806495401595), ((2, 30), 0.006014215035570992), ((12, 112), 0.0060211171706517535), ((8, 25), 0.006021236379941304), ((8, 139), 0.006042912602424622), ((11, 76), 0.006048080821832021), ((5, 40), 0.006052039149734709), ((4, 19), 0.006058190431859758), ((12, 56), 0.00606098688311047), ((11, 344), 0.006062485691573884), ((11, 125), 0.006063246064715915), ((5, 58), 0.006067380309104919), ((12, 465), 0.006069832377963596), ((10, 158), 0.006077812363704045), ((2, 27), 0.0060821543965074755), ((5, 35), 0.006085754682620366), ((11, 466), 0.0060886310206519235), ((6, 130), 0.006091349654727512), ((5, 0), 0.006096219023068746), ((4, 85), 0.006101581785413954), ((4, 9), 0.006105199456214905), ((7, 174), 0.006110505097442203), ((4, 79), 0.006112703846560584), ((8, 239), 0.006120146976576911), ((4, 117), 0.0061256082521544564), ((8, 140), 0.006128130273686515), ((13, 381), 0.006144139915704727), ((2, 39), 0.00614686475859748), ((2, 7), 0.006147119320101208), ((12, 43), 0.006148057679335277), ((8, 9), 0.006163286666075389), ((13, 433), 0.006164822313520644), ((9, 257), 0.00617816299200058), ((11, 157), 0.006181835714313719), ((4, 58), 0.006182389126883613), ((10, 218), 0.006190342207749684), ((7, 147), 0.006197585827774472), ((12, 351), 0.006200237406624688), ((12, 189), 0.0062104761600494385), ((12, 461), 0.006212009737888972), ((7, 108), 0.006214359982146157), ((10, 292), 0.006217173818084929), ((12, 16), 0.0062225328551398385), ((3, 11), 0.006224813560644786), ((13, 427), 0.006232635014586979), ((6, 143), 0.006241575711303287), ((4, 75), 0.0062491268747382695), ((6, 14), 0.006252702739503648), ((8, 231), 0.006258843673600091), ((5, 1), 0.006260597871409522), ((8, 125), 0.006264536745018429), ((11, 250), 0.006274198078446918), ((8, 5), 0.006281693776448567), ((10, 47), 0.006302913857830895), ((4, 29), 0.006304972701602512), ((11, 370), 0.006306969457202488), ((12, 37), 0.006311313973532783), ((7, 57), 0.006313944028483497), ((10, 280), 0.006314338909255134), ((4, 127), 0.0063180699944496155), ((10, 364), 0.0063397255208757185), ((7, 173), 0.006341828654209773), ((9, 22), 0.006342327843109767), ((11, 194), 0.006345162375105752), ((11, 88), 0.00635551040371259), ((8, 46), 0.006355644100242191), ((10, 132), 0.006357916113403108), ((9, 52), 0.006364409294393327), ((3, 54), 0.006369056387080086), ((6, 17), 0.006373209257920583), ((12, 135), 0.006373551984628041), ((8, 162), 0.006374206807878282), ((7, 250), 0.006381362676620483), ((11, 11), 0.0063896386159790885), ((12, 211), 0.006396112342675527), ((9, 425), 0.006403500007258521), ((7, 86), 0.006417172650496165), ((6, 193), 0.006417872591151131), ((6, 252), 0.006419123874770271), ((12, 425), 0.006430796864959929), ((11, 16), 0.0064334919055302935), ((3, 42), 0.006433750192324321), ((5, 109), 0.0064357250101036495), ((5, 123), 0.0064438217216067845), ((5, 113), 0.006443955418136384), ((8, 26), 0.0064512934121820666), ((2, 42), 0.006453887455993229), ((7, 46), 0.0064600913061036), ((12, 321), 0.006464956121312248), ((7, 201), 0.00647173242436515), ((11, 389), 0.006487725509537591), ((6, 184), 0.006490592327382829), ((3, 12), 0.006498762302928501), ((12, 397), 0.0065070220993624795), ((9, 386), 0.006508462544944551), ((5, 16), 0.006517479403151406), ((8, 18), 0.006543195909923977), ((8, 61), 0.006555274542835023), ((5, 59), 0.006558573080433739), ((5, 92), 0.006561637338664796), ((12, 376), 0.006563490049706565), ((9, 241), 0.006596078061395221), ((4, 99), 0.00661030908425649), ((11, 59), 0.006621394720342424), ((7, 117), 0.00663640515671836), ((6, 50), 0.006647075215975444), ((11, 209), 0.00665180053975847), ((11, 334), 0.006659150123596191), ((5, 126), 0.0066645774576399065), ((12, 497), 0.006683833069271511), ((12, 392), 0.00670463095108668), ((13, 469), 0.006716662810908424), ((13, 86), 0.006727101074324714), ((2, 33), 0.006731046984593074), ((7, 199), 0.006734309097131093), ((4, 37), 0.006739937596850925), ((6, 191), 0.006748163865672218), ((5, 108), 0.006757910880777571), ((8, 98), 0.006761332352956136), ((8, 60), 0.006763194170263078), ((10, 339), 0.006765394161144893), ((5, 52), 0.0068075814180903966), ((10, 324), 0.006808701902627945), ((9, 445), 0.006816966666115655), ((7, 157), 0.006842894272671806), ((11, 488), 0.006847913894388411), ((8, 8), 0.006859545906384786), ((5, 24), 0.006865339974562327), ((12, 259), 0.0068668598930041), ((2, 46), 0.006868792904747857), ((9, 352), 0.006885100569989946), ((12, 409), 0.006890693886412514), ((8, 95), 0.00689115251104037), ((5, 11), 0.006896678772237565), ((5, 33), 0.006906283398469289), ((11, 4), 0.0069283681611220045), ((7, 100), 0.006941189782487022), ((12, 98), 0.006947315401501126), ((7, 78), 0.00695081717438168), ((4, 111), 0.006958699888653225), ((11, 40), 0.006967466738488939), ((8, 233), 0.006974221103721195), ((11, 332), 0.006977433959643046), ((12, 74), 0.006978581349054973), ((9, 89), 0.00700077580081092), ((5, 45), 0.007004180716143714), ((8, 89), 0.007013951738675435), ((11, 444), 0.007026231951183743), ((9, 117), 0.007028283344374763), ((5, 115), 0.007032722234725952), ((11, 203), 0.007039934396743774), ((4, 5), 0.007046818733215332), ((5, 77), 0.007051561441686418), ((4, 61), 0.007056141065226661), ((5, 3), 0.007063986526595222), ((6, 157), 0.007080809937583076), ((8, 143), 0.007082212302419875), ((2, 16), 0.007097007499800788), ((5, 117), 0.007117094265090095), ((4, 25), 0.007119218508402507), ((4, 8), 0.007120600177182091), ((8, 245), 0.00712457795937856), ((11, 205), 0.007147211167547438), ((13, 418), 0.007149082091119554), ((2, 19), 0.007155751188596089), ((8, 229), 0.0071559374531110125), ((5, 76), 0.007170317901505364), ((8, 85), 0.007173672318458557), ((8, 38), 0.007183167669508193), ((8, 11), 0.007188788718647427), ((13, 376), 0.007194465233219994), ((11, 396), 0.007229186594486237), ((7, 141), 0.007245229350195991), ((8, 141), 0.007258085740937127), ((5, 25), 0.007263953487078349), ((5, 56), 0.007266708546214634), ((12, 62), 0.007283197508917915), ((9, 511), 0.007286182708210415), ((5, 55), 0.007286327580610911), ((8, 171), 0.007308844890859392), ((6, 254), 0.007322504288620419), ((9, 433), 0.007322776648733351), ((6, 2), 0.007333353989654117), ((6, 133), 0.007384899589750502), ((5, 82), 0.007397403319676717), ((6, 15), 0.007399333847893609), ((3, 51), 0.0074185894595252145), ((2, 25), 0.007429348925749461), ((8, 203), 0.007453334000375535), ((9, 467), 0.007476804984940423), ((12, 410), 0.0074860867526796125), ((11, 308), 0.0074907806184556745), ((4, 36), 0.0074931300348705715), ((12, 191), 0.007496854497326745), ((5, 99), 0.007506704164875878), ((7, 14), 0.007517377535502116), ((12, 110), 0.007527284324169159), ((8, 220), 0.007538557880454593), ((12, 42), 0.007557170258627998), ((6, 162), 0.007575380305449168), ((12, 241), 0.007633252276314629), ((8, 187), 0.00763426058822208), ((5, 87), 0.007634274661540985), ((7, 236), 0.007638649808035957), ((4, 110), 0.007641038960880703), ((4, 47), 0.007663579450713264), ((12, 498), 0.00768918792406718), ((5, 38), 0.007690717776616414), ((11, 324), 0.007734961807727814), ((8, 216), 0.007738676336076524), ((8, 54), 0.007767444683445824), ((5, 10), 0.007769126858976152), ((8, 232), 0.007771303256352742), ((2, 15), 0.007786340183681912), ((8, 79), 0.007798574037022061), ((5, 85), 0.007806373967064751), ((6, 156), 0.00782819175057941), ((5, 23), 0.007833332651191287), ((4, 59), 0.007844979564348856), ((12, 478), 0.007871280113855997), ((3, 25), 0.007877735628022088), ((3, 6), 0.007902277840508355), ((12, 104), 0.007956417070494758), ((4, 45), 0.007972841461499533), ((5, 39), 0.007992547419336107), ((11, 70), 0.007993201414744059), ((5, 51), 0.008015890088346269), ((8, 63), 0.008022492130597433), ((12, 338), 0.008049502968788147), ((4, 23), 0.008077365656693777), ((5, 18), 0.008091524243354797), ((8, 84), 0.008109307123555077), ((5, 96), 0.008116898437341055), ((10, 41), 0.008125459982289208), ((7, 43), 0.008125528693199158), ((7, 107), 0.008128886421521505), ((12, 82), 0.0081470873620775), ((5, 67), 0.0081559419631958), ((3, 57), 0.008171361353662279), ((8, 213), 0.008171812527709536), ((5, 63), 0.008179011444250742), ((5, 8), 0.008208375838067796), ((5, 48), 0.008222118847899966), ((11, 208), 0.008228377335601382), ((12, 234), 0.008247032761573792), ((11, 359), 0.008272399504979452), ((8, 138), 0.008284472756915622), ((7, 230), 0.008315088020430671), ((4, 14), 0.008318407668007744), ((9, 127), 0.008324111501375834), ((11, 246), 0.00836365090476142), ((4, 48), 0.008366867899894714), ((7, 171), 0.008375813563664755), ((2, 20), 0.008381515741348267), ((5, 104), 0.008430075314309862), ((8, 22), 0.008458604415257772), ((5, 68), 0.008475882311662039), ((4, 64), 0.008500069379806519), ((4, 96), 0.00850254711177614), ((5, 61), 0.008535608649253845), ((5, 31), 0.008537081380685171), ((3, 44), 0.008545421891742282), ((3, 34), 0.00858636200428009), ((12, 92), 0.008590471413400438), ((2, 53), 0.008598913749059042), ((3, 16), 0.008620496425363753), ((3, 56), 0.00867002291811837), ((5, 66), 0.008752154807249704), ((7, 128), 0.008771488236056434), ((4, 18), 0.008787468075752258), ((3, 4), 0.008824509878953299), ((12, 226), 0.008827779855993059), ((5, 7), 0.008867451714144813), ((5, 6), 0.008869250615437826), ((5, 54), 0.008887178368038602), ((2, 4), 0.008905539082156287), ((11, 219), 0.008956650892893473), ((7, 190), 0.009029991096920438), ((5, 86), 0.009082076450188955), ((5, 5), 0.009096621639198728), ((4, 21), 0.009103828834162818), ((4, 44), 0.009112573332256742), ((4, 83), 0.00912979907459683), ((5, 102), 0.009135004546907213), ((11, 496), 0.009151349465052286), ((4, 7), 0.009163471559683481), ((7, 166), 0.0091809771127171), ((4, 55), 0.009238007167975107), ((4, 71), 0.009300971196757423), ((4, 4), 0.0093285557296541), ((10, 425), 0.009358467327223884), ((13, 108), 0.00936960263384713), ((9, 441), 0.009377303222815195), ((11, 248), 0.00939994388156467), ((2, 54), 0.009454314079549577), ((4, 15), 0.009601771831512451), ((8, 19), 0.009655912717183432), ((2, 48), 0.009695995185110304), ((2, 18), 0.009717544747723473), ((10, 243), 0.009726582301987542), ((8, 198), 0.009742570420106253), ((5, 103), 0.009757238957617018), ((6, 84), 0.009780056774616241), ((8, 154), 0.009794196320904626), ((5, 127), 0.00982966853512658), ((4, 86), 0.009832039475440979), ((4, 122), 0.00985495580567254), ((8, 66), 0.009907354911168417), ((4, 104), 0.009914813770188225), ((3, 59), 0.009999324050214555), ((4, 76), 0.010028812620374892), ((4, 88), 0.01006168954902225), ((4, 33), 0.01008696522977617), ((5, 19), 0.010092837942971123), ((3, 62), 0.010113029016388787), ((13, 99), 0.010120397640599145), ((12, 262), 0.010140635901027255), ((5, 81), 0.01024526274866528), ((8, 153), 0.010337709552711911), ((5, 13), 0.010341592133045197), ((4, 17), 0.010365646746423509), ((4, 80), 0.010369166731834412), ((11, 309), 0.010455300410588583), ((5, 101), 0.010495810045136346), ((7, 229), 0.010505398942364587), ((2, 59), 0.010541866223017374), ((4, 16), 0.010558126701249016), ((4, 30), 0.010645938416322073), ((5, 14), 0.010661270883348253), ((12, 344), 0.010671884649329715), ((8, 93), 0.010704379942682054), ((8, 136), 0.010745243065887027), ((4, 46), 0.010753335224257575), ((4, 66), 0.01081130239698622), ((11, 117), 0.010821301076147292), ((8, 152), 0.010825544595718384), ((3, 1), 0.010832134220335219), ((4, 42), 0.010853552983866798), ((3, 5), 0.010948200192716386), ((5, 42), 0.01107809692621231), ((11, 21), 0.011101920571592119), ((3, 28), 0.01119675487279892), ((3, 50), 0.011246654722425673), ((4, 72), 0.011268417040506998), ((4, 78), 0.011388894584443834), ((2, 61), 0.011421297987302145), ((2, 57), 0.01145376099480523), ((4, 41), 0.011510581605964236), ((12, 413), 0.011552997761302523), ((3, 46), 0.011636864807870653), ((2, 5), 0.011697758403089311), ((4, 107), 0.011745189627011618), ((5, 105), 0.011777992049853006), ((3, 32), 0.011848927372031741), ((3, 31), 0.011853420899973975), ((10, 350), 0.01186174319850074), ((2, 21), 0.01187549697028266), ((4, 103), 0.011905408567852445), ((4, 20), 0.01190595163239373), ((4, 65), 0.011977075702614255), ((2, 49), 0.012053107221921286), ((4, 116), 0.01205602122677697), ((5, 116), 0.01212380826473236), ((3, 30), 0.012207922008302476), ((2, 43), 0.01244408306148317), ((3, 7), 0.012457973427242704), ((4, 109), 0.01246559288766649), ((3, 58), 0.012476694252755906), ((8, 177), 0.01255907780594296), ((4, 82), 0.01285759276813931), ((3, 17), 0.012993009554015266), ((3, 53), 0.013046943479114108), ((3, 40), 0.013063858780595992), ((8, 236), 0.013148377339045206), ((4, 102), 0.013274316986401876), ((3, 0), 0.01336267093817393), ((4, 97), 0.01341126196914249), ((3, 26), 0.013502134217156304), ((2, 60), 0.01352522936132219), ((2, 23), 0.01352626747555203), ((3, 35), 0.01356470998790529), ((2, 8), 0.013715049458874596), ((3, 55), 0.013728110326661004), ((3, 47), 0.013833172619342804), ((5, 125), 0.01385388606124454), ((13, 98), 0.013856760329670377), ((2, 35), 0.013898094495137533), ((3, 61), 0.013944440417819552), ((3, 63), 0.013946364323298136), ((4, 54), 0.014021413193808662), ((3, 41), 0.014084421926074557), ((11, 251), 0.014336066113577949), ((3, 20), 0.014513581991195679), ((4, 24), 0.014680269691679213), ((4, 3), 0.014838218688964844), ((5, 100), 0.014953462613953484), ((4, 73), 0.015138962202601962), ((2, 41), 0.015151000685162015), ((11, 57), 0.015299845072958205), ((4, 26), 0.015568430225054422), ((4, 125), 0.01619404885503981), ((3, 15), 0.01625029080443912), ((3, 37), 0.01643733845816718), ((3, 3), 0.01657997237311469), ((4, 114), 0.016684903038872614), ((4, 32), 0.016904479927486844), ((3, 13), 0.017332737644513447), ((4, 56), 0.017411586311128404), ((2, 12), 0.0175114158127043), ((2, 63), 0.017569306823942397), ((4, 12), 0.017608559793896146), ((3, 29), 0.017704615990320843), ((4, 70), 0.01772716310289171), ((12, 23), 0.017802571256955464), ((2, 47), 0.018062303463617962), ((3, 33), 0.018206394380993314), ((2, 3), 0.01828311218155755), ((2, 14), 0.01836154858271281), ((2, 28), 0.01865945922003852), ((3, 10), 0.01870156659020318), ((2, 34), 0.01902946001953549), ((2, 58), 0.019334910644425288), ((2, 31), 0.019385006692674425), ((2, 26), 0.01996537380748325), ((3, 19), 0.02038125197092692), ((3, 24), 0.02040625446372562), ((2, 37), 0.020764384004804824), ((2, 0), 0.021099739604526095), ((2, 62), 0.022179240981737774), ((3, 49), 0.022829044196340773), ((2, 51), 0.02442577812406752), ((3, 2), 0.024491548538208008), ((2, 45), 0.02750461631351047), ((2, 10), 0.029434031910366483), ((3, 60), 0.030624621444278292), ((3, 27), 0.03253674507141113), ((3, 52), 0.03523754080136617), ((3, 45), 0.045508639680014715), ((3, 18), 0.048350632190704346), ((1, 0), 0.24198773172166613), ((1, 2), 0.30829652150472003), ((1, 1), 0.35901959737141925)]\n",
            "Length of weights_dic_sort_item is : 3715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMcDZ6QsOY_r",
        "outputId": "3bc686e0-d74d-4533-c493-e3f03d21fe73"
      },
      "source": [
        "num_channels_to_delete_overall=round(len(weights_dic_sort_item)*r)#getting how many channels has to be deleted\n",
        "num_channels_to_delete_overall"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "483"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdNxI9_hkkro"
      },
      "source": [
        "dic_layer={}#getting at which layer which channel need to be deleted\n",
        "for i in range(num_channels_to_delete_overall):\n",
        "  if weights_dic_sort_item[i][0][0] not in dic_layer:\n",
        "    dic_layer[weights_dic_sort_item[i][0][0]]=[]\n",
        "    dic_layer[weights_dic_sort_item[i][0][0]].append(weights_dic_sort_item[i][0][1])\n",
        "  else:\n",
        "    dic_layer[weights_dic_sort_item[i][0][0]].append(weights_dic_sort_item[i][0][1])\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KEOKt8Lreqk",
        "outputId": "67a8ac86-6016-4a25-daeb-680a18260a4d"
      },
      "source": [
        "dic_layer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{2: [24],\n",
              " 3: [14],\n",
              " 4: [43,\n",
              "  69,\n",
              "  123,\n",
              "  0,\n",
              "  49,\n",
              "  27,\n",
              "  89,\n",
              "  77,\n",
              "  1,\n",
              "  92,\n",
              "  121,\n",
              "  115,\n",
              "  124,\n",
              "  53,\n",
              "  100,\n",
              "  74,\n",
              "  39,\n",
              "  67,\n",
              "  118],\n",
              " 5: [95, 64],\n",
              " 6: [149,\n",
              "  255,\n",
              "  37,\n",
              "  44,\n",
              "  174,\n",
              "  171,\n",
              "  232,\n",
              "  54,\n",
              "  243,\n",
              "  233,\n",
              "  82,\n",
              "  123,\n",
              "  110,\n",
              "  181,\n",
              "  58,\n",
              "  64,\n",
              "  47,\n",
              "  202,\n",
              "  61,\n",
              "  186,\n",
              "  28,\n",
              "  102,\n",
              "  165,\n",
              "  131,\n",
              "  57,\n",
              "  68,\n",
              "  152,\n",
              "  48,\n",
              "  74,\n",
              "  121,\n",
              "  96,\n",
              "  67,\n",
              "  137,\n",
              "  8,\n",
              "  13,\n",
              "  235,\n",
              "  139,\n",
              "  158,\n",
              "  136,\n",
              "  128,\n",
              "  134,\n",
              "  180,\n",
              "  125,\n",
              "  135,\n",
              "  190,\n",
              "  52,\n",
              "  120,\n",
              "  49,\n",
              "  167,\n",
              "  122,\n",
              "  175,\n",
              "  92,\n",
              "  117,\n",
              "  108,\n",
              "  42,\n",
              "  188,\n",
              "  38,\n",
              "  71,\n",
              "  39,\n",
              "  147,\n",
              "  173,\n",
              "  185,\n",
              "  209,\n",
              "  237,\n",
              "  24,\n",
              "  16,\n",
              "  242,\n",
              "  100,\n",
              "  225,\n",
              "  9,\n",
              "  81,\n",
              "  150,\n",
              "  18],\n",
              " 7: [140,\n",
              "  228,\n",
              "  94,\n",
              "  204,\n",
              "  170,\n",
              "  239,\n",
              "  106,\n",
              "  82,\n",
              "  29,\n",
              "  177,\n",
              "  245,\n",
              "  146,\n",
              "  27,\n",
              "  104,\n",
              "  16,\n",
              "  217,\n",
              "  215,\n",
              "  39,\n",
              "  237,\n",
              "  248,\n",
              "  59,\n",
              "  20,\n",
              "  126,\n",
              "  32,\n",
              "  31,\n",
              "  9,\n",
              "  87,\n",
              "  191,\n",
              "  241,\n",
              "  223,\n",
              "  88,\n",
              "  187,\n",
              "  89,\n",
              "  176,\n",
              "  124,\n",
              "  49,\n",
              "  51,\n",
              "  189,\n",
              "  214,\n",
              "  110,\n",
              "  12,\n",
              "  19,\n",
              "  63,\n",
              "  231,\n",
              "  69,\n",
              "  109,\n",
              "  103,\n",
              "  50,\n",
              "  197,\n",
              "  76,\n",
              "  160,\n",
              "  212,\n",
              "  210,\n",
              "  254],\n",
              " 8: [129, 218],\n",
              " 9: [351,\n",
              "  362,\n",
              "  40,\n",
              "  333,\n",
              "  388,\n",
              "  364,\n",
              "  329,\n",
              "  54,\n",
              "  137,\n",
              "  358,\n",
              "  295,\n",
              "  471,\n",
              "  186,\n",
              "  50,\n",
              "  328,\n",
              "  38,\n",
              "  176,\n",
              "  131,\n",
              "  217,\n",
              "  481,\n",
              "  164,\n",
              "  76,\n",
              "  215,\n",
              "  286,\n",
              "  335,\n",
              "  422,\n",
              "  419,\n",
              "  8,\n",
              "  255,\n",
              "  207,\n",
              "  318,\n",
              "  26,\n",
              "  377,\n",
              "  261,\n",
              "  459,\n",
              "  21,\n",
              "  80,\n",
              "  253,\n",
              "  247,\n",
              "  284,\n",
              "  432,\n",
              "  274,\n",
              "  225,\n",
              "  154,\n",
              "  218,\n",
              "  98,\n",
              "  371,\n",
              "  396,\n",
              "  382,\n",
              "  159,\n",
              "  460,\n",
              "  455,\n",
              "  509,\n",
              "  360,\n",
              "  262,\n",
              "  15,\n",
              "  118,\n",
              "  273,\n",
              "  392,\n",
              "  339,\n",
              "  27,\n",
              "  420,\n",
              "  10,\n",
              "  506,\n",
              "  457,\n",
              "  488,\n",
              "  469,\n",
              "  415,\n",
              "  239,\n",
              "  504,\n",
              "  331,\n",
              "  370,\n",
              "  219,\n",
              "  324,\n",
              "  122,\n",
              "  168,\n",
              "  96,\n",
              "  110,\n",
              "  109,\n",
              "  363,\n",
              "  198,\n",
              "  4,\n",
              "  272,\n",
              "  202,\n",
              "  297,\n",
              "  46,\n",
              "  205,\n",
              "  181,\n",
              "  355,\n",
              "  151,\n",
              "  104,\n",
              "  9,\n",
              "  497,\n",
              "  16,\n",
              "  293,\n",
              "  304,\n",
              "  252,\n",
              "  495,\n",
              "  294,\n",
              "  246,\n",
              "  383,\n",
              "  271,\n",
              "  140,\n",
              "  498,\n",
              "  41,\n",
              "  309,\n",
              "  158,\n",
              "  290,\n",
              "  144,\n",
              "  156,\n",
              "  92,\n",
              "  353,\n",
              "  359,\n",
              "  108,\n",
              "  167,\n",
              "  307,\n",
              "  316,\n",
              "  171,\n",
              "  395,\n",
              "  99,\n",
              "  180,\n",
              "  356,\n",
              "  283,\n",
              "  33,\n",
              "  73,\n",
              "  340,\n",
              "  406,\n",
              "  275,\n",
              "  31,\n",
              "  242,\n",
              "  121,\n",
              "  462,\n",
              "  64,\n",
              "  263,\n",
              "  49,\n",
              "  150,\n",
              "  57,\n",
              "  494,\n",
              "  129,\n",
              "  231,\n",
              "  350,\n",
              "  323,\n",
              "  221,\n",
              "  510,\n",
              "  234,\n",
              "  312,\n",
              "  437,\n",
              "  160,\n",
              "  62,\n",
              "  94,\n",
              "  489,\n",
              "  182,\n",
              "  315,\n",
              "  464,\n",
              "  366,\n",
              "  440,\n",
              "  480,\n",
              "  128,\n",
              "  65,\n",
              "  439,\n",
              "  161,\n",
              "  116,\n",
              "  306,\n",
              "  265,\n",
              "  426,\n",
              "  314,\n",
              "  361,\n",
              "  183,\n",
              "  175,\n",
              "  397,\n",
              "  201,\n",
              "  418,\n",
              "  508,\n",
              "  429,\n",
              "  278,\n",
              "  236,\n",
              "  206,\n",
              "  134,\n",
              "  119,\n",
              "  53,\n",
              "  19,\n",
              "  243,\n",
              "  77,\n",
              "  458,\n",
              "  478,\n",
              "  254,\n",
              "  34,\n",
              "  482,\n",
              "  143,\n",
              "  17,\n",
              "  170,\n",
              "  69,\n",
              "  178,\n",
              "  405,\n",
              "  332,\n",
              "  14,\n",
              "  190,\n",
              "  387,\n",
              "  184,\n",
              "  391,\n",
              "  58,\n",
              "  136],\n",
              " 10: [195,\n",
              "  377,\n",
              "  396,\n",
              "  379,\n",
              "  13,\n",
              "  505,\n",
              "  459,\n",
              "  461,\n",
              "  380,\n",
              "  448,\n",
              "  71,\n",
              "  456,\n",
              "  168,\n",
              "  312,\n",
              "  469,\n",
              "  470,\n",
              "  138,\n",
              "  36,\n",
              "  361,\n",
              "  93,\n",
              "  231,\n",
              "  463,\n",
              "  75,\n",
              "  129,\n",
              "  286,\n",
              "  293,\n",
              "  142,\n",
              "  391,\n",
              "  424,\n",
              "  157,\n",
              "  185,\n",
              "  340,\n",
              "  31,\n",
              "  336,\n",
              "  381,\n",
              "  511,\n",
              "  334,\n",
              "  408,\n",
              "  465,\n",
              "  170,\n",
              "  19,\n",
              "  211,\n",
              "  480,\n",
              "  467,\n",
              "  152,\n",
              "  326,\n",
              "  311,\n",
              "  119,\n",
              "  236,\n",
              "  484,\n",
              "  400,\n",
              "  387,\n",
              "  246,\n",
              "  473,\n",
              "  328,\n",
              "  128,\n",
              "  172,\n",
              "  148,\n",
              "  70,\n",
              "  302,\n",
              "  283,\n",
              "  439,\n",
              "  274,\n",
              "  301,\n",
              "  342,\n",
              "  441,\n",
              "  240,\n",
              "  365,\n",
              "  275,\n",
              "  378,\n",
              "  401,\n",
              "  460,\n",
              "  18,\n",
              "  322,\n",
              "  299,\n",
              "  222,\n",
              "  291,\n",
              "  411,\n",
              "  223,\n",
              "  344,\n",
              "  496,\n",
              "  165,\n",
              "  162,\n",
              "  208,\n",
              "  341,\n",
              "  252,\n",
              "  217,\n",
              "  39,\n",
              "  213,\n",
              "  230,\n",
              "  370,\n",
              "  111,\n",
              "  95,\n",
              "  56,\n",
              "  479,\n",
              "  69,\n",
              "  474,\n",
              "  101,\n",
              "  281,\n",
              "  478,\n",
              "  426,\n",
              "  372,\n",
              "  393,\n",
              "  417,\n",
              "  433,\n",
              "  205],\n",
              " 11: [504, 58, 129, 0, 2, 202, 484, 386, 395, 503, 131, 84, 316, 173],\n",
              " 12: [196, 423, 157, 400, 474],\n",
              " 13: [207, 452, 37, 41]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGukkizMZOlO",
        "outputId": "383c83b6-4e34-4b6e-ca0d-c501c75ceafc"
      },
      "source": [
        "#loaing the model\n",
        "new_model_w=tf.keras.applications.vgg16.VGG16(weights='imagenet',include_top=True)\n",
        "new_model_w.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thKRsZ8_vuGj"
      },
      "source": [
        "dic_layer_sorted_l2={}#sorted channel indices at each layer so that it would be suitable for deletion\n",
        "for key,value in dic_layer.items():\n",
        "  dic_layer_sorted_l2[key]=sorted(value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwoRSHCxv855",
        "outputId": "c8af2f90-345a-4871-aa14-e0890c59afd2"
      },
      "source": [
        "dic_layer_sorted_l2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{2: [24],\n",
              " 3: [14],\n",
              " 4: [0,\n",
              "  1,\n",
              "  27,\n",
              "  39,\n",
              "  43,\n",
              "  49,\n",
              "  53,\n",
              "  67,\n",
              "  69,\n",
              "  74,\n",
              "  77,\n",
              "  89,\n",
              "  92,\n",
              "  100,\n",
              "  115,\n",
              "  118,\n",
              "  121,\n",
              "  123,\n",
              "  124],\n",
              " 5: [64, 95],\n",
              " 6: [8,\n",
              "  9,\n",
              "  13,\n",
              "  16,\n",
              "  18,\n",
              "  24,\n",
              "  28,\n",
              "  37,\n",
              "  38,\n",
              "  39,\n",
              "  42,\n",
              "  44,\n",
              "  47,\n",
              "  48,\n",
              "  49,\n",
              "  52,\n",
              "  54,\n",
              "  57,\n",
              "  58,\n",
              "  61,\n",
              "  64,\n",
              "  67,\n",
              "  68,\n",
              "  71,\n",
              "  74,\n",
              "  81,\n",
              "  82,\n",
              "  92,\n",
              "  96,\n",
              "  100,\n",
              "  102,\n",
              "  108,\n",
              "  110,\n",
              "  117,\n",
              "  120,\n",
              "  121,\n",
              "  122,\n",
              "  123,\n",
              "  125,\n",
              "  128,\n",
              "  131,\n",
              "  134,\n",
              "  135,\n",
              "  136,\n",
              "  137,\n",
              "  139,\n",
              "  147,\n",
              "  149,\n",
              "  150,\n",
              "  152,\n",
              "  158,\n",
              "  165,\n",
              "  167,\n",
              "  171,\n",
              "  173,\n",
              "  174,\n",
              "  175,\n",
              "  180,\n",
              "  181,\n",
              "  185,\n",
              "  186,\n",
              "  188,\n",
              "  190,\n",
              "  202,\n",
              "  209,\n",
              "  225,\n",
              "  232,\n",
              "  233,\n",
              "  235,\n",
              "  237,\n",
              "  242,\n",
              "  243,\n",
              "  255],\n",
              " 7: [9,\n",
              "  12,\n",
              "  16,\n",
              "  19,\n",
              "  20,\n",
              "  27,\n",
              "  29,\n",
              "  31,\n",
              "  32,\n",
              "  39,\n",
              "  49,\n",
              "  50,\n",
              "  51,\n",
              "  59,\n",
              "  63,\n",
              "  69,\n",
              "  76,\n",
              "  82,\n",
              "  87,\n",
              "  88,\n",
              "  89,\n",
              "  94,\n",
              "  103,\n",
              "  104,\n",
              "  106,\n",
              "  109,\n",
              "  110,\n",
              "  124,\n",
              "  126,\n",
              "  140,\n",
              "  146,\n",
              "  160,\n",
              "  170,\n",
              "  176,\n",
              "  177,\n",
              "  187,\n",
              "  189,\n",
              "  191,\n",
              "  197,\n",
              "  204,\n",
              "  210,\n",
              "  212,\n",
              "  214,\n",
              "  215,\n",
              "  217,\n",
              "  223,\n",
              "  228,\n",
              "  231,\n",
              "  237,\n",
              "  239,\n",
              "  241,\n",
              "  245,\n",
              "  248,\n",
              "  254],\n",
              " 8: [129, 218],\n",
              " 9: [4,\n",
              "  8,\n",
              "  9,\n",
              "  10,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  19,\n",
              "  21,\n",
              "  26,\n",
              "  27,\n",
              "  31,\n",
              "  33,\n",
              "  34,\n",
              "  38,\n",
              "  40,\n",
              "  41,\n",
              "  46,\n",
              "  49,\n",
              "  50,\n",
              "  53,\n",
              "  54,\n",
              "  57,\n",
              "  58,\n",
              "  62,\n",
              "  64,\n",
              "  65,\n",
              "  69,\n",
              "  73,\n",
              "  76,\n",
              "  77,\n",
              "  80,\n",
              "  92,\n",
              "  94,\n",
              "  96,\n",
              "  98,\n",
              "  99,\n",
              "  104,\n",
              "  108,\n",
              "  109,\n",
              "  110,\n",
              "  116,\n",
              "  118,\n",
              "  119,\n",
              "  121,\n",
              "  122,\n",
              "  128,\n",
              "  129,\n",
              "  131,\n",
              "  134,\n",
              "  136,\n",
              "  137,\n",
              "  140,\n",
              "  143,\n",
              "  144,\n",
              "  150,\n",
              "  151,\n",
              "  154,\n",
              "  156,\n",
              "  158,\n",
              "  159,\n",
              "  160,\n",
              "  161,\n",
              "  164,\n",
              "  167,\n",
              "  168,\n",
              "  170,\n",
              "  171,\n",
              "  175,\n",
              "  176,\n",
              "  178,\n",
              "  180,\n",
              "  181,\n",
              "  182,\n",
              "  183,\n",
              "  184,\n",
              "  186,\n",
              "  190,\n",
              "  198,\n",
              "  201,\n",
              "  202,\n",
              "  205,\n",
              "  206,\n",
              "  207,\n",
              "  215,\n",
              "  217,\n",
              "  218,\n",
              "  219,\n",
              "  221,\n",
              "  225,\n",
              "  231,\n",
              "  234,\n",
              "  236,\n",
              "  239,\n",
              "  242,\n",
              "  243,\n",
              "  246,\n",
              "  247,\n",
              "  252,\n",
              "  253,\n",
              "  254,\n",
              "  255,\n",
              "  261,\n",
              "  262,\n",
              "  263,\n",
              "  265,\n",
              "  271,\n",
              "  272,\n",
              "  273,\n",
              "  274,\n",
              "  275,\n",
              "  278,\n",
              "  283,\n",
              "  284,\n",
              "  286,\n",
              "  290,\n",
              "  293,\n",
              "  294,\n",
              "  295,\n",
              "  297,\n",
              "  304,\n",
              "  306,\n",
              "  307,\n",
              "  309,\n",
              "  312,\n",
              "  314,\n",
              "  315,\n",
              "  316,\n",
              "  318,\n",
              "  323,\n",
              "  324,\n",
              "  328,\n",
              "  329,\n",
              "  331,\n",
              "  332,\n",
              "  333,\n",
              "  335,\n",
              "  339,\n",
              "  340,\n",
              "  350,\n",
              "  351,\n",
              "  353,\n",
              "  355,\n",
              "  356,\n",
              "  358,\n",
              "  359,\n",
              "  360,\n",
              "  361,\n",
              "  362,\n",
              "  363,\n",
              "  364,\n",
              "  366,\n",
              "  370,\n",
              "  371,\n",
              "  377,\n",
              "  382,\n",
              "  383,\n",
              "  387,\n",
              "  388,\n",
              "  391,\n",
              "  392,\n",
              "  395,\n",
              "  396,\n",
              "  397,\n",
              "  405,\n",
              "  406,\n",
              "  415,\n",
              "  418,\n",
              "  419,\n",
              "  420,\n",
              "  422,\n",
              "  426,\n",
              "  429,\n",
              "  432,\n",
              "  437,\n",
              "  439,\n",
              "  440,\n",
              "  455,\n",
              "  457,\n",
              "  458,\n",
              "  459,\n",
              "  460,\n",
              "  462,\n",
              "  464,\n",
              "  469,\n",
              "  471,\n",
              "  478,\n",
              "  480,\n",
              "  481,\n",
              "  482,\n",
              "  488,\n",
              "  489,\n",
              "  494,\n",
              "  495,\n",
              "  497,\n",
              "  498,\n",
              "  504,\n",
              "  506,\n",
              "  508,\n",
              "  509,\n",
              "  510],\n",
              " 10: [13,\n",
              "  18,\n",
              "  19,\n",
              "  31,\n",
              "  36,\n",
              "  39,\n",
              "  56,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  75,\n",
              "  93,\n",
              "  95,\n",
              "  101,\n",
              "  111,\n",
              "  119,\n",
              "  128,\n",
              "  129,\n",
              "  138,\n",
              "  142,\n",
              "  148,\n",
              "  152,\n",
              "  157,\n",
              "  162,\n",
              "  165,\n",
              "  168,\n",
              "  170,\n",
              "  172,\n",
              "  185,\n",
              "  195,\n",
              "  205,\n",
              "  208,\n",
              "  211,\n",
              "  213,\n",
              "  217,\n",
              "  222,\n",
              "  223,\n",
              "  230,\n",
              "  231,\n",
              "  236,\n",
              "  240,\n",
              "  246,\n",
              "  252,\n",
              "  274,\n",
              "  275,\n",
              "  281,\n",
              "  283,\n",
              "  286,\n",
              "  291,\n",
              "  293,\n",
              "  299,\n",
              "  301,\n",
              "  302,\n",
              "  311,\n",
              "  312,\n",
              "  322,\n",
              "  326,\n",
              "  328,\n",
              "  334,\n",
              "  336,\n",
              "  340,\n",
              "  341,\n",
              "  342,\n",
              "  344,\n",
              "  361,\n",
              "  365,\n",
              "  370,\n",
              "  372,\n",
              "  377,\n",
              "  378,\n",
              "  379,\n",
              "  380,\n",
              "  381,\n",
              "  387,\n",
              "  391,\n",
              "  393,\n",
              "  396,\n",
              "  400,\n",
              "  401,\n",
              "  408,\n",
              "  411,\n",
              "  417,\n",
              "  424,\n",
              "  426,\n",
              "  433,\n",
              "  439,\n",
              "  441,\n",
              "  448,\n",
              "  456,\n",
              "  459,\n",
              "  460,\n",
              "  461,\n",
              "  463,\n",
              "  465,\n",
              "  467,\n",
              "  469,\n",
              "  470,\n",
              "  473,\n",
              "  474,\n",
              "  478,\n",
              "  479,\n",
              "  480,\n",
              "  484,\n",
              "  496,\n",
              "  505,\n",
              "  511],\n",
              " 11: [0, 2, 58, 84, 129, 131, 173, 202, 316, 386, 395, 484, 503, 504],\n",
              " 12: [157, 196, 400, 423, 474],\n",
              " 13: [37, 41, 207, 452]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsAv3cdEy6Xl",
        "outputId": "4e9d9c40-9bd5-4707-9482-dfe27879c3cf"
      },
      "source": [
        "type(dic_layer_sorted_l2[4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDRFHuPHO0B3",
        "outputId": "74e06e9e-6efe-4ba9-e3fb-d104c0ae3504"
      },
      "source": [
        "#do the deleteion\n",
        "for key,value in dic_layer_sorted_l2.items():\n",
        "  if key!=0:\n",
        "    surgeon = Surgeon(new_model_w)\n",
        "    surgeon.add_job('delete_channels', new_model_w.layers[layer[key-1]], channels=value)#deletion\n",
        "    new_model_w = surgeon.operate()#fine tuning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deleting 19/128 channels from layer: block2_conv2\n",
            "Deleting 66/256 channels from layer: block3_conv2\n",
            "Deleting 1/64 channels from layer: block1_conv2\n",
            "Deleting 7/512 channels from layer: block5_conv1\n",
            "Deleting 44/256 channels from layer: block3_conv3\n",
            "Deleting 159/512 channels from layer: block4_conv2\n",
            "Deleting 70/512 channels from layer: block4_conv3\n",
            "Deleting 1/128 channels from layer: block2_conv1\n",
            "Deleting 1/512 channels from layer: block5_conv3\n",
            "Deleting 2/256 channels from layer: block3_conv1\n",
            "Deleting 2/512 channels from layer: block5_conv2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxlQpla7YF7K",
        "outputId": "07a9265e-b024-43a4-9f92-edfee3e722e5"
      },
      "source": [
        "new_model_w.compile(loss = 'categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])#recompile the model\n",
        "new_model_w.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 63)      36351     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 127)     72136     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 109)     124696    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 254)       249428    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 190)       434530    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 212)       362732    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       977408    \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 353)       1626977   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 442)       1404676   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 505)       2009395   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 510)       2318460   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 511)       2346001   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102563840 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 135,406,734\n",
            "Trainable params: 135,406,734\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PSob4_bz3aV"
      },
      "source": [
        "evaluating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXwv11DeInJM"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJoxAlWL9mWf"
      },
      "source": [
        "total_time=0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbkrdt8Jz9aD",
        "outputId": "4addc7ad-1632-4dc0-f12f-3a51a3039025"
      },
      "source": [
        "pred_w = []\n",
        "\n",
        "for filename in os.listdir(path):\n",
        "    label = filename.split('_')[0]\n",
        "    file_path = path + \"/\" + filename\n",
        "    x=time.time()\n",
        "    image=tf.keras.preprocessing.image.load_img(file_path, target_size=(224, 224))  # reading image (Folder path and image name )\n",
        "      \n",
        "    image=np.array(image)\n",
        "    image=image.reshape((1,image.shape[0],image.shape[1],image.shape[2]))\n",
        "    image=preprocess_input(image)\n",
        "\n",
        "    op1=new_model_w.predict(image)\n",
        "    y=time.time()\n",
        "    total_time = total_time + (y-x)\n",
        "    label1=decode_predictions(op1,top=1)\n",
        "    pred_w.append([label, label1[0][0][0]])\n",
        "\n",
        "count = 0\n",
        "for i in range(len(pred_w)):\n",
        "  if pred_w[i][0] == pred_w[i][1] :\n",
        "    count = count + 1\n",
        "\n",
        "print(\"####### FOR RATE : \", r)\n",
        "print('Model Flops : ', modelFlops(new_model_w))\n",
        "print('Total : ', len(pred_w), ', Correct : ', count, ', Accuracy : ', (100*count/len(pred_w)))\n",
        "print('Time Taken for prediction : ', (total_time/len(pred_w)) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "####### FOR RATE :  0.1\n",
            "Model Flops :  24446304924\n",
            "Total :  84 , Correct :  41 , Accuracy :  48.80952380952381\n",
            "Time Taken for prediction :  0.022287079266139438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSMt3RYs-oKj"
      },
      "source": [
        "saving model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-qEBAJK-lfW"
      },
      "source": [
        "new_model_w.save(\"vgg_w_16\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lulVyRyW-bHD"
      },
      "source": [
        "Checking model size after pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lcWSAG_-kQ4",
        "outputId": "a596bb71-08d7-4554-ff69-1bad4d5171bf"
      },
      "source": [
        "import os\n",
        "import math\n",
        "# Get file size in bytes for a given model\n",
        "print(\"Model size after pruning=>\",(os.stat('/content/vgg_w_16').st_size)/math.pow(2,20),\" Mega Bytes\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model size after pruning=> 516.6165008544922  Mega Bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmUuvycQw3RI"
      },
      "source": [
        "rates_w=[0]\n",
        "params_w=[138357544]\n",
        "model_size_w=[527.8]\n",
        "accuracy_w=[98.8]\n",
        "flops_w=[20467662529]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfoYAp6a6Fdr",
        "outputId": "7bf90f76-5cd1-4070-e291-a648383e4b4d"
      },
      "source": [
        "print(rates_w)\n",
        "print(accuracy_w)\n",
        "print(params_w)\n",
        "print(model_size_w)\n",
        "print(flops_w)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n",
            "[98.8]\n",
            "[138357544]\n",
            "[527.8]\n",
            "[20467662529]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCPnpPogeQSd"
      },
      "source": [
        "Calculating all metrices for different rate values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5Brc-sASM5Q",
        "outputId": "8b3b549c-e37d-4ed6-e971-049407d4ec9d"
      },
      "source": [
        "rate=[0.01,0.02,0.03,0.04,0.05,0.06,0.07]#different values of rates\n",
        "i=0\n",
        "for r in rate:\n",
        "  print(\"###################################################################################################################################################################\")\n",
        "  print(\"FOR RATE : \", r)\n",
        "  rates_w.append(r)\n",
        "  num_channels_to_delete_overall=round(len(weights_dic_sort_item)*r)\n",
        "  print(\"Number of channels to delete\",num_channels_to_delete_overall)\n",
        "\n",
        "  dic_layer={}\n",
        "  for i in range(num_channels_to_delete_overall):\n",
        "    if weights_dic_sort_item[i][0][0] not in dic_layer:\n",
        "      dic_layer[weights_dic_sort_item[i][0][0]]=[]\n",
        "      dic_layer[weights_dic_sort_item[i][0][0]].append(weights_dic_sort_item[i][0][1])\n",
        "    else:\n",
        "      dic_layer[weights_dic_sort_item[i][0][0]].append(weights_dic_sort_item[i][0][1])\n",
        "\n",
        "  dic_layer_sorted_l2={}\n",
        "  for key,value in dic_layer.items():\n",
        "    dic_layer_sorted_l2[key]=sorted(value)\n",
        "\n",
        "  new_model_w=tf.keras.applications.vgg16.VGG16(weights='imagenet',include_top=True)\n",
        "  new_model_w.summary()\n",
        "  print(\"Number of parameter before pruning\",new_model_w.count_params())\n",
        "\n",
        "  for key,value in dic_layer_sorted_l2.items():\n",
        "    if key!=0:\n",
        "      surgeon = Surgeon(new_model_w)\n",
        "      surgeon.add_job('delete_channels', new_model_w.layers[layer[key-1]], channels=value)\n",
        "      new_model_w = surgeon.operate()\n",
        "  \n",
        "  new_model_w.compile(loss = 'categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
        "  new_model_w.summary()\n",
        "\n",
        "  total_time=0.0\n",
        "\n",
        "  pred_w = []\n",
        "\n",
        "  for filename in os.listdir(path):\n",
        "      label = filename.split('_')[0]\n",
        "      file_path = path + \"/\" + filename\n",
        "      x=time.time()\n",
        "      image=tf.keras.preprocessing.image.load_img(file_path, target_size=(224, 224))  # reading image (Folder path and image name )\n",
        "        \n",
        "      image=np.array(image)\n",
        "      image=image.reshape((1,image.shape[0],image.shape[1],image.shape[2]))\n",
        "      image=preprocess_input(image)\n",
        "\n",
        "      op1=new_model_w.predict(image)\n",
        "      y=time.time()\n",
        "      total_time = total_time + (y-x)\n",
        "      label1=decode_predictions(op1,top=1)\n",
        "      pred_w.append([label, label1[0][0][0]])\n",
        "\n",
        "  count = 0\n",
        "  for i in range(len(pred_w)):\n",
        "    if pred_w[i][0] == pred_w[i][1] :\n",
        "      count = count + 1\n",
        "  print('Model Flops : ', modelFlops(new_model_w))\n",
        "  flops_w.append(modelFlops(new_model_w))\n",
        "  accuracy_w.append(round(100*count/len(pred_w),2))\n",
        "  print('Total : ', len(pred_w), ', Correct : ', count, ', Accuracy : ', (100*count/len(pred_w)))\n",
        "  #comp_time.append(round(total_time/len(pred_w),2))\n",
        "  print('Time Taken for prediction : ', (total_time/len(pred_w)) )\n",
        "  params_w.append(new_model_w.count_params())\n",
        "  print(\"Number of parameter after pruning\",new_model_w.count_params())\n",
        "\n",
        "  new_model_w.save((\"vgg16_w_\"+str(i)))\n",
        "  frm = \"/content/\" + \"vgg16_w_\" + str(i)\n",
        "  model_size_w.append(round((os.stat(frm).st_size)/math.pow(2,20),2))\n",
        "  print(\"Model size after pruning=>\",(os.stat(frm).st_size)/math.pow(2,20),\" Mega Bytes\")\n",
        "  i+=1\n",
        "  print(\"######################################################################################################################################################################\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "###################################################################################################################################################################\n",
            "FOR RATE :  0.01\n",
            "Number of channels to delete 37\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Number of parameter before pruning 138357544\n",
            "Deleting 8/128 channels from layer: block2_conv2\n",
            "Deleting 19/256 channels from layer: block3_conv2\n",
            "Deleting 1/64 channels from layer: block1_conv2\n",
            "Deleting 2/512 channels from layer: block5_conv1\n",
            "Deleting 3/256 channels from layer: block3_conv3\n",
            "Deleting 4/512 channels from layer: block4_conv2\n",
            "Model: \"model_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 63)      36351     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     72704     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 120)     138360    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       276736    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 237)       546285    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 253)       539902    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1166336   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 508)       2341372   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2341376   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 510)       2350590   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2350592   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,165,060\n",
            "Trainable params: 138,165,060\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model Flops :  29822863579\n",
            "Total :  84 , Correct :  82 , Accuracy :  97.61904761904762\n",
            "Time Taken for prediction :  0.0254988812264942\n",
            "Number of parameter after pruning 138165060\n",
            "Model size after pruning=> 527.1374015808105  Mega Bytes\n",
            "######################################################################################################################################################################\n",
            "###################################################################################################################################################################\n",
            "FOR RATE :  0.02\n",
            "Number of channels to delete 74\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Number of parameter before pruning 138357544\n",
            "Deleting 12/128 channels from layer: block2_conv2\n",
            "Deleting 27/256 channels from layer: block3_conv2\n",
            "Deleting 1/64 channels from layer: block1_conv2\n",
            "Deleting 2/512 channels from layer: block5_conv1\n",
            "Deleting 8/256 channels from layer: block3_conv3\n",
            "Deleting 20/512 channels from layer: block4_conv2\n",
            "Deleting 4/512 channels from layer: block4_conv3\n",
            "Model: \"model_36\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 63)      36351     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     72704     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 116)     133748    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       267520    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 229)       527845    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 248)       511376    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1143296   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 492)       2267628   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 508)       2249932   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 510)       2332230   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2350592   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 137,897,678\n",
            "Trainable params: 137,897,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model Flops :  29052658806\n",
            "Total :  84 , Correct :  81 , Accuracy :  96.42857142857143\n",
            "Time Taken for prediction :  0.02557879402523949\n",
            "Number of parameter after pruning 137897678\n",
            "Model size after pruning=> 526.117561340332  Mega Bytes\n",
            "######################################################################################################################################################################\n",
            "###################################################################################################################################################################\n",
            "FOR RATE :  0.03\n",
            "Number of channels to delete 111\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Number of parameter before pruning 138357544\n",
            "Deleting 13/128 channels from layer: block2_conv2\n",
            "Deleting 35/256 channels from layer: block3_conv2\n",
            "Deleting 1/64 channels from layer: block1_conv2\n",
            "Deleting 2/512 channels from layer: block5_conv1\n",
            "Deleting 11/256 channels from layer: block3_conv3\n",
            "Deleting 41/512 channels from layer: block4_conv2\n",
            "Deleting 7/512 channels from layer: block4_conv3\n",
            "Deleting 1/128 channels from layer: block2_conv1\n",
            "Model: \"model_44\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 63)      36351     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 127)     72136     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 115)     131560    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       265216    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 221)       509405    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 245)       487550    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1129472   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 471)       2170839   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 505)       2141200   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 510)       2318460   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2350592   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 137,617,237\n",
            "Trainable params: 137,617,237\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model Flops :  28354799201\n",
            "Total :  84 , Correct :  84 , Accuracy :  100.0\n",
            "Time Taken for prediction :  0.029027127084277925\n",
            "Number of parameter after pruning 137617237\n",
            "Model size after pruning=> 525.0479049682617  Mega Bytes\n",
            "######################################################################################################################################################################\n",
            "###################################################################################################################################################################\n",
            "FOR RATE :  0.04\n",
            "Number of channels to delete 149\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Number of parameter before pruning 138357544\n",
            "Deleting 15/128 channels from layer: block2_conv2\n",
            "Deleting 42/256 channels from layer: block3_conv2\n",
            "Deleting 1/64 channels from layer: block1_conv2\n",
            "Deleting 2/512 channels from layer: block5_conv1\n",
            "Deleting 15/256 channels from layer: block3_conv3\n",
            "Deleting 61/512 channels from layer: block4_conv2\n",
            "Deleting 12/512 channels from layer: block4_conv3\n",
            "Deleting 1/128 channels from layer: block2_conv1\n",
            "Model: \"model_52\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 63)      36351     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 127)     72136     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 113)     129272    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       260608    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 214)       493270    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 241)       464407    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1111040   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 451)       2078659   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 500)       2030000   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 510)       2295510   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2350592   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 137,326,301\n",
            "Trainable params: 137,326,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model Flops :  27665505579\n",
            "Total :  84 , Correct :  82 , Accuracy :  97.61904761904762\n",
            "Time Taken for prediction :  0.030969954672313872\n",
            "Number of parameter after pruning 137326301\n",
            "Model size after pruning=> 523.9382171630859  Mega Bytes\n",
            "######################################################################################################################################################################\n",
            "###################################################################################################################################################################\n",
            "FOR RATE :  0.05\n",
            "Number of channels to delete 186\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Number of parameter before pruning 138357544\n",
            "Deleting 16/128 channels from layer: block2_conv2\n",
            "Deleting 45/256 channels from layer: block3_conv2\n",
            "Deleting 1/64 channels from layer: block1_conv2\n",
            "Deleting 2/512 channels from layer: block5_conv1\n",
            "Deleting 21/256 channels from layer: block3_conv3\n",
            "Deleting 78/512 channels from layer: block4_conv2\n",
            "Deleting 21/512 channels from layer: block4_conv3\n",
            "Deleting 1/128 channels from layer: block2_conv1\n",
            "Deleting 1/512 channels from layer: block5_conv3\n",
            "Model: \"model_61\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 63)      36351     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 127)     72136     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 112)     128128    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       258304    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 211)       486355    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 235)       446500    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1083392   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 434)       2000306   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 491)       1918337   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 510)       2254200   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2350592   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 511)       2355199   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102563840 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 136,833,744\n",
            "Trainable params: 136,833,744\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model Flops :  27107094486\n",
            "Total :  84 , Correct :  82 , Accuracy :  97.61904761904762\n",
            "Time Taken for prediction :  0.03390024673371088\n",
            "Number of parameter after pruning 136833744\n",
            "Model size after pruning=> 522.0594024658203  Mega Bytes\n",
            "######################################################################################################################################################################\n",
            "###################################################################################################################################################################\n",
            "FOR RATE :  0.06\n",
            "Number of channels to delete 223\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Number of parameter before pruning 138357544\n",
            "Deleting 16/128 channels from layer: block2_conv2\n",
            "Deleting 51/256 channels from layer: block3_conv2\n",
            "Deleting 1/64 channels from layer: block1_conv2\n",
            "Deleting 3/512 channels from layer: block5_conv1\n",
            "Deleting 24/256 channels from layer: block3_conv3\n",
            "Deleting 95/512 channels from layer: block4_conv2\n",
            "Deleting 30/512 channels from layer: block4_conv3\n",
            "Deleting 1/128 channels from layer: block2_conv1\n",
            "Deleting 1/512 channels from layer: block5_conv3\n",
            "Deleting 1/256 channels from layer: block3_conv1\n",
            "Model: \"model_71\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 63)      36351     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 127)     72136     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 112)     128128    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 255)       257295    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 205)       470680    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 232)       428272    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1069568   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 417)       1921953   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 482)       1809428   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 509)       2208551   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2345984   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 511)       2355199   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102563840 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 136,547,489\n",
            "Trainable params: 136,547,489\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model Flops :  26553226673\n",
            "Total :  84 , Correct :  79 , Accuracy :  94.04761904761905\n",
            "Time Taken for prediction :  0.03820375033787319\n",
            "Number of parameter after pruning 136547489\n",
            "Model size after pruning=> 520.9675674438477  Mega Bytes\n",
            "######################################################################################################################################################################\n",
            "###################################################################################################################################################################\n",
            "FOR RATE :  0.07\n",
            "Number of channels to delete 260\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Number of parameter before pruning 138357544\n",
            "Deleting 17/128 channels from layer: block2_conv2\n",
            "Deleting 58/256 channels from layer: block3_conv2\n",
            "Deleting 1/64 channels from layer: block1_conv2\n",
            "Deleting 3/512 channels from layer: block5_conv1\n",
            "Deleting 28/256 channels from layer: block3_conv3\n",
            "Deleting 110/512 channels from layer: block4_conv2\n",
            "Deleting 40/512 channels from layer: block4_conv3\n",
            "Deleting 1/128 channels from layer: block2_conv1\n",
            "Deleting 1/512 channels from layer: block5_conv3\n",
            "Deleting 1/256 channels from layer: block3_conv1\n",
            "Model: \"model_81\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 63)      36351     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 127)     72136     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 111)     126984    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 255)       255000    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 198)       454608    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 228)       406524    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1051136   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 402)       1852818   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 472)       1708168   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 509)       2162741   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2345984   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 511)       2355199   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102563840 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 136,271,593\n",
            "Trainable params: 136,271,593\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model Flops :  25959019708\n",
            "Total :  84 , Correct :  74 , Accuracy :  88.0952380952381\n",
            "Time Taken for prediction :  0.042655885219573975\n",
            "Number of parameter after pruning 136271593\n",
            "Model size after pruning=> 519.9152488708496  Mega Bytes\n",
            "######################################################################################################################################################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcMcpZPB1W6t",
        "outputId": "ded9de9f-3498-482a-dbf9-3f876976bbc2"
      },
      "source": [
        "print(rates_w)\n",
        "print(accuracy_w)\n",
        "print(params_w)\n",
        "print(model_size_w)\n",
        "print(flops_w)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07]\n",
            "[98.8, 97.62, 96.43, 100.0, 97.62, 97.62, 94.05, 88.1]\n",
            "[138357544, 138165060, 137897678, 137617237, 137326301, 136833744, 136547489, 136271593]\n",
            "[527.8, 527.14, 526.12, 525.05, 523.94, 522.06, 520.97, 519.92]\n",
            "[20467662529, 29822863579, 29052658806, 28354799201, 27665505579, 27107094486, 26553226673, 25959019708]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JwbP6IG1gml",
        "outputId": "0d2b90b8-bc44-40d2-fc9f-6542b0df51e7"
      },
      "source": [
        "rate=[0.08,0.10,0.12,0.14,0.16]#different values of rates\n",
        "i=7\n",
        "for r in rate:\n",
        "  print(\"###################################################################################################################################################################\")\n",
        "  print(\"FOR RATE : \", r)\n",
        "  rates_w.append(r)\n",
        "  num_channels_to_delete_overall=round(len(weights_dic_sort_item)*r)\n",
        "  print(\"Number of channels to delete\",num_channels_to_delete_overall)\n",
        "\n",
        "  dic_layer={}\n",
        "  for i in range(num_channels_to_delete_overall):\n",
        "    if weights_dic_sort_item[i][0][0] not in dic_layer:\n",
        "      dic_layer[weights_dic_sort_item[i][0][0]]=[]\n",
        "      dic_layer[weights_dic_sort_item[i][0][0]].append(weights_dic_sort_item[i][0][1])\n",
        "    else:\n",
        "      dic_layer[weights_dic_sort_item[i][0][0]].append(weights_dic_sort_item[i][0][1])\n",
        "\n",
        "  dic_layer_sorted_l2={}\n",
        "  for key,value in dic_layer.items():\n",
        "    dic_layer_sorted_l2[key]=sorted(value)\n",
        "\n",
        "  new_model_w=tf.keras.applications.vgg16.VGG16(weights='imagenet',include_top=True)\n",
        "  new_model_w.summary()\n",
        "  print(\"Number of parameter before pruning\",new_model_w.count_params())\n",
        "\n",
        "  for key,value in dic_layer_sorted_l2.items():\n",
        "    if key!=0:\n",
        "      surgeon = Surgeon(new_model_w)\n",
        "      surgeon.add_job('delete_channels', new_model_w.layers[layer[key-1]], channels=value)\n",
        "      new_model_w = surgeon.operate()\n",
        "  \n",
        "  new_model_w.compile(loss = 'categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
        "  new_model_w.summary()\n",
        "\n",
        "  total_time=0.0\n",
        "\n",
        "  pred_w = []\n",
        "\n",
        "  for filename in os.listdir(path):\n",
        "      label = filename.split('_')[0]\n",
        "      file_path = path + \"/\" + filename\n",
        "      x=time.time()\n",
        "      image=tf.keras.preprocessing.image.load_img(file_path, target_size=(224, 224))  # reading image (Folder path and image name )\n",
        "        \n",
        "      image=np.array(image)\n",
        "      image=image.reshape((1,image.shape[0],image.shape[1],image.shape[2]))\n",
        "      image=preprocess_input(image)\n",
        "\n",
        "      op1=new_model_w.predict(image)\n",
        "      y=time.time()\n",
        "      total_time = total_time + (y-x)\n",
        "      label1=decode_predictions(op1,top=1)\n",
        "      pred_w.append([label, label1[0][0][0]])\n",
        "\n",
        "  count = 0\n",
        "  for i in range(len(pred_w)):\n",
        "    if pred_w[i][0] == pred_w[i][1] :\n",
        "      count = count + 1\n",
        "  print('Model Flops : ', modelFlops(new_model_w))\n",
        "  flops_w.append(modelFlops(new_model_w))\n",
        "  accuracy_w.append(round(100*count/len(pred_w),2))\n",
        "  print('Total : ', len(pred_w), ', Correct : ', count, ', Accuracy : ', (100*count/len(pred_w)))\n",
        "  #comp_time.append(round(total_time/len(pred_w),2))\n",
        "  print('Time Taken for prediction : ', (total_time/len(pred_w)) )\n",
        "  params_w.append(new_model_w.count_params())\n",
        "  print(\"Number of parameter after pruning\",new_model_w.count_params())\n",
        "\n",
        "  new_model_w.save((\"vgg16_w_\"+str(i)))\n",
        "  frm = \"/content/\" + \"vgg16_w_\" + str(i)\n",
        "  model_size_w.append(round((os.stat(frm).st_size)/math.pow(2,20),2))\n",
        "  print(\"Model size after pruning=>\",(os.stat(frm).st_size)/math.pow(2,20),\" Mega Bytes\")\n",
        "  i+=1\n",
        "  print(\"######################################################################################################################################################################\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "###################################################################################################################################################################\n",
            "FOR RATE :  0.08\n",
            "Number of channels to delete 297\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Number of parameter before pruning 138357544\n",
            "Deleting 18/128 channels from layer: block2_conv2\n",
            "Deleting 61/256 channels from layer: block3_conv2\n",
            "Deleting 1/64 channels from layer: block1_conv2\n",
            "Deleting 4/512 channels from layer: block5_conv1\n",
            "Deleting 31/256 channels from layer: block3_conv3\n",
            "Deleting 129/512 channels from layer: block4_conv2\n",
            "Deleting 49/512 channels from layer: block4_conv3\n",
            "Deleting 1/128 channels from layer: block2_conv1\n",
            "Deleting 1/512 channels from layer: block5_conv3\n",
            "Deleting 1/256 channels from layer: block3_conv1\n",
            "Deleting 1/512 channels from layer: block5_conv2\n",
            "Model: \"model_92\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 63)      36351     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 127)     72136     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 110)     125840    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 255)       252705    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 195)       447720    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 225)       395100    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1037312   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 383)       1765247   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 463)       1596424   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 508)       2117344   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 511)       2336803   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 511)       2350600   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102563840 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 135,977,526\n",
            "Trainable params: 135,977,526\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model Flops :  25443779967\n",
            "Total :  84 , Correct :  64 , Accuracy :  76.19047619047619\n",
            "Time Taken for prediction :  0.04584423133305141\n",
            "Number of parameter after pruning 135977526\n",
            "Model size after pruning=> 518.791675567627  Mega Bytes\n",
            "######################################################################################################################################################################\n",
            "###################################################################################################################################################################\n",
            "FOR RATE :  0.1\n",
            "Number of channels to delete 372\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Number of parameter before pruning 138357544\n",
            "Deleting 19/128 channels from layer: block2_conv2\n",
            "Deleting 66/256 channels from layer: block3_conv2\n",
            "Deleting 1/64 channels from layer: block1_conv2\n",
            "Deleting 7/512 channels from layer: block5_conv1\n",
            "Deleting 44/256 channels from layer: block3_conv3\n",
            "Deleting 159/512 channels from layer: block4_conv2\n",
            "Deleting 70/512 channels from layer: block4_conv3\n",
            "Deleting 1/128 channels from layer: block2_conv1\n",
            "Deleting 1/512 channels from layer: block5_conv3\n",
            "Deleting 2/256 channels from layer: block3_conv1\n",
            "Deleting 2/512 channels from layer: block5_conv2\n",
            "Model: \"model_103\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 63)      36351     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 127)     72136     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 109)     124696    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 254)       249428    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 190)       434530    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 212)       362732    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       977408    \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 353)       1626977   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 442)       1404676   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 505)       2009395   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 510)       2318460   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 511)       2346001   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102563840 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 135,406,734\n",
            "Trainable params: 135,406,734\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model Flops :  24446304924\n",
            "Total :  84 , Correct :  41 , Accuracy :  48.80952380952381\n",
            "Time Taken for prediction :  0.04786808717818487\n",
            "Number of parameter after pruning 135406734\n",
            "Model size after pruning=> 516.6146240234375  Mega Bytes\n",
            "######################################################################################################################################################################\n",
            "###################################################################################################################################################################\n",
            "FOR RATE :  0.12\n",
            "Number of channels to delete 446\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Number of parameter before pruning 138357544\n",
            "Deleting 19/128 channels from layer: block2_conv2\n",
            "Deleting 73/256 channels from layer: block3_conv2\n",
            "Deleting 1/64 channels from layer: block1_conv2\n",
            "Deleting 11/512 channels from layer: block5_conv1\n",
            "Deleting 50/256 channels from layer: block3_conv3\n",
            "Deleting 189/512 channels from layer: block4_conv2\n",
            "Deleting 92/512 channels from layer: block4_conv3\n",
            "Deleting 1/128 channels from layer: block2_conv1\n",
            "Deleting 2/512 channels from layer: block5_conv3\n",
            "Deleting 2/256 channels from layer: block3_conv1\n",
            "Deleting 4/512 channels from layer: block5_conv2\n",
            "Deleting 2/512 channels from layer: block4_conv1\n",
            "Model: \"model_115\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 63)      36351     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 127)     72136     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 109)     124696    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 254)       249428    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 183)       418521    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 206)       339488    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 510)       946050    \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 323)       1482893   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 420)       1221360   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 501)       1894281   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 508)       2291080   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 510)       2332230   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102363136 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 134,651,754\n",
            "Trainable params: 134,651,754\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model Flops :  23576089154\n",
            "Total :  84 , Correct :  22 , Accuracy :  26.19047619047619\n",
            "Time Taken for prediction :  0.05252964439846221\n",
            "Number of parameter after pruning 134651754\n",
            "Model size after pruning=> 513.7348861694336  Mega Bytes\n",
            "######################################################################################################################################################################\n",
            "###################################################################################################################################################################\n",
            "FOR RATE :  0.14\n",
            "Number of channels to delete 520\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_13 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Number of parameter before pruning 138357544\n",
            "Deleting 19/128 channels from layer: block2_conv2\n",
            "Deleting 77/256 channels from layer: block3_conv2\n",
            "Deleting 1/64 channels from layer: block1_conv2\n",
            "Deleting 14/512 channels from layer: block5_conv1\n",
            "Deleting 59/256 channels from layer: block3_conv3\n",
            "Deleting 211/512 channels from layer: block4_conv2\n",
            "Deleting 120/512 channels from layer: block4_conv3\n",
            "Deleting 1/128 channels from layer: block2_conv1\n",
            "Deleting 4/512 channels from layer: block5_conv3\n",
            "Deleting 3/256 channels from layer: block3_conv1\n",
            "Deleting 9/512 channels from layer: block5_conv2\n",
            "Deleting 2/512 channels from layer: block4_conv1\n",
            "Model: \"model_127\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_13 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 63)      36351     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 127)     72136     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 109)     124696    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 253)       248446    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 179)       407762    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 197)       317564    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 510)       904740    \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 301)       1381891   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 392)       1062320   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 498)       1757442   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 503)       2254949   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 508)       2300224   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              101961728 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 133,710,353\n",
            "Trainable params: 133,710,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model Flops :  22811438984\n",
            "Total :  84 , Correct :  12 , Accuracy :  14.285714285714286\n",
            "Time Taken for prediction :  0.05863589616048904\n",
            "Number of parameter after pruning 133710353\n",
            "Model size after pruning=> 510.14204025268555  Mega Bytes\n",
            "######################################################################################################################################################################\n",
            "###################################################################################################################################################################\n",
            "FOR RATE :  0.16\n",
            "Number of channels to delete 594\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_14 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Number of parameter before pruning 138357544\n",
            "Deleting 24/128 channels from layer: block2_conv2\n",
            "Deleting 83/256 channels from layer: block3_conv2\n",
            "Deleting 1/64 channels from layer: block1_conv2\n",
            "Deleting 20/512 channels from layer: block5_conv1\n",
            "Deleting 60/256 channels from layer: block3_conv3\n",
            "Deleting 238/512 channels from layer: block4_conv2\n",
            "Deleting 141/512 channels from layer: block4_conv3\n",
            "Deleting 1/128 channels from layer: block2_conv1\n",
            "Deleting 6/512 channels from layer: block5_conv3\n",
            "Deleting 3/256 channels from layer: block3_conv1\n",
            "Deleting 14/512 channels from layer: block5_conv2\n",
            "Deleting 3/512 channels from layer: block4_conv1\n",
            "Model: \"model_139\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_14 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 63)      36351     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 127)     72136     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 104)     118976    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 253)       237061    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 173)       394094    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 196)       305368    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 509)       898385    \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 274)       1255468   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 371)       915257    \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 492)       1643280   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 498)       2205642   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 506)       2268398   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              101560320 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 132,790,840\n",
            "Trainable params: 132,790,840\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model Flops :  21918411950\n",
            "Total :  84 , Correct :  5 , Accuracy :  5.9523809523809526\n",
            "Time Taken for prediction :  0.06211440052304949\n",
            "Number of parameter after pruning 132790840\n",
            "Model size after pruning=> 506.63465881347656  Mega Bytes\n",
            "######################################################################################################################################################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2BWgSNS1qlz",
        "outputId": "ad09a31e-209c-4807-a781-108027b5d79d"
      },
      "source": [
        "print(rates_w)\n",
        "print(accuracy_w)\n",
        "print(params_w)\n",
        "print(model_size_w)\n",
        "print(flops_w)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.1, 0.12, 0.14, 0.16]\n",
            "[98.8, 97.62, 96.43, 100.0, 97.62, 97.62, 94.05, 88.1, 76.19, 48.81, 26.19, 14.29, 5.95]\n",
            "[138357544, 138165060, 137897678, 137617237, 137326301, 136833744, 136547489, 136271593, 135977526, 135406734, 134651754, 133710353, 132790840]\n",
            "[527.8, 527.14, 526.12, 525.05, 523.94, 522.06, 520.97, 519.92, 518.79, 516.61, 513.73, 510.14, 506.63]\n",
            "[30932349056, 29822863579, 29052658806, 28354799201, 27665505579, 27107094486, 26553226673, 25959019708, 25443779967, 24446304924, 23576089154, 22811438984, 21918411950]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bWnbOWCrflS"
      },
      "source": [
        "Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-9j6rwIHY5V"
      },
      "source": [
        "flops_w[0]=30932349056"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2cUSLxnHgSw",
        "outputId": "79da9e9e-c9b6-4a35-929e-016a472edfbc"
      },
      "source": [
        "flops_w"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[30932349056,\n",
              " 29822863579,\n",
              " 29052658806,\n",
              " 28354799201,\n",
              " 27665505579,\n",
              " 27107094486,\n",
              " 26553226673,\n",
              " 25959019708,\n",
              " 25443779967,\n",
              " 24446304924,\n",
              " 23576089154,\n",
              " 22811438984,\n",
              " 21918411950]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "miuABmi4rpgD",
        "outputId": "be574fcc-d3f5-4247-9718-38d6a920bd10"
      },
      "source": [
        "fig1,a1 =  plt.subplots(2,2)\n",
        "a1[0][0].plot(rates_w,params_w)\n",
        "a1[0][0].set_title('Rate Vs. Parameters')\n",
        "a1[0][1].plot(rates_w,model_size_w)\n",
        "a1[0][1].set_title('Rate Vs. mode_size')\n",
        "a1[1][0].plot(rates_w,accuracy_w)\n",
        "a1[1][0].set_title('Rate Vs. Accuracy')\n",
        "a1[1][1].plot(rates_w,flops_w)\n",
        "a1[1][1].set_title('Rate Vs. flops')\n",
        "fig1.tight_layout()\n",
        "fig1.set_size_inches(15, 10)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1za2AxASN1j"
      },
      "source": [
        "# Stop Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk0wkOzZ39rh"
      },
      "source": [
        "## Using Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poqIaPO54BNi"
      },
      "source": [
        "pip install torch_pruning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCIos_3L4JRa"
      },
      "source": [
        "import torch\n",
        "from torchvision.models import resnet18, vgg16_bn\n",
        "import torch_pruning as tp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3yOe5uW4K62"
      },
      "source": [
        "model_torch = vgg16_bn(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEgkw2bx5Emz"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "def count_parameters(model, print_model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: continue\n",
        "        param = parameter.numel()\n",
        "        table.add_row([name, param])\n",
        "        total_params+=param\n",
        "    if print_model == True :\n",
        "      print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "    \n",
        "count_parameters(model_torch, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT7RMPOHFu6S"
      },
      "source": [
        "## Pytorch self trial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmuGTQZF5Ofw"
      },
      "source": [
        "def selfTrial(model_torch) :\n",
        "  # 1. setup strategy (L1 Norm)\n",
        "  strategy = tp.strategy.L1Strategy() # or tp.strategy.RandomStrategy()\n",
        "\n",
        "  # 2. build layer dependency for resnet18\n",
        "  DG = tp.DependencyGraph()\n",
        "  DG.build_dependency(model_torch, example_inputs=torch.randn(1,3,224,224))\n",
        "\n",
        "  # 3. get a pruning plan from the dependency graph.\n",
        "  pruning_idxs = strategy()# or manually selected pruning_idxs=[2, 6, 9]\n",
        "  pruning_plan = DG.get_pruning_plan( model_torch.conv1, tp.prune_conv, idxs=pruning_idxs )\n",
        "  print(pruning_plan)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjF9xHlmDNIs"
      },
      "source": [
        "## Pytorch Code from internet "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm12jdoNDPDR"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torchvision import models\n",
        "import cv2\n",
        "import sys\n",
        "import numpy as np\n",
        "import time\n",
        " \n",
        "def replace_layers(model, i, indexes, layers):\n",
        "    if i in indexes:\n",
        "        return layers[indexes.index(i)]\n",
        "    return model[i]\n",
        "\n",
        "def prune_vgg16_conv_layer(model, layer_index, filter_index, use_cuda=False):\n",
        "    _, conv = list(model.features._modules.items())[layer_index]\n",
        "    next_conv = None\n",
        "    offset = 1\n",
        "\n",
        "    while layer_index + offset <  len(model.features._modules.items()):\n",
        "        res =  list(model.features._modules.items())[layer_index+offset]\n",
        "        if isinstance(res[1], torch.nn.modules.conv.Conv2d):\n",
        "            next_name, next_conv = res\n",
        "            break\n",
        "        offset = offset + 1\n",
        "    \n",
        "    new_conv = \\\n",
        "        torch.nn.Conv2d(in_channels = conv.in_channels, \\\n",
        "            out_channels = conv.out_channels - 1,\n",
        "            kernel_size = conv.kernel_size, \\\n",
        "            stride = conv.stride,\n",
        "            padding = conv.padding,\n",
        "            dilation = conv.dilation,\n",
        "            groups = conv.groups,\n",
        "            bias = (conv.bias is not None))\n",
        "\n",
        "    old_weights = conv.weight.data.cpu().numpy()\n",
        "    new_weights = new_conv.weight.data.cpu().numpy()\n",
        "\n",
        "    new_weights[: filter_index, :, :, :] = old_weights[: filter_index, :, :, :]\n",
        "    new_weights[filter_index : , :, :, :] = old_weights[filter_index + 1 :, :, :, :]\n",
        "    new_conv.weight.data = torch.from_numpy(new_weights)\n",
        "    if use_cuda:\n",
        "        new_conv.weight.data = new_conv.weight.data.cuda()\n",
        "\n",
        "    bias_numpy = conv.bias.data.cpu().numpy()\n",
        "\n",
        "    bias = np.zeros(shape = (bias_numpy.shape[0] - 1), dtype = np.float32)\n",
        "    bias[:filter_index] = bias_numpy[:filter_index]\n",
        "    bias[filter_index : ] = bias_numpy[filter_index + 1 :]\n",
        "    new_conv.bias.data = torch.from_numpy(bias)\n",
        "    if use_cuda:\n",
        "        new_conv.bias.data = new_conv.bias.data.cuda()\n",
        "\n",
        "    if not next_conv is None:\n",
        "        next_new_conv = \\\n",
        "            torch.nn.Conv2d(in_channels = next_conv.in_channels - 1,\\\n",
        "                out_channels =  next_conv.out_channels, \\\n",
        "                kernel_size = next_conv.kernel_size, \\\n",
        "                stride = next_conv.stride,\n",
        "                padding = next_conv.padding,\n",
        "                dilation = next_conv.dilation,\n",
        "                groups = next_conv.groups,\n",
        "                bias = (next_conv.bias is not None))\n",
        "\n",
        "        old_weights = next_conv.weight.data.cpu().numpy()\n",
        "        new_weights = next_new_conv.weight.data.cpu().numpy()\n",
        "\n",
        "        new_weights[:, : filter_index, :, :] = old_weights[:, : filter_index, :, :]\n",
        "        new_weights[:, filter_index : , :, :] = old_weights[:, filter_index + 1 :, :, :]\n",
        "        next_new_conv.weight.data = torch.from_numpy(new_weights)\n",
        "        if use_cuda:\n",
        "            next_new_conv.weight.data = next_new_conv.weight.data.cuda()\n",
        "\n",
        "        next_new_conv.bias.data = next_conv.bias.data\n",
        "\n",
        "    if not next_conv is None:\n",
        "        features = torch.nn.Sequential(\n",
        "                *(replace_layers(model.features, i, [layer_index, layer_index+offset], \\\n",
        "                    [new_conv, next_new_conv]) for i, _ in enumerate(model.features)))\n",
        "        del model.features\n",
        "        del conv\n",
        "\n",
        "        model.features = features\n",
        "\n",
        "    else:\n",
        "        #Prunning the last conv layer. This affects the first linear layer of the classifier.\n",
        "        model.features = torch.nn.Sequential(\n",
        "                *(replace_layers(model.features, i, [layer_index], \\\n",
        "                    [new_conv]) for i, _ in enumerate(model.features)))\n",
        "        layer_index = 0\n",
        "        old_linear_layer = None\n",
        "        for _, module in model.classifier._modules.items():\n",
        "            if isinstance(module, torch.nn.Linear):\n",
        "                old_linear_layer = module\n",
        "                break\n",
        "            layer_index = layer_index  + 1\n",
        "\n",
        "        if old_linear_layer is None:\n",
        "            raise BaseException(\"No linear laye found in classifier\")\n",
        "        params_per_input_channel = old_linear_layer.in_features // conv.out_channels\n",
        "\n",
        "        new_linear_layer = \\\n",
        "            torch.nn.Linear(old_linear_layer.in_features - params_per_input_channel, \n",
        "                old_linear_layer.out_features)\n",
        "        \n",
        "        old_weights = old_linear_layer.weight.data.cpu().numpy()\n",
        "        new_weights = new_linear_layer.weight.data.cpu().numpy()        \n",
        "\n",
        "        new_weights[:, : filter_index * params_per_input_channel] = \\\n",
        "            old_weights[:, : filter_index * params_per_input_channel]\n",
        "        new_weights[:, filter_index * params_per_input_channel :] = \\\n",
        "            old_weights[:, (filter_index + 1) * params_per_input_channel :]\n",
        "        \n",
        "        new_linear_layer.bias.data = old_linear_layer.bias.data\n",
        "\n",
        "        new_linear_layer.weight.data = torch.from_numpy(new_weights)\n",
        "        if use_cuda:\n",
        "            new_linear_layer.weight.data = new_linear_layer.weight.data.cuda()\n",
        "\n",
        "        classifier = torch.nn.Sequential(\n",
        "            *(replace_layers(model.classifier, i, [layer_index], \\\n",
        "                [new_linear_layer]) for i, _ in enumerate(model.classifier)))\n",
        "\n",
        "        del model.classifier\n",
        "        del next_conv\n",
        "        del conv\n",
        "        model.classifier = classifier\n",
        "\n",
        "    return model\n",
        "\n",
        "model = models.vgg16(pretrained=True)\n",
        "model.train()\n",
        "t0 = time.time()\n",
        "new_model = prune_vgg16_conv_layer(model, 28, 10)\n",
        "print(\"The prunning took\", time.time() - t0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w2Hht5hDSGE"
      },
      "source": [
        "count_parameters(new_model, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jt468vKgDV3W"
      },
      "source": [
        "before = count_parameters(models.vgg16(pretrained=True), False)\n",
        "after = count_parameters(new_model, False)\n",
        "print(\"Params pruned : \", before - after)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}